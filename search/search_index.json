{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the wai-annotations manual! Installation - how to install the library Usage - running the library from the command-line Examples - common use-cases Plugin Guide - adding new domains/formats/conversions Domains - supported domains Plugins - available plugins Glossary - explanations of terms","title":"Home"},{"location":"conversion_options/","text":"Conversion options for wai-annotations The following options can be specified before any stages in the conversion chain, and globally affect the process of converting datasets: -h , --help : Lists this set of conversion options and then exits. -v : Optional argument to set the logging verbosity of the conversion. Can be specified multiple times to further increase verbosity. --macro-file : The macros to use during the conversion.","title":"Conversion options for wai-annotations"},{"location":"conversion_options/#conversion-options-for-wai-annotations","text":"The following options can be specified before any stages in the conversion chain, and globally affect the process of converting datasets: -h , --help : Lists this set of conversion options and then exits. -v : Optional argument to set the logging verbosity of the conversion. Can be specified multiple times to further increase verbosity. --macro-file : The macros to use during the conversion.","title":"Conversion options for wai-annotations"},{"location":"domains/","text":"Domains Image Classification Domain Images categorised by content. The image classification domain deals with labelling entire images as containing a certain subject. Instances in this domain contain an image and a string label classifying the image. Image Object-Detection Domain Images containing multiple identified objects. The image object-detection domain pertains to finding regions of still images which contain identifiable objects. Instances in this domain consist of an image and a set of regions (either axis-aligned boxes or polygons), each with an accompanying label, identifying the detected objects within the image. Image Segmentation Domain Images segmented by category. The image segmentation domain 'colourises' an image by assigning a category to each pixel (where no category corresponds to 'the background'). Instances in this domain are a still image and a corresponding table of the same size, where each element is a label. Speech Domain Transcriptions of recorded speech. The speech domain covers audio data of people speaking natural languages, annotated with text transcribing the verbal contents of the audio. Instances in this domain are an audio file and a string containing the transcription.","title":"Domains"},{"location":"domains/#domains","text":"","title":"Domains"},{"location":"domains/#image-classification-domain","text":"Images categorised by content. The image classification domain deals with labelling entire images as containing a certain subject. Instances in this domain contain an image and a string label classifying the image.","title":"Image Classification Domain"},{"location":"domains/#image-object-detection-domain","text":"Images containing multiple identified objects. The image object-detection domain pertains to finding regions of still images which contain identifiable objects. Instances in this domain consist of an image and a set of regions (either axis-aligned boxes or polygons), each with an accompanying label, identifying the detected objects within the image.","title":"Image Object-Detection Domain"},{"location":"domains/#image-segmentation-domain","text":"Images segmented by category. The image segmentation domain 'colourises' an image by assigning a category to each pixel (where no category corresponds to 'the background'). Instances in this domain are a still image and a corresponding table of the same size, where each element is a label.","title":"Image Segmentation Domain"},{"location":"domains/#speech-domain","text":"Transcriptions of recorded speech. The speech domain covers audio data of people speaking natural languages, annotated with text transcribing the verbal contents of the audio. Instances in this domain are an audio file and a string containing the transcription.","title":"Speech Domain"},{"location":"examples/","text":"Examples Tip: While building a conversion pipeline command, open a separate terminal to quickly output the available plugins ( wai-annotations plugins ) and the help for a specific plugin ( wai-annotations plugins -o PLUGINNAME ). NB: In the examples below, input and output represent directories, which you will have to adapt. Format conversions ADAMS to MS-COCO Also adds additional logging information and removes annotations smaller than 5 pixels in either dimension. wai-annotations convert -v \\ from-adams-od -i input \\ dimension-discarder --min-width 5 --min-height 5 \\ to-coco-od -o output/annotations.json --license-name \"my license\" --no-images Monolithic Tensorflow records to sharded ones Here we are converting a monolithic TFRecords file into a sharded one ( -s 5 - five shards) and only using a subset of labels ( -l label2,label4,label6 ): wai-annotations convert \\ from-tfrecords-od -i input/objects.records \\ filter-labels -l label2,label4,label6 \\ to-tfrecords-od -o output/subset.records -s 5 -p labels.pbtxt ADAMS to Tensorflow records (masks) The ADAMS input directory contains sub-directories, so we use the \"input/**/*.report\" glob syntax to find all .report files recursively. The data gets split into train/test with a 80/20 ratio. Supplying split names will automatically insert these names into the output file, i.e., output/data.tfrecords will get turned into output/train/data.tfrecords and output/test/data.tfrecords . No path gets supplied to the file containing the labels ( labels.txt ), it will get placed into the correct output directory automatically: wai-annotations convert \\ from-adams-od -i \"input/**/*.report\" \\ coerce-mask \\ to-tf-od -o output/data.tfrecords -p labels.txt --split-names train test --split-ratios 80 20 ADAMS individual layer image segmentation to blue channel JPGs ADAMS supports the individual layers format for image segmentation format, where for each JPG image a PNG with the same file name plus the label suffix is present (e.g.g: 1.jpg -> 1-car.png and 1-person.png). In this case, we only want to include the car annotations in the output. The output gets split into train/val with a ratio of 80/20: wai-annotations convert \\ from-layer-segments-is -i \"input/**/*.png\" --labels car \\ to-indexed-png-is -o output --split-names train val --split-ratios 80 20 Image augmentation The following command-line loads ADAMS annotations and saves augmented MSCOCO ones. The pipeline adds augmented images ( -m add ) that are cropped, flipped, blurred, rotated and scaled. Each inline stream processor changes randomly about 10% of the images ( -T 0.9 - if a random number between 0 and 1 is at least the threshold provided with the -T parameter then the augmentation occurs). Since each augmentation has its own stochastic element, it is being seeded ( -a ) to generate reproducible datasets: wai-annotations convert \\ from-adams-od -i \"input/**/*.report\" \\ crop -a -m add -T 0.9 -f 0.0 -t 0.1 \\ # crop 0-10% of the image flip -a -m add -T 0.9 -d lr \\ # flip left-to-right gaussian-blur -a -m add -T 0.9 -f 0.2 -t 0.5 \\ # sigma from 0.2-0.5 rotate -a -m add -T 0.9 -f=-10 -t=10 \\ # rotate from -10 to +10 degrees scale -a -m add -T 0.9 -f 0.8 -t 1.2 -k -u \\ # scale from 80 to 120%, keeping aspect ratio, resizing the image to-coco-od -o output/annotations.json","title":"Examples"},{"location":"examples/#examples","text":"Tip: While building a conversion pipeline command, open a separate terminal to quickly output the available plugins ( wai-annotations plugins ) and the help for a specific plugin ( wai-annotations plugins -o PLUGINNAME ). NB: In the examples below, input and output represent directories, which you will have to adapt.","title":"Examples"},{"location":"examples/#format-conversions","text":"","title":"Format conversions"},{"location":"examples/#adams-to-ms-coco","text":"Also adds additional logging information and removes annotations smaller than 5 pixels in either dimension. wai-annotations convert -v \\ from-adams-od -i input \\ dimension-discarder --min-width 5 --min-height 5 \\ to-coco-od -o output/annotations.json --license-name \"my license\" --no-images","title":"ADAMS to MS-COCO"},{"location":"examples/#monolithic-tensorflow-records-to-sharded-ones","text":"Here we are converting a monolithic TFRecords file into a sharded one ( -s 5 - five shards) and only using a subset of labels ( -l label2,label4,label6 ): wai-annotations convert \\ from-tfrecords-od -i input/objects.records \\ filter-labels -l label2,label4,label6 \\ to-tfrecords-od -o output/subset.records -s 5 -p labels.pbtxt","title":"Monolithic Tensorflow records to sharded ones"},{"location":"examples/#adams-to-tensorflow-records-masks","text":"The ADAMS input directory contains sub-directories, so we use the \"input/**/*.report\" glob syntax to find all .report files recursively. The data gets split into train/test with a 80/20 ratio. Supplying split names will automatically insert these names into the output file, i.e., output/data.tfrecords will get turned into output/train/data.tfrecords and output/test/data.tfrecords . No path gets supplied to the file containing the labels ( labels.txt ), it will get placed into the correct output directory automatically: wai-annotations convert \\ from-adams-od -i \"input/**/*.report\" \\ coerce-mask \\ to-tf-od -o output/data.tfrecords -p labels.txt --split-names train test --split-ratios 80 20","title":"ADAMS to Tensorflow records (masks)"},{"location":"examples/#adams-individual-layer-image-segmentation-to-blue-channel-jpgs","text":"ADAMS supports the individual layers format for image segmentation format, where for each JPG image a PNG with the same file name plus the label suffix is present (e.g.g: 1.jpg -> 1-car.png and 1-person.png). In this case, we only want to include the car annotations in the output. The output gets split into train/val with a ratio of 80/20: wai-annotations convert \\ from-layer-segments-is -i \"input/**/*.png\" --labels car \\ to-indexed-png-is -o output --split-names train val --split-ratios 80 20","title":"ADAMS individual layer image segmentation to blue channel JPGs"},{"location":"examples/#image-augmentation","text":"The following command-line loads ADAMS annotations and saves augmented MSCOCO ones. The pipeline adds augmented images ( -m add ) that are cropped, flipped, blurred, rotated and scaled. Each inline stream processor changes randomly about 10% of the images ( -T 0.9 - if a random number between 0 and 1 is at least the threshold provided with the -T parameter then the augmentation occurs). Since each augmentation has its own stochastic element, it is being seeded ( -a ) to generate reproducible datasets: wai-annotations convert \\ from-adams-od -i \"input/**/*.report\" \\ crop -a -m add -T 0.9 -f 0.0 -t 0.1 \\ # crop 0-10% of the image flip -a -m add -T 0.9 -d lr \\ # flip left-to-right gaussian-blur -a -m add -T 0.9 -f 0.2 -t 0.5 \\ # sigma from 0.2-0.5 rotate -a -m add -T 0.9 -f=-10 -t=10 \\ # rotate from -10 to +10 degrees scale -a -m add -T 0.9 -f 0.8 -t 1.2 -k -u \\ # scale from 80 to 120%, keeping aspect ratio, resizing the image to-coco-od -o output/annotations.json","title":"Image augmentation"},{"location":"glossary/","text":"Glossary Glossary of terminology used in wai-annotations. Component - A single participating element in a pipeline. Can be a source (inserts items into the start of a pipeline), a sink (consumes items from the end of a pipeline), or a processor (an intermediary element which performs some operation on the items in the pipeline). Conversion Pipeline - A series of stages comprising a complete conversion sequence, consisting of an input format, a series of intermediate processing stages, and a final output format. Cross-Domain Converter (XDC) - An intermediate processor which converts a dataset from one domain to another. For example, a video-based domain could be converted to an image-based domain by treating each frame of the video as an individual image. Domain - A specific type of data, being annotated in a specific manner. For example, datasets in the image object-detection domain consist of still images annotated with regions containing identified objects. Format - An external representation of a domain. This is typically a way of storing instances of the domain on disk. Inline Stream Processor (ISP) - An intermediate processor in the conversion chain, which performs some mutation of the items in a dataset. ISPs cannot change the domain of a dataset. For example, an ISP might remove images that are smaller than a certain size from the conversion stream (for image-based domains). Instance - A specific example of data-item and its annotations in a given domain. Macro - A command-line keyword which is used in place of a series of command-line options. Macros are stored in a JSON file, and specified to wai.annotations via the --macro-file command-line option. Negative Example - An item in a dataset which has no annotations. These are typically used when learning to provide examples of what not to look for. Plugin - An implementation of a stage which can be used by wai.annotations to perform some feature. Plugins can be specified by external modules via the wai.annotations.plugins entry-point in their setup.py script. Plugin Specifier - A class which advertises the components that a particular plugin offers for use with wai-annotations. Pipeline - A series of components which process items in their defined order, each passing its output to the next. Specifier - A class used to advertise a stage/domain to wai.annotations from an external module. Splitting - Because wai.annotations only supports linear pipelines, many formats support splitting of their outputs over a number of output directories. Stage - A collection of components which produces, consumes or processes instances.","title":"Glossary"},{"location":"glossary/#glossary","text":"Glossary of terminology used in wai-annotations. Component - A single participating element in a pipeline. Can be a source (inserts items into the start of a pipeline), a sink (consumes items from the end of a pipeline), or a processor (an intermediary element which performs some operation on the items in the pipeline). Conversion Pipeline - A series of stages comprising a complete conversion sequence, consisting of an input format, a series of intermediate processing stages, and a final output format. Cross-Domain Converter (XDC) - An intermediate processor which converts a dataset from one domain to another. For example, a video-based domain could be converted to an image-based domain by treating each frame of the video as an individual image. Domain - A specific type of data, being annotated in a specific manner. For example, datasets in the image object-detection domain consist of still images annotated with regions containing identified objects. Format - An external representation of a domain. This is typically a way of storing instances of the domain on disk. Inline Stream Processor (ISP) - An intermediate processor in the conversion chain, which performs some mutation of the items in a dataset. ISPs cannot change the domain of a dataset. For example, an ISP might remove images that are smaller than a certain size from the conversion stream (for image-based domains). Instance - A specific example of data-item and its annotations in a given domain. Macro - A command-line keyword which is used in place of a series of command-line options. Macros are stored in a JSON file, and specified to wai.annotations via the --macro-file command-line option. Negative Example - An item in a dataset which has no annotations. These are typically used when learning to provide examples of what not to look for. Plugin - An implementation of a stage which can be used by wai.annotations to perform some feature. Plugins can be specified by external modules via the wai.annotations.plugins entry-point in their setup.py script. Plugin Specifier - A class which advertises the components that a particular plugin offers for use with wai-annotations. Pipeline - A series of components which process items in their defined order, each passing its output to the next. Specifier - A class used to advertise a stage/domain to wai.annotations from an external module. Splitting - Because wai.annotations only supports linear pipelines, many formats support splitting of their outputs over a number of output directories. Stage - A collection of components which produces, consumes or processes instances.","title":"Glossary"},{"location":"install/","text":"Installation of wai-annotations To install wai-annotations issue the following commands using pip: pip install wai.annotations.core wai.annotations.core does not come with any input/output formats installed. You will need to install a plugin for each format that you want to convert between. For a description of the plugin system, see the plugin guide . For installing all available plugins, use this command: pip install wai.annotations Available plugins Image classification https://github.com/waikato-ufdl/wai-annotations-adams https://github.com/waikato-ufdl/wai-annotations-subdir Object detection https://github.com/waikato-ufdl/wai-annotations-adams https://github.com/waikato-ufdl/wai-annotations-coco https://github.com/waikato-ufdl/wai-annotations-roi https://github.com/waikato-ufdl/wai-annotations-tf https://github.com/waikato-ufdl/wai-annotations-vgg https://github.com/waikato-ufdl/wai-annotations-voc https://github.com/waikato-ufdl/wai-annotations-yolo Image segmentation https://github.com/waikato-ufdl/wai-annotations-bluechannel https://github.com/waikato-ufdl/wai-annotations-indexedpng https://github.com/waikato-ufdl/wai-annotations-layersegments Audio https://github.com/waikato-ufdl/wai-annotations-commonvoice https://github.com/waikato-ufdl/wai-annotations-festvox Image augmentation https://github.com/waikato-ufdl/wai-annotations-imgaug","title":"Installation"},{"location":"install/#installation-of-wai-annotations","text":"To install wai-annotations issue the following commands using pip: pip install wai.annotations.core wai.annotations.core does not come with any input/output formats installed. You will need to install a plugin for each format that you want to convert between. For a description of the plugin system, see the plugin guide . For installing all available plugins, use this command: pip install wai.annotations","title":"Installation of wai-annotations"},{"location":"install/#available-plugins","text":"Image classification https://github.com/waikato-ufdl/wai-annotations-adams https://github.com/waikato-ufdl/wai-annotations-subdir Object detection https://github.com/waikato-ufdl/wai-annotations-adams https://github.com/waikato-ufdl/wai-annotations-coco https://github.com/waikato-ufdl/wai-annotations-roi https://github.com/waikato-ufdl/wai-annotations-tf https://github.com/waikato-ufdl/wai-annotations-vgg https://github.com/waikato-ufdl/wai-annotations-voc https://github.com/waikato-ufdl/wai-annotations-yolo Image segmentation https://github.com/waikato-ufdl/wai-annotations-bluechannel https://github.com/waikato-ufdl/wai-annotations-indexedpng https://github.com/waikato-ufdl/wai-annotations-layersegments Audio https://github.com/waikato-ufdl/wai-annotations-commonvoice https://github.com/waikato-ufdl/wai-annotations-festvox Image augmentation https://github.com/waikato-ufdl/wai-annotations-imgaug","title":"Available plugins"},{"location":"plugin/","text":"Adding components to wai-annotations through plugins wai-annotations uses a plugin system to allow other libraries to add new processing components without modifying the base library source. This document details how to go about using this system. Plugin Types There are 4 types of components which can be added to wai-annotations via plugin: input formats, ISPs, XDCs and output formats. New domains can also be added, but these are specified indirectly via any of the previous components. Domains New domains are added indirectly to wai-annotations as dependencies of components, as a domain which has no components is essentially unreachable to a conversion chain. However the specification of new domains is treated as a plugin-related issue, so it is detailed here. A domain is essentially the definition of an instance format, which contains both an item in the conversion dataset and the annotations attached to that item. The actual item in the dataset is represented by a FileInfo object, which contains the name of the item, and the binary data blob containing the item's file data. Domains need to specify a sub-class of FileInfo to represent the item and any additional data about it. The annotations for an instance can be any arbitrary type. To specify a new domain, a domain specifier must be created. This is achieved by importing the base classes from the core wai-annotations package and implementing the abstract methods. from typing import Type from wai.annotations.core.instance import FileInfo, Instance from wai.annotations.core.specifier import DomainSpecifier # Define the file-info type which holds dataset item data class MyFileInfo(FileInfo): @classmethod def from_file_data(cls, file_name: str, file_data: bytes) -> 'MyFileInfo': # If we don't need any additional information, or it is calculated in the init method return cls(file_name, file_data) # Define the type of annotations for the domain class MyAnnotations: ... # Define an instance type with additional functionality, if required class MyInstance(Instance[MyFileInfo, MyAnnotations]): def additional_method(self): ... # Define the domain specifier reporting the various classes for domain instances class MyDomainSpecifier(DomainSpecifier): @classmethod def domain_name(cls) -> str: return \"my domain\" @classmethod def file_type(cls) -> Type[MyFileInfo]: return MyFileInfo @classmethod def annotations_type(cls) -> Type[MyAnnotations]: return MyAnnotations # If our instances need additional functionality, we can override this method. The default is # wai.annotations.core.instance.Instance[cls.file_type(), cls.annotations_type()], and if we # do override this method, the type returned must inherit from this default type. @classmethod def instance_class(cls) -> Type[Instance]: return MyInstance Writing New Components The base classes for components can be imported from wai-annotations' core package: from wai.annotations.core.component import Reader, InputConverter # For input formats from wai.annotations.core.component import InlineStreamProcessor # For ISPs from wai.annotations.core.component import CrossDomainConverter # For XDCs from wai.annotations.core.component import Writer, OutputConverter # For output formats Sub-class the base classes for the type of component you are trying to implement, and fill in the generic type-parameters and abstract methods. For generic type-parameters, component base classes vary on instance types, which are defined in the domain specifier for the domains the component operates in. Therefore the best way to specify the instance type-parameter is to import the domain specifiers for the domains of interest and use their instance_class() methods. For the abstract methods, each component has a few methods which require implementation. The purpose of each should be fairly self-explanatory, but the following examples will (hopefully) illustrate how to use each base class. Input Formats Input formats consist of 2 components, a reader and an input-converter. The reader reads files from disk into an arbitrary format, and the input-converter converts that format into the instance format for the domain of the dataset. An example of how to implement a new input-format: from typing import Iterator, IO, Type from wai.annotations.core.component import Reader, InputConverter from wai.annotations.core.specifier import InputFormatSpecifier from wai.annotations.domain.image.object_detection import ImageObjectDetectionDomainSpecifier # Get the instance type from the domain specifier ImageObjectDetectionInstance = ImageObjectDetectionDomainSpecifier.instance_class() # Define the external format in any way you like (if being used with an output format as well, # define separately and import) class MyExternalFormat: @classmethod def from_annotation_file(cls, file: IO[bytes]) -> 'MyExternalFormat': ... @classmethod def from_negative_file(cls, file: IO[bytes]) -> 'MyExternalFormat': ... def to_image_object_detection_instance(self) -> ImageObjectDetectionInstance: ... # Define your reader, which parses files into your external format class MyReader(Reader[MyExternalFormat]): # Returns an iterator of instances in the given file, in case a single file # contains multiple dataset items def read_annotation_file(self, filename: str) -> Iterator[MyExternalFormat]: with open(filename, \"rb\") as file: yield MyExternalFormat.from_annotation_file(file) # Returns an iterator of negative instances in the given file def read_negative_file(self, filename: str) -> Iterator[MyExternalFormat]: with open(filename, \"rb\") as file: yield MyExternalFormat.from_negative_file(file) # Define your input converter, which converts your external format into the domain of interest (image object-detection # in this example) class MyInputConverter(InputConverter[MyExternalFormat, ImageObjectDetectionInstance]): # Converts the instance from its external format to the domain format def convert(self, instance: MyExternalFormat) -> Iterator[ImageObjectDetectionInstance]: yield instance.to_image_object_detection_instance() # Create a specifier to advertise our input format to the plugin system class MyInputFormatSpecifier(InputFormatSpecifier): # The domain of the input format @classmethod def domain(cls) -> Type[ImageObjectDetectionDomainSpecifier]: return ImageObjectDetectionDomainSpecifier # The reader class we defined earlier @classmethod def reader(cls) -> Type[MyReader]: return MyReader # The input converter class we defined earlier @classmethod def input_converter(cls) -> Type[MyInputConverter]: return MyInputConverter Inline Stream Processors from typing import Iterable, Optional, Set, Type from wai.annotations.core.component import InlineStreamProcessor from wai.annotations.core.specifier import ISPSpecifier, DomainSpecifier from wai.annotations.domain.image.object_detection import ImageObjectDetectionDomainSpecifier # Get the instance type from the domain specifier ImageObjectDetectionInstance = ImageObjectDetectionDomainSpecifier.instance_class() # Define the ISP class MyISP(InlineStreamProcessor[ImageObjectDetectionInstance]): # Takes an instance from the conversion stream and processes it. Returns an iterable so that new # instances can be injected into the conversion stream, or removed from it def _process_element(self, element: ImageObjectDetectionInstance) -> Iterable[ImageObjectDetectionInstance]: ... # Advertise the ISP to the plugin system via a specifier class MyISPSpecifier(ISPSpecifier): # Specifies the domains this ISP can operate on. None indicates any domain, and a set indicates # a set of specific domains @classmethod def domains(cls) -> Optional[Set[Type[DomainSpecifier]]]: return {ImageObjectDetectionDomainSpecifier} # The actual ISP type we defined earlier @classmethod def processor_type(cls) -> Type[InlineStreamProcessor]: return MyISP Cross-Domain Converters from typing import Iterable, Type from wai.annotations.core.component import CrossDomainConverter from wai.annotations.core.specifier import XDCSpecifier, DomainSpecifier from wai.annotations.domain.image.classification import ImageClassificationDomainSpecifier from wai.annotations.domain.image.object_detection import ImageObjectDetectionDomainSpecifier # Get the instance types from the domain specifiers ImageClassificationInstance = ImageClassificationDomainSpecifier.instance_class() ImageObjectDetectionInstance = ImageObjectDetectionDomainSpecifier.instance_class() # Define your XDC, in this case converting from the image object-detection domain to # the image classification domain class MyXDC(CrossDomainConverter[ImageObjectDetectionInstance, ImageClassificationInstance]): # Convert the instance, returning an iterable again to allow insertion/deletion of instances def _convert_element(self, element: ImageObjectDetectionInstance) -> Iterable[ImageClassificationInstance]: ... # Define the specifier to advertise our new XDC to the plugin system class MyXDCSpecifier(XDCSpecifier): # Declare the input domain of the converter @classmethod def from_domain(cls) -> Type[DomainSpecifier]: return ImageObjectDetectionDomainSpecifier # Declare the output domain of the converter @classmethod def to_domain(cls) -> Type[DomainSpecifier]: return ImageClassificationDomainSpecifier # Advertise our XDC defined earlier @classmethod def converter(cls) -> Type[CrossDomainConverter]: return MyXDC Output Formats Output formats also consist of 2 components, a writer and an output-converter. The output-converter converts instances from the domain format to an arbitrary external format for the output format, and the writer writes the instances in that format to disk. An example of how to implement a new output-format: from typing import Iterator, IO, Type, Iterable from wai.annotations.core.component import Writer, OutputConverter from wai.annotations.core.instance import FileInfo from wai.annotations.core.specifier import OutputFormatSpecifier, DomainSpecifier from wai.annotations.domain.image.object_detection import ImageObjectDetectionDomainSpecifier # Get the instance type from the domain specifier ImageObjectDetectionInstance = ImageObjectDetectionDomainSpecifier.instance_class() # Define the external format in any way you like (if being used with an input format as well, define # separately and import) class MyExternalFormat: @classmethod def from_image_object_detection_instance(cls, instance: ImageObjectDetectionInstance) -> 'MyExternalFormat': ... # Define your writer, which writes instances of your external format to disk class MyWriter(Writer[MyExternalFormat]): # Depending on the external format, it might write all instances to a single file, # or each instance to its own file in a directory. Provide some helpful information # on which is the case here @classmethod def output_help_text(cls) -> str: ... # How to write the actual instances to disk def write(self, instances: Iterable[MyExternalFormat], path: str): ... # Whether the output option should be a file (if not, then it should be # a directory) def expects_file(self) -> bool: ... # Lets wai-annotations extract the file from your external format def extract_file_info_from_external_format(self, instance: MyExternalFormat) -> FileInfo: ... # Define your output converter, which converts instances from the format's domain (image object-detection # in this example) into your external format class MyOutputConverter(OutputConverter[ImageObjectDetectionInstance, MyExternalFormat]): # Converts the instance from the domain format into your external format def convert(self, instance: ImageObjectDetectionInstance) -> Iterator[MyExternalFormat]: yield MyExternalFormat.from_image_object_detection_instance(instance) # Create a specifier to advertise our output format to the plugin system class MyOutputFormatSpecifier(OutputFormatSpecifier): # Specify the domain the format is in @classmethod def domain(cls) -> Type[DomainSpecifier]: return ImageObjectDetectionDomainSpecifier # Specify the writer we declared earlier @classmethod def writer(cls) -> Type[Writer]: return MyWriter # Specify the output converter we declared earlier @classmethod def output_converter(cls) -> Type[OutputConverter]: return MyOutputConverter Best Practice Although in each of the examples shown here, we have defined our plugin specifiers in the same file as the components they advertise, this is not the recommended approach. The specifier types should instead be defined in their own sub-package, and the methods should locally import the specified types (instead of globally at the beginning of the specifier Python file). This is so the specifier can be imported into the plugin system without importing potentially heavy-weight libraries that the components depend on for their functionality. This way the system can provide reflection of the available plugins, but only load those plugins that are actually selected for use in a conversion. Advertising Plugins In order for wai-annotations to recognise your plugin, the specified needs to be advertised as an entry point in your setup script under the wai.annotations.plugins group: # setup.py from setuptools import setup setup( ..., entry_points={ \"wai.annotations.plugins\": [ # Input Formats \"from-my-input-format=com.example.specifiers:MyInputFormatSpecifier\", # Output Formats \"to-my-output-format=com.example.specifiers:MyOutputFormatSpecifier\", # ISPs \"my-isp=com.example.specifiers:MyISPSpecifier\", # XDCs \"my-xdc=com.example.specifiers:MyXDCSpecifier\" ] } ) Adding Command-Line Options to Plugin Components TODO","title":"Plugin guide"},{"location":"plugin/#adding-components-to-wai-annotations-through-plugins","text":"wai-annotations uses a plugin system to allow other libraries to add new processing components without modifying the base library source. This document details how to go about using this system.","title":"Adding components to wai-annotations through plugins"},{"location":"plugin/#plugin-types","text":"There are 4 types of components which can be added to wai-annotations via plugin: input formats, ISPs, XDCs and output formats. New domains can also be added, but these are specified indirectly via any of the previous components.","title":"Plugin Types"},{"location":"plugin/#domains","text":"New domains are added indirectly to wai-annotations as dependencies of components, as a domain which has no components is essentially unreachable to a conversion chain. However the specification of new domains is treated as a plugin-related issue, so it is detailed here. A domain is essentially the definition of an instance format, which contains both an item in the conversion dataset and the annotations attached to that item. The actual item in the dataset is represented by a FileInfo object, which contains the name of the item, and the binary data blob containing the item's file data. Domains need to specify a sub-class of FileInfo to represent the item and any additional data about it. The annotations for an instance can be any arbitrary type. To specify a new domain, a domain specifier must be created. This is achieved by importing the base classes from the core wai-annotations package and implementing the abstract methods. from typing import Type from wai.annotations.core.instance import FileInfo, Instance from wai.annotations.core.specifier import DomainSpecifier # Define the file-info type which holds dataset item data class MyFileInfo(FileInfo): @classmethod def from_file_data(cls, file_name: str, file_data: bytes) -> 'MyFileInfo': # If we don't need any additional information, or it is calculated in the init method return cls(file_name, file_data) # Define the type of annotations for the domain class MyAnnotations: ... # Define an instance type with additional functionality, if required class MyInstance(Instance[MyFileInfo, MyAnnotations]): def additional_method(self): ... # Define the domain specifier reporting the various classes for domain instances class MyDomainSpecifier(DomainSpecifier): @classmethod def domain_name(cls) -> str: return \"my domain\" @classmethod def file_type(cls) -> Type[MyFileInfo]: return MyFileInfo @classmethod def annotations_type(cls) -> Type[MyAnnotations]: return MyAnnotations # If our instances need additional functionality, we can override this method. The default is # wai.annotations.core.instance.Instance[cls.file_type(), cls.annotations_type()], and if we # do override this method, the type returned must inherit from this default type. @classmethod def instance_class(cls) -> Type[Instance]: return MyInstance","title":"Domains"},{"location":"plugin/#writing-new-components","text":"The base classes for components can be imported from wai-annotations' core package: from wai.annotations.core.component import Reader, InputConverter # For input formats from wai.annotations.core.component import InlineStreamProcessor # For ISPs from wai.annotations.core.component import CrossDomainConverter # For XDCs from wai.annotations.core.component import Writer, OutputConverter # For output formats Sub-class the base classes for the type of component you are trying to implement, and fill in the generic type-parameters and abstract methods. For generic type-parameters, component base classes vary on instance types, which are defined in the domain specifier for the domains the component operates in. Therefore the best way to specify the instance type-parameter is to import the domain specifiers for the domains of interest and use their instance_class() methods. For the abstract methods, each component has a few methods which require implementation. The purpose of each should be fairly self-explanatory, but the following examples will (hopefully) illustrate how to use each base class.","title":"Writing New Components"},{"location":"plugin/#input-formats","text":"Input formats consist of 2 components, a reader and an input-converter. The reader reads files from disk into an arbitrary format, and the input-converter converts that format into the instance format for the domain of the dataset. An example of how to implement a new input-format: from typing import Iterator, IO, Type from wai.annotations.core.component import Reader, InputConverter from wai.annotations.core.specifier import InputFormatSpecifier from wai.annotations.domain.image.object_detection import ImageObjectDetectionDomainSpecifier # Get the instance type from the domain specifier ImageObjectDetectionInstance = ImageObjectDetectionDomainSpecifier.instance_class() # Define the external format in any way you like (if being used with an output format as well, # define separately and import) class MyExternalFormat: @classmethod def from_annotation_file(cls, file: IO[bytes]) -> 'MyExternalFormat': ... @classmethod def from_negative_file(cls, file: IO[bytes]) -> 'MyExternalFormat': ... def to_image_object_detection_instance(self) -> ImageObjectDetectionInstance: ... # Define your reader, which parses files into your external format class MyReader(Reader[MyExternalFormat]): # Returns an iterator of instances in the given file, in case a single file # contains multiple dataset items def read_annotation_file(self, filename: str) -> Iterator[MyExternalFormat]: with open(filename, \"rb\") as file: yield MyExternalFormat.from_annotation_file(file) # Returns an iterator of negative instances in the given file def read_negative_file(self, filename: str) -> Iterator[MyExternalFormat]: with open(filename, \"rb\") as file: yield MyExternalFormat.from_negative_file(file) # Define your input converter, which converts your external format into the domain of interest (image object-detection # in this example) class MyInputConverter(InputConverter[MyExternalFormat, ImageObjectDetectionInstance]): # Converts the instance from its external format to the domain format def convert(self, instance: MyExternalFormat) -> Iterator[ImageObjectDetectionInstance]: yield instance.to_image_object_detection_instance() # Create a specifier to advertise our input format to the plugin system class MyInputFormatSpecifier(InputFormatSpecifier): # The domain of the input format @classmethod def domain(cls) -> Type[ImageObjectDetectionDomainSpecifier]: return ImageObjectDetectionDomainSpecifier # The reader class we defined earlier @classmethod def reader(cls) -> Type[MyReader]: return MyReader # The input converter class we defined earlier @classmethod def input_converter(cls) -> Type[MyInputConverter]: return MyInputConverter","title":"Input Formats"},{"location":"plugin/#inline-stream-processors","text":"from typing import Iterable, Optional, Set, Type from wai.annotations.core.component import InlineStreamProcessor from wai.annotations.core.specifier import ISPSpecifier, DomainSpecifier from wai.annotations.domain.image.object_detection import ImageObjectDetectionDomainSpecifier # Get the instance type from the domain specifier ImageObjectDetectionInstance = ImageObjectDetectionDomainSpecifier.instance_class() # Define the ISP class MyISP(InlineStreamProcessor[ImageObjectDetectionInstance]): # Takes an instance from the conversion stream and processes it. Returns an iterable so that new # instances can be injected into the conversion stream, or removed from it def _process_element(self, element: ImageObjectDetectionInstance) -> Iterable[ImageObjectDetectionInstance]: ... # Advertise the ISP to the plugin system via a specifier class MyISPSpecifier(ISPSpecifier): # Specifies the domains this ISP can operate on. None indicates any domain, and a set indicates # a set of specific domains @classmethod def domains(cls) -> Optional[Set[Type[DomainSpecifier]]]: return {ImageObjectDetectionDomainSpecifier} # The actual ISP type we defined earlier @classmethod def processor_type(cls) -> Type[InlineStreamProcessor]: return MyISP","title":"Inline Stream Processors"},{"location":"plugin/#cross-domain-converters","text":"from typing import Iterable, Type from wai.annotations.core.component import CrossDomainConverter from wai.annotations.core.specifier import XDCSpecifier, DomainSpecifier from wai.annotations.domain.image.classification import ImageClassificationDomainSpecifier from wai.annotations.domain.image.object_detection import ImageObjectDetectionDomainSpecifier # Get the instance types from the domain specifiers ImageClassificationInstance = ImageClassificationDomainSpecifier.instance_class() ImageObjectDetectionInstance = ImageObjectDetectionDomainSpecifier.instance_class() # Define your XDC, in this case converting from the image object-detection domain to # the image classification domain class MyXDC(CrossDomainConverter[ImageObjectDetectionInstance, ImageClassificationInstance]): # Convert the instance, returning an iterable again to allow insertion/deletion of instances def _convert_element(self, element: ImageObjectDetectionInstance) -> Iterable[ImageClassificationInstance]: ... # Define the specifier to advertise our new XDC to the plugin system class MyXDCSpecifier(XDCSpecifier): # Declare the input domain of the converter @classmethod def from_domain(cls) -> Type[DomainSpecifier]: return ImageObjectDetectionDomainSpecifier # Declare the output domain of the converter @classmethod def to_domain(cls) -> Type[DomainSpecifier]: return ImageClassificationDomainSpecifier # Advertise our XDC defined earlier @classmethod def converter(cls) -> Type[CrossDomainConverter]: return MyXDC","title":"Cross-Domain Converters"},{"location":"plugin/#output-formats","text":"Output formats also consist of 2 components, a writer and an output-converter. The output-converter converts instances from the domain format to an arbitrary external format for the output format, and the writer writes the instances in that format to disk. An example of how to implement a new output-format: from typing import Iterator, IO, Type, Iterable from wai.annotations.core.component import Writer, OutputConverter from wai.annotations.core.instance import FileInfo from wai.annotations.core.specifier import OutputFormatSpecifier, DomainSpecifier from wai.annotations.domain.image.object_detection import ImageObjectDetectionDomainSpecifier # Get the instance type from the domain specifier ImageObjectDetectionInstance = ImageObjectDetectionDomainSpecifier.instance_class() # Define the external format in any way you like (if being used with an input format as well, define # separately and import) class MyExternalFormat: @classmethod def from_image_object_detection_instance(cls, instance: ImageObjectDetectionInstance) -> 'MyExternalFormat': ... # Define your writer, which writes instances of your external format to disk class MyWriter(Writer[MyExternalFormat]): # Depending on the external format, it might write all instances to a single file, # or each instance to its own file in a directory. Provide some helpful information # on which is the case here @classmethod def output_help_text(cls) -> str: ... # How to write the actual instances to disk def write(self, instances: Iterable[MyExternalFormat], path: str): ... # Whether the output option should be a file (if not, then it should be # a directory) def expects_file(self) -> bool: ... # Lets wai-annotations extract the file from your external format def extract_file_info_from_external_format(self, instance: MyExternalFormat) -> FileInfo: ... # Define your output converter, which converts instances from the format's domain (image object-detection # in this example) into your external format class MyOutputConverter(OutputConverter[ImageObjectDetectionInstance, MyExternalFormat]): # Converts the instance from the domain format into your external format def convert(self, instance: ImageObjectDetectionInstance) -> Iterator[MyExternalFormat]: yield MyExternalFormat.from_image_object_detection_instance(instance) # Create a specifier to advertise our output format to the plugin system class MyOutputFormatSpecifier(OutputFormatSpecifier): # Specify the domain the format is in @classmethod def domain(cls) -> Type[DomainSpecifier]: return ImageObjectDetectionDomainSpecifier # Specify the writer we declared earlier @classmethod def writer(cls) -> Type[Writer]: return MyWriter # Specify the output converter we declared earlier @classmethod def output_converter(cls) -> Type[OutputConverter]: return MyOutputConverter","title":"Output Formats"},{"location":"plugin/#best-practice","text":"Although in each of the examples shown here, we have defined our plugin specifiers in the same file as the components they advertise, this is not the recommended approach. The specifier types should instead be defined in their own sub-package, and the methods should locally import the specified types (instead of globally at the beginning of the specifier Python file). This is so the specifier can be imported into the plugin system without importing potentially heavy-weight libraries that the components depend on for their functionality. This way the system can provide reflection of the available plugins, but only load those plugins that are actually selected for use in a conversion.","title":"Best Practice"},{"location":"plugin/#advertising-plugins","text":"In order for wai-annotations to recognise your plugin, the specified needs to be advertised as an entry point in your setup script under the wai.annotations.plugins group: # setup.py from setuptools import setup setup( ..., entry_points={ \"wai.annotations.plugins\": [ # Input Formats \"from-my-input-format=com.example.specifiers:MyInputFormatSpecifier\", # Output Formats \"to-my-output-format=com.example.specifiers:MyOutputFormatSpecifier\", # ISPs \"my-isp=com.example.specifiers:MyISPSpecifier\", # XDCs \"my-xdc=com.example.specifiers:MyXDCSpecifier\" ] } )","title":"Advertising Plugins"},{"location":"plugin/#adding-command-line-options-to-plugin-components","text":"TODO","title":"Adding Command-Line Options to Plugin Components"},{"location":"plugins/","text":"Plugins Source stage FROM-ADAMS-IC Reads image classification annotations in the ADAMS report-format Domain(s): Image Classification Domain Options: usage: from-adams-ic [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED] [-e FORMAT FORMAT FORMAT] -c FIELD optional arguments: -I FILENAME, --inputs-file FILENAME Files containing lists of input files (can use glob syntax) -i FILENAME, --input FILENAME Input files (can use glob syntax) -N FILENAME, --negatives-file FILENAME Files containing lists of negative files (can use glob syntax) -n FILENAME, --negative FILENAME Files that have no annotations (can use glob syntax) -o FILENAME, --output-file FILENAME optional file to write read filenames into --seed SEED the seed to use for randomisation -e FORMAT FORMAT FORMAT, --extensions FORMAT FORMAT FORMAT image format extensions in order of preference -c FIELD, --class-field FIELD the report field containing the image class FROM-ADAMS-OD Reads image object-detection annotations in the ADAMS report-format Domain(s): Image Object-Detection Domain Options: usage: from-adams-od [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED] [-e FORMAT FORMAT FORMAT] [-p PREFIXES [PREFIXES ...]] optional arguments: -I FILENAME, --inputs-file FILENAME Files containing lists of input files (can use glob syntax) -i FILENAME, --input FILENAME Input files (can use glob syntax) -N FILENAME, --negatives-file FILENAME Files containing lists of negative files (can use glob syntax) -n FILENAME, --negative FILENAME Files that have no annotations (can use glob syntax) -o FILENAME, --output-file FILENAME optional file to write read filenames into --seed SEED the seed to use for randomisation -e FORMAT FORMAT FORMAT, --extensions FORMAT FORMAT FORMAT image format extensions in order of preference -p PREFIXES [PREFIXES ...], --prefixes PREFIXES [PREFIXES ...] prefixes to parse FROM-BLUE-CHANNEL-IS Reads image segmentation files in the blue-channel format Domain(s): Image Segmentation Domain Options: usage: from-blue-channel-is [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED] [--image-path-rel PATH] --labels LABEL [LABEL ...] optional arguments: -I FILENAME, --inputs-file FILENAME Files containing lists of input files (can use glob syntax) -i FILENAME, --input FILENAME Input files (can use glob syntax) -N FILENAME, --negatives-file FILENAME Files containing lists of negative files (can use glob syntax) -n FILENAME, --negative FILENAME Files that have no annotations (can use glob syntax) -o FILENAME, --output-file FILENAME optional file to write read filenames into --seed SEED the seed to use for randomisation --image-path-rel PATH Relative path to image files from annotations --labels LABEL [LABEL ...] specifies the labels for each index FROM-COCO-OD Reads image object-detection annotations in the MS-COCO JSON-format Domain(s): Image Object-Detection Domain Options: usage: from-coco-od [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED] optional arguments: -I FILENAME, --inputs-file FILENAME Files containing lists of input files (can use glob syntax) -i FILENAME, --input FILENAME Input files (can use glob syntax) -N FILENAME, --negatives-file FILENAME Files containing lists of negative files (can use glob syntax) -n FILENAME, --negative FILENAME Files that have no annotations (can use glob syntax) -o FILENAME, --output-file FILENAME optional file to write read filenames into --seed SEED the seed to use for randomisation FROM-COMMON-VOICE-SP Reads speech transcriptions in the Mozilla Common-Voice TSV-format Domain(s): Speech Domain Options: usage: from-common-voice-sp [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED] [--rel-path REL_PATH] optional arguments: -I FILENAME, --inputs-file FILENAME Files containing lists of input files (can use glob syntax) -i FILENAME, --input FILENAME Input files (can use glob syntax) -N FILENAME, --negatives-file FILENAME Files containing lists of negative files (can use glob syntax) -n FILENAME, --negative FILENAME Files that have no annotations (can use glob syntax) -o FILENAME, --output-file FILENAME optional file to write read filenames into --seed SEED the seed to use for randomisation --rel-path REL_PATH the relative path from the annotations file to the audio files FROM-FESTVOX-SP Reads speech transcriptions in the Festival FestVox format Domain(s): Speech Domain Options: usage: from-festvox-sp [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED] [--rel-path REL_PATH] optional arguments: -I FILENAME, --inputs-file FILENAME Files containing lists of input files (can use glob syntax) -i FILENAME, --input FILENAME Input files (can use glob syntax) -N FILENAME, --negatives-file FILENAME Files containing lists of negative files (can use glob syntax) -n FILENAME, --negative FILENAME Files that have no annotations (can use glob syntax) -o FILENAME, --output-file FILENAME optional file to write read filenames into --seed SEED the seed to use for randomisation --rel-path REL_PATH the relative path from the annotations file to the audio files FROM-INDEXED-PNG-IS Reads image segmentation files in the indexed-PNG format Domain(s): Image Segmentation Domain Options: usage: from-indexed-png-is [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED] [--image-path-rel PATH] --labels LABEL [LABEL ...] optional arguments: -I FILENAME, --inputs-file FILENAME Files containing lists of input files (can use glob syntax) -i FILENAME, --input FILENAME Input files (can use glob syntax) -N FILENAME, --negatives-file FILENAME Files containing lists of negative files (can use glob syntax) -n FILENAME, --negative FILENAME Files that have no annotations (can use glob syntax) -o FILENAME, --output-file FILENAME optional file to write read filenames into --seed SEED the seed to use for randomisation --image-path-rel PATH Relative path to image files from annotations --labels LABEL [LABEL ...] specifies the labels for each index FROM-LAYER-SEGMENTS-IS Reads in the layer-segments image-segmentation format from disk, where each label has a binary PNG storing the mask for that label Domain(s): Image Segmentation Domain Options: usage: from-layer-segments-is [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED] [--label-separator SEPARATOR] --labels LABEL [LABEL ...] [--image-path-rel PATH] optional arguments: -I FILENAME, --inputs-file FILENAME Files containing lists of input files (can use glob syntax) -i FILENAME, --input FILENAME Input files (can use glob syntax) -N FILENAME, --negatives-file FILENAME Files containing lists of negative files (can use glob syntax) -n FILENAME, --negative FILENAME Files that have no annotations (can use glob syntax) -o FILENAME, --output-file FILENAME optional file to write read filenames into --seed SEED the seed to use for randomisation --label-separator SEPARATOR the separator between the base filename and the label --labels LABEL [LABEL ...] specifies the labels for each index --image-path-rel PATH Relative path to image files from annotations FROM-ROI-OD Reads image object-detection annotations in the ROI CSV-format Domain(s): Image Object-Detection Domain Options: usage: from-roi-od [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED] [-e FORMAT FORMAT FORMAT] [--prefix READER_PREFIX] [--suffix READER_SUFFIX] optional arguments: -I FILENAME, --inputs-file FILENAME Files containing lists of input files (can use glob syntax) -i FILENAME, --input FILENAME Input files (can use glob syntax) -N FILENAME, --negatives-file FILENAME Files containing lists of negative files (can use glob syntax) -n FILENAME, --negative FILENAME Files that have no annotations (can use glob syntax) -o FILENAME, --output-file FILENAME optional file to write read filenames into --seed SEED the seed to use for randomisation -e FORMAT FORMAT FORMAT, --extensions FORMAT FORMAT FORMAT image format extensions in order of preference --prefix READER_PREFIX the prefix for output filenames (default = '') --suffix READER_SUFFIX the suffix for output filenames (default = '-rois.csv') FROM-SUBDIR-IC Reads images from sub-directories named after their class labels. Domain(s): Image Classification Domain Options: usage: from-subdir-ic [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED] optional arguments: -I FILENAME, --inputs-file FILENAME Files containing lists of input files (can use glob syntax) -i FILENAME, --input FILENAME Input files (can use glob syntax) -N FILENAME, --negatives-file FILENAME Files containing lists of negative files (can use glob syntax) -n FILENAME, --negative FILENAME Files that have no annotations (can use glob syntax) -o FILENAME, --output-file FILENAME optional file to write read filenames into --seed SEED the seed to use for randomisation FROM-TF-OD Reads image object-detection annotations in the TFRecords binary format Domain(s): Image Object-Detection Domain Options: usage: from-tf-od [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED] [--mask-threshold THRESHOLD] [--sample-stride STRIDE] optional arguments: -I FILENAME, --inputs-file FILENAME Files containing lists of input files (can use glob syntax) -i FILENAME, --input FILENAME Input files (can use glob syntax) -N FILENAME, --negatives-file FILENAME Files containing lists of negative files (can use glob syntax) -n FILENAME, --negative FILENAME Files that have no annotations (can use glob syntax) -o FILENAME, --output-file FILENAME optional file to write read filenames into --seed SEED the seed to use for randomisation --mask-threshold THRESHOLD the threshold to use when calculating polygons from masks --sample-stride STRIDE the stride to use when calculating polygons from masks FROM-VGG-OD Reads image object-detection annotations in the VGG JSON-format Domain(s): Image Object-Detection Domain Options: usage: from-vgg-od [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED] optional arguments: -I FILENAME, --inputs-file FILENAME Files containing lists of input files (can use glob syntax) -i FILENAME, --input FILENAME Input files (can use glob syntax) -N FILENAME, --negatives-file FILENAME Files containing lists of negative files (can use glob syntax) -n FILENAME, --negative FILENAME Files that have no annotations (can use glob syntax) -o FILENAME, --output-file FILENAME optional file to write read filenames into --seed SEED the seed to use for randomisation FROM-VOC-OD Reads image object-detection annotations in the Pascal VOC XML-format Domain(s): Image Object-Detection Domain Options: usage: from-voc-od [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED] optional arguments: -I FILENAME, --inputs-file FILENAME Files containing lists of input files (can use glob syntax) -i FILENAME, --input FILENAME Input files (can use glob syntax) -N FILENAME, --negatives-file FILENAME Files containing lists of negative files (can use glob syntax) -n FILENAME, --negative FILENAME Files that have no annotations (can use glob syntax) -o FILENAME, --output-file FILENAME optional file to write read filenames into --seed SEED the seed to use for randomisation FROM-YOLO-OD Reads image object-detection annotations in the YOLO format Domain(s): Image Object-Detection Domain Options: usage: from-yolo-od [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED] [--image-path-rel PATH] [-l PATH] optional arguments: -I FILENAME, --inputs-file FILENAME Files containing lists of input files (can use glob syntax) -i FILENAME, --input FILENAME Input files (can use glob syntax) -N FILENAME, --negatives-file FILENAME Files containing lists of negative files (can use glob syntax) -n FILENAME, --negative FILENAME Files that have no annotations (can use glob syntax) -o FILENAME, --output-file FILENAME optional file to write read filenames into --seed SEED the seed to use for randomisation --image-path-rel PATH Relative path to image files from annotations -l PATH, --labels PATH Path to the labels file Processor stage CHECK-DUPLICATE-FILENAMES Causes the conversion stream to halt when multiple dataset items have the same filename Domain(s): Speech Domain Image Segmentation Domain Image Object-Detection Domain Image Classification Domain Options: usage: check-duplicate-filenames COERCE-BOX Converts all annotation bounds into box regions Domain(s): Image Object-Detection Domain Options: usage: coerce-box COERCE-MASK Converts all annotation bounds into polygon regions Domain(s): Image Object-Detection Domain Options: usage: coerce-mask CONVERT-IMAGE-FORMAT Converts images from one format to another Domain(s): Image Segmentation Domain Image Object-Detection Domain Image Classification Domain Options: usage: convert-image-format -f FORMAT optional arguments: -f FORMAT, --format FORMAT format to convert images to CROP Crops images. Domain(s): Image Object-Detection Domain Image Classification Domain Options: usage: crop [-m IMGAUG_MODE] [--suffix IMGAUG_SUFFIX] [-f PERCENT_FROM] [-t PERCENT_TO] [-s SEED] [-a] [-T THRESHOLD] [-u] optional arguments: -m IMGAUG_MODE, --mode IMGAUG_MODE the image augmentation mode to use, available modes: replace, add --suffix IMGAUG_SUFFIX the suffix to use for the file names in case of augmentation mode add -f PERCENT_FROM, --from-percent PERCENT_FROM the minimum percent to crop from images -t PERCENT_TO, --to-percent PERCENT_TO the maximum percent to crop from images -s SEED, --seed SEED the seed value to use for the random number generator; randomly seeded if not provided -a, --seed-augmentation whether to seed the augmentation; if specified, uses the seeded random generator to produce a seed value from 0 to 1000 for the augmentation. -T THRESHOLD, --threshold THRESHOLD the threshold to use for Random.rand(): if equal or above, augmentation gets applied; range: 0-1; default: 0 (= always) -u, --update-size whether to update the image size after the crop operation or scale back to original size DIMENSION-DISCARDER Removes annotations which fall outside certain size constraints Domain(s): Image Object-Detection Domain Options: usage: dimension-discarder [--max-area MAX_AREA] [--max-height MAX_HEIGHT] [--max-width MAX_WIDTH] [--min-area MIN_AREA] [--min-height MIN_HEIGHT] [--min-width MIN_WIDTH] [--verbose] optional arguments: --max-area MAX_AREA the maximum area of annotations to convert --max-height MAX_HEIGHT the maximum height of annotations to convert --max-width MAX_WIDTH the maximum width of annotations to convert --min-area MIN_AREA the minimum area of annotations to convert --min-height MIN_HEIGHT the minimum height of annotations to convert --min-width MIN_WIDTH the minimum width of annotations to convert --verbose outputs information when discarding annotations DISCARD-NEGATIVES Discards negative examples (those without annotations) from the stream Domain(s): Speech Domain Image Segmentation Domain Image Object-Detection Domain Image Classification Domain Options: usage: discard-negatives FILTER-LABELS Filters detected objects down to those with specified labels. Domain(s): Image Object-Detection Domain Options: usage: filter-labels [-l LABELS [LABELS ...]] [-r regexp] optional arguments: -l LABELS [LABELS ...], --labels LABELS [LABELS ...] labels to use -r regexp, --regexp regexp regular expression for using only a subset of labels FLIP Flips images either left-to-right, up-to-down or both. Domain(s): Image Object-Detection Domain Image Classification Domain Options: usage: flip [-d DIRECTION] [-m IMGAUG_MODE] [--suffix IMGAUG_SUFFIX] [-s SEED] [-a] [-T THRESHOLD] optional arguments: -d DIRECTION, --direction DIRECTION the direction to flip, available options: lr, up, lrup -m IMGAUG_MODE, --mode IMGAUG_MODE the image augmentation mode to use, available modes: replace, add --suffix IMGAUG_SUFFIX the suffix to use for the file names in case of augmentation mode add -s SEED, --seed SEED the seed value to use for the random number generator; randomly seeded if not provided -a, --seed-augmentation whether to seed the augmentation; if specified, uses the seeded random generator to produce a seed value from 0 to 1000 for the augmentation. -T THRESHOLD, --threshold THRESHOLD the threshold to use for Random.rand(): if equal or above, augmentation gets applied; range: 0-1; default: 0 (= always) GAUSSIAN-BLUR Applies gaussian blur to images. Domain(s): Image Object-Detection Domain Image Classification Domain Options: usage: gaussian-blur [-m IMGAUG_MODE] [--suffix IMGAUG_SUFFIX] [-s SEED] [-a] [-f SIGMA_FROM] [-t SIGMA_TO] [-T THRESHOLD] optional arguments: -m IMGAUG_MODE, --mode IMGAUG_MODE the image augmentation mode to use, available modes: replace, add --suffix IMGAUG_SUFFIX the suffix to use for the file names in case of augmentation mode add -s SEED, --seed SEED the seed value to use for the random number generator; randomly seeded if not provided -a, --seed-augmentation whether to seed the augmentation; if specified, uses the seeded random generator to produce a seed value from 0 to 1000 for the augmentation. -f SIGMA_FROM, --from-sigma SIGMA_FROM the minimum sigma for the blur to apply to the images -t SIGMA_TO, --to-sigma SIGMA_TO the maximum sigma for the blur to apply to the images -T THRESHOLD, --threshold THRESHOLD the threshold to use for Random.rand(): if equal or above, augmentation gets applied; range: 0-1; default: 0 (= always) HSL-GRAYSCALE Turns RGB images into fake grayscale ones by converting them to HSL and then using the L channel for all channels. The brightness can be influenced and varied even. Domain(s): Image Object-Detection Domain Image Classification Domain Options: usage: hsl-grayscale [-f FACTOR_FROM] [-t FACTOR_TO] [-m IMGAUG_MODE] [--suffix IMGAUG_SUFFIX] [-s SEED] [-a] [-T THRESHOLD] optional arguments: -f FACTOR_FROM, --from-factor FACTOR_FROM the start of the factor range to apply to the L channel to darken or lighten the image (<1: darker, >1: lighter) -t FACTOR_TO, --to-factor FACTOR_TO the end of the factor range to apply to the L channel to darken or lighten the image (<1: darker, >1: lighter) -m IMGAUG_MODE, --mode IMGAUG_MODE the image augmentation mode to use, available modes: replace, add --suffix IMGAUG_SUFFIX the suffix to use for the file names in case of augmentation mode add -s SEED, --seed SEED the seed value to use for the random number generator; randomly seeded if not provided -a, --seed-augmentation whether to seed the augmentation; if specified, uses the seeded random generator to produce a seed value from 0 to 1000 for the augmentation. -T THRESHOLD, --threshold THRESHOLD the threshold to use for Random.rand(): if equal or above, augmentation gets applied; range: 0-1; default: 0 (= always) LINEAR-CONTRAST Applies linear contrast to images. Domain(s): Image Object-Detection Domain Image Classification Domain Options: usage: linear-contrast [-f ALPHA_FROM] [-t ALPHA_TO] [-m IMGAUG_MODE] [--suffix IMGAUG_SUFFIX] [-s SEED] [-a] [-T THRESHOLD] optional arguments: -f ALPHA_FROM, --from-alpha ALPHA_FROM the minimum alpha to apply to the images -t ALPHA_TO, --to-alpha ALPHA_TO the maximum alpha to apply to the images -m IMGAUG_MODE, --mode IMGAUG_MODE the image augmentation mode to use, available modes: replace, add --suffix IMGAUG_SUFFIX the suffix to use for the file names in case of augmentation mode add -s SEED, --seed SEED the seed value to use for the random number generator; randomly seeded if not provided -a, --seed-augmentation whether to seed the augmentation; if specified, uses the seeded random generator to produce a seed value from 0 to 1000 for the augmentation. -T THRESHOLD, --threshold THRESHOLD the threshold to use for Random.rand(): if equal or above, augmentation gets applied; range: 0-1; default: 0 (= always) MAP-LABELS Maps object-detection labels from one set to another Domain(s): Image Object-Detection Domain Options: usage: map-labels [-m old=new] optional arguments: -m old=new, --mapping old=new mapping for labels, for replacing one label string with another (eg when fixing/collapsing labels) OD-TO-IC Converts image object-detection instances into image classification instances Domain(s): Image Object-Detection Domain Options: usage: od-to-ic [-m HANDLER] optional arguments: -m HANDLER, --multiplicity HANDLER how to handle instances with more than one located object OD-TO-IS Converts image object-detection instances into image segmentation instances Domain(s): Image Object-Detection Domain Options: usage: od-to-is [--label-error] --labels LABEL [LABEL ...] optional arguments: --label-error whether to raise errors when an unspecified label is encountered (default is to ignore) --labels LABEL [LABEL ...] specifies the labels for each index PASSTHROUGH Dummy ISP which has no effect on the conversion stream Domain(s): Speech Domain Image Segmentation Domain Image Object-Detection Domain Image Classification Domain Options: usage: passthrough POLYGON-DISCARDER Removes annotations with polygons which fall outside certain point limit constraints Domain(s): Image Object-Detection Domain Options: usage: polygon-discarder [--max-points MAX_POINTS] [--min-points MIN_POINTS] [--verbose] optional arguments: --max-points MAX_POINTS the maximum number of points in the polygon --min-points MIN_POINTS the minimum number of points in the polygon --verbose outputs information when discarding annotations REMOVE-CLASSES Removes classes from classification/image-segmentation instances Domain(s): Image Segmentation Domain Image Classification Domain Options: usage: remove-classes -c CLASS [CLASS ...] optional arguments: -c CLASS [CLASS ...], --classes CLASS [CLASS ...] the classes to remove ROTATE Rotates images randomly within a range of degrees or by a specified degree. Specify seed value and force augmentation to be seeded to generate repeatable augmentations. Domain(s): Image Object-Detection Domain Image Classification Domain Options: usage: rotate [-f DEGREE_FROM] [-t DEGREE_TO] [-m IMGAUG_MODE] [--suffix IMGAUG_SUFFIX] [-s SEED] [-a] [-T THRESHOLD] optional arguments: -f DEGREE_FROM, --from-degree DEGREE_FROM the start of the degree range to use for rotating the images -t DEGREE_TO, --to-degree DEGREE_TO the end of the degree range to use for rotating the images -m IMGAUG_MODE, --mode IMGAUG_MODE the image augmentation mode to use, available modes: replace, add --suffix IMGAUG_SUFFIX the suffix to use for the file names in case of augmentation mode add -s SEED, --seed SEED the seed value to use for the random number generator; randomly seeded if not provided -a, --seed-augmentation whether to seed the augmentation; if specified, uses the seeded random generator to produce a seed value from 0 to 1000 for the augmentation. -T THRESHOLD, --threshold THRESHOLD the threshold to use for Random.rand(): if equal or above, augmentation gets applied; range: 0-1; default: 0 (= always) SCALE Scales images randomly within a range of percentages or by a specified percentage. Specify seed value and force augmentation to be seeded to generate repeatable augmentations. Domain(s): Image Object-Detection Domain Image Classification Domain Options: usage: scale [-m IMGAUG_MODE] [--suffix IMGAUG_SUFFIX] [-k] [-f PERCENTAGE_FROM] [-t PERCENTAGE_TO] [-s SEED] [-a] [-T THRESHOLD] [-u] optional arguments: -m IMGAUG_MODE, --mode IMGAUG_MODE the image augmentation mode to use, available modes: replace, add --suffix IMGAUG_SUFFIX the suffix to use for the file names in case of augmentation mode add -k, --keep-aspect whether to keep the aspect ratio -f PERCENTAGE_FROM, --from-percentage PERCENTAGE_FROM the start of the percentage range to use for scaling the images -t PERCENTAGE_TO, --to-percentage PERCENTAGE_TO the end of the percentage range to use for scaling the images -s SEED, --seed SEED the seed value to use for the random number generator; randomly seeded if not provided -a, --seed-augmentation whether to seed the augmentation; if specified, uses the seeded random generator to produce a seed value from 0 to 1000 for the augmentation. -T THRESHOLD, --threshold THRESHOLD the threshold to use for Random.rand(): if equal or above, augmentation gets applied; range: 0-1; default: 0 (= always) -u, --update-size whether to update the image size after the scaling operation or use original size STRIP-ANNOTATIONS ISP which removes annotations from instances Domain(s): Speech Domain Image Segmentation Domain Image Object-Detection Domain Image Classification Domain Options: usage: strip-annotations Sink stage TO-ADAMS-IC Writes image classification annotations in the ADAMS report-format Domain(s): Image Classification Domain Options: usage: to-adams-ic -c FIELD [--annotations-only] -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]] optional arguments: -c FIELD, --class-field FIELD the report field containing the image class --annotations-only skip the writing of data files, outputting only the annotation files -o PATH, --output PATH output directory to write files to --split-names SPLIT NAME [SPLIT NAME ...] the names to use for the splits --split-ratios RATIO [RATIO ...] the ratios to use for the splits TO-ADAMS-OD Writes image object-detection annotations in the ADAMS report-format Domain(s): Image Object-Detection Domain Options: usage: to-adams-od [--annotations-only] -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]] optional arguments: --annotations-only skip the writing of data files, outputting only the annotation files -o PATH, --output PATH output directory to write files to --split-names SPLIT NAME [SPLIT NAME ...] the names to use for the splits --split-ratios RATIO [RATIO ...] the ratios to use for the splits TO-BLUE-CHANNEL-IS Writes image segmentation files in the blue-channel format Domain(s): Image Segmentation Domain Options: usage: to-blue-channel-is [--annotations-only] -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]] optional arguments: --annotations-only skip the writing of data files, outputting only the annotation files -o PATH, --output PATH the directory to write the annotation images to --split-names SPLIT NAME [SPLIT NAME ...] the names to use for the splits --split-ratios RATIO [RATIO ...] the ratios to use for the splits TO-COCO-OD Writes image object-detection annotations in the MS-COCO JSON-format Domain(s): Image Object-Detection Domain Options: usage: to-coco-od [--annotations-only] [--categories CATEGORY [CATEGORY ...]] [--category-output-file FILENAME] [--default-supercategory SUPERCATEGORY] [--error-on-new-category] [--license-name LICENSE_NAME] [--license-url LICENSE_URL] -o PATH [--pretty] [--sort-categories] [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]] optional arguments: --annotations-only skip the writing of data files, outputting only the annotation files --categories CATEGORY [CATEGORY ...] defines the order of the categories --category-output-file FILENAME file to write the categories into, as a simple comma-separated list --default-supercategory SUPERCATEGORY the supercategory to use for pre-defined categories --error-on-new-category whether unspecified categories should raise an error --license-name LICENSE_NAME the license of the images --license-url LICENSE_URL the license of the images -o PATH, --output PATH output file to write annotations to (images are placed in same directory) --pretty whether to format the JSON annotations file with indentation --sort-categories whether to put the categories in alphabetical order --split-names SPLIT NAME [SPLIT NAME ...] the names to use for the splits --split-ratios RATIO [RATIO ...] the ratios to use for the splits TO-COMMON-VOICE-SP Writes speech transcriptions in the Mozilla Common-Voice TSV-format Domain(s): Speech Domain Options: usage: to-common-voice-sp [--annotations-only] -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]] optional arguments: --annotations-only skip the writing of data files, outputting only the annotation files -o PATH, --output PATH the filename of the TSV file to write the annotations into --split-names SPLIT NAME [SPLIT NAME ...] the names to use for the splits --split-ratios RATIO [RATIO ...] the ratios to use for the splits TO-FESTVOX-SP Writes speech transcriptions in the Festival FestVox format Domain(s): Speech Domain Options: usage: to-festvox-sp [--annotations-only] -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]] optional arguments: --annotations-only skip the writing of data files, outputting only the annotation files -o PATH, --output PATH the filename of the FestVox file to write the annotations into --split-names SPLIT NAME [SPLIT NAME ...] the names to use for the splits --split-ratios RATIO [RATIO ...] the ratios to use for the splits TO-INDEXED-PNG-IS Writes image segmentation files in the indexed-PNG format Domain(s): Image Segmentation Domain Options: usage: to-indexed-png-is [--annotations-only] -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]] optional arguments: --annotations-only skip the writing of data files, outputting only the annotation files -o PATH, --output PATH the directory to write the annotation images to --split-names SPLIT NAME [SPLIT NAME ...] the names to use for the splits --split-ratios RATIO [RATIO ...] the ratios to use for the splits TO-LAYER-SEGMENTS-IS Writes the layer-segments image-segmentation format to disk Domain(s): Image Segmentation Domain Options: usage: to-layer-segments-is [--annotations-only] [--label-separator SEPARATOR] -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]] optional arguments: --annotations-only skip the writing of data files, outputting only the annotation files --label-separator SEPARATOR the separator between the base filename and the label -o PATH, --output PATH the directory to write the annotation images to --split-names SPLIT NAME [SPLIT NAME ...] the names to use for the splits --split-ratios RATIO [RATIO ...] the ratios to use for the splits TO-ROI-OD Writes image object-detection annotations in the ROI CSV-format Domain(s): Image Object-Detection Domain Options: usage: to-roi-od [-d WIDTH HEIGHT] [--annotations-only] [--comments COMMENTS [COMMENTS ...]] -o PATH [--size-mode] [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]] [--prefix WRITER_PREFIX] [--suffix WRITER_SUFFIX] optional arguments: -d WIDTH HEIGHT, --image-dimensions WIDTH HEIGHT image dimensions to use if none can be inferred --annotations-only skip the writing of data files, outputting only the annotation files --comments COMMENTS [COMMENTS ...] comments to write to the beginning of the ROI file -o PATH, --output PATH output directory to write files to --size-mode writes the ROI files with x,y,w,h headers instead of x0,y0,x1,y1 --split-names SPLIT NAME [SPLIT NAME ...] the names to use for the splits --split-ratios RATIO [RATIO ...] the ratios to use for the splits --prefix WRITER_PREFIX the prefix for output filenames (default = '') --suffix WRITER_SUFFIX the suffix for output filenames (default = '-rois.csv') TO-SUBDIR-IC Writes images to sub-directories named after their class labels. Domain(s): Image Classification Domain Options: usage: to-subdir-ic -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]] optional arguments: -o PATH, --output PATH the directory to store the class directories in --split-names SPLIT NAME [SPLIT NAME ...] the names to use for the splits --split-ratios RATIO [RATIO ...] the ratios to use for the splits TO-TF-OD Writes image object-detection annotations in the TFRecords binary format Domain(s): Image Object-Detection Domain Options: usage: to-tf-od [--dense] [--source-id-type {filename,numeric-dummy}] -o PATH [-p FILENAME] [-s FILENAME [FILENAME ...]] [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]] optional arguments: --dense outputs masks in the dense numerical format instead of PNG-encoded --source-id-type {filename,numeric-dummy} by default, the filename gets stored in the 'source_id' field, but some algorithms try to convert it into a number and fail with 'StringToNumberOp could not correctly convert string'; in which case you can use 'numeric-dummy' (see https://github.com/google/automl/issues/307) -o PATH, --output PATH name of output file for TFRecords -p FILENAME, --protobuf FILENAME for storing the label strings and IDs -s FILENAME [FILENAME ...], --shards FILENAME [FILENAME ...] additional shards to write to --split-names SPLIT NAME [SPLIT NAME ...] the names to use for the splits --split-ratios RATIO [RATIO ...] the ratios to use for the splits TO-VGG-OD Writes image object-detection annotations in the VGG JSON-format Domain(s): Image Object-Detection Domain Options: usage: to-vgg-od [--annotations-only] -o PATH [--pretty] [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]] optional arguments: --annotations-only skip the writing of data files, outputting only the annotation files -o PATH, --output PATH output file to write annotations to (images are placed in same directory) --pretty whether to format the JSON annotations file with indentation --split-names SPLIT NAME [SPLIT NAME ...] the names to use for the splits --split-ratios RATIO [RATIO ...] the ratios to use for the splits TO-VOC-OD Writes image object-detection annotations in the Pascal VOC XML-format Domain(s): Image Object-Detection Domain Options: usage: to-voc-od [--annotations-only] -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]] optional arguments: --annotations-only skip the writing of data files, outputting only the annotation files -o PATH, --output PATH output directory to write annotations to (images are placed in same directory) --split-names SPLIT NAME [SPLIT NAME ...] the names to use for the splits --split-ratios RATIO [RATIO ...] the ratios to use for the splits TO-VOID-IC Consumes instances without writing them. Domain(s): Image Classification Domain Options: usage: to-void-ic TO-VOID-IS Consumes instances without writing them. Domain(s): Image Segmentation Domain Options: usage: to-void-is TO-VOID-OD Consumes instances without writing them. Domain(s): Image Object-Detection Domain Options: usage: to-void-od TO-VOID-SP Consumes instances without writing them. Domain(s): Speech Domain Options: usage: to-void-sp TO-YOLO-OD Writes image object-detection annotations in the YOLO format Domain(s): Image Object-Detection Domain Options: usage: to-yolo-od [-c PATH] [-l PATH] [--annotations-only] -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]] optional arguments: -c PATH, --labels-csv PATH Path to the labels CSV file to write -l PATH, --labels PATH Path to the labels file to write --annotations-only skip the writing of data files, outputting only the annotation files -o PATH, --output PATH output directory to write images and annotations to --split-names SPLIT NAME [SPLIT NAME ...] the names to use for the splits --split-ratios RATIO [RATIO ...] the ratios to use for the splits","title":"Plugins"},{"location":"plugins/#plugins","text":"","title":"Plugins"},{"location":"plugins/#source-stage","text":"","title":"Source stage"},{"location":"plugins/#from-adams-ic","text":"Reads image classification annotations in the ADAMS report-format","title":"FROM-ADAMS-IC"},{"location":"plugins/#domains","text":"Image Classification Domain","title":"Domain(s):"},{"location":"plugins/#options","text":"usage: from-adams-ic [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED] [-e FORMAT FORMAT FORMAT] -c FIELD optional arguments: -I FILENAME, --inputs-file FILENAME Files containing lists of input files (can use glob syntax) -i FILENAME, --input FILENAME Input files (can use glob syntax) -N FILENAME, --negatives-file FILENAME Files containing lists of negative files (can use glob syntax) -n FILENAME, --negative FILENAME Files that have no annotations (can use glob syntax) -o FILENAME, --output-file FILENAME optional file to write read filenames into --seed SEED the seed to use for randomisation -e FORMAT FORMAT FORMAT, --extensions FORMAT FORMAT FORMAT image format extensions in order of preference -c FIELD, --class-field FIELD the report field containing the image class","title":"Options:"},{"location":"plugins/#from-adams-od","text":"Reads image object-detection annotations in the ADAMS report-format","title":"FROM-ADAMS-OD"},{"location":"plugins/#domains_1","text":"Image Object-Detection Domain","title":"Domain(s):"},{"location":"plugins/#options_1","text":"usage: from-adams-od [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED] [-e FORMAT FORMAT FORMAT] [-p PREFIXES [PREFIXES ...]] optional arguments: -I FILENAME, --inputs-file FILENAME Files containing lists of input files (can use glob syntax) -i FILENAME, --input FILENAME Input files (can use glob syntax) -N FILENAME, --negatives-file FILENAME Files containing lists of negative files (can use glob syntax) -n FILENAME, --negative FILENAME Files that have no annotations (can use glob syntax) -o FILENAME, --output-file FILENAME optional file to write read filenames into --seed SEED the seed to use for randomisation -e FORMAT FORMAT FORMAT, --extensions FORMAT FORMAT FORMAT image format extensions in order of preference -p PREFIXES [PREFIXES ...], --prefixes PREFIXES [PREFIXES ...] prefixes to parse","title":"Options:"},{"location":"plugins/#from-blue-channel-is","text":"Reads image segmentation files in the blue-channel format","title":"FROM-BLUE-CHANNEL-IS"},{"location":"plugins/#domains_2","text":"Image Segmentation Domain","title":"Domain(s):"},{"location":"plugins/#options_2","text":"usage: from-blue-channel-is [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED] [--image-path-rel PATH] --labels LABEL [LABEL ...] optional arguments: -I FILENAME, --inputs-file FILENAME Files containing lists of input files (can use glob syntax) -i FILENAME, --input FILENAME Input files (can use glob syntax) -N FILENAME, --negatives-file FILENAME Files containing lists of negative files (can use glob syntax) -n FILENAME, --negative FILENAME Files that have no annotations (can use glob syntax) -o FILENAME, --output-file FILENAME optional file to write read filenames into --seed SEED the seed to use for randomisation --image-path-rel PATH Relative path to image files from annotations --labels LABEL [LABEL ...] specifies the labels for each index","title":"Options:"},{"location":"plugins/#from-coco-od","text":"Reads image object-detection annotations in the MS-COCO JSON-format","title":"FROM-COCO-OD"},{"location":"plugins/#domains_3","text":"Image Object-Detection Domain","title":"Domain(s):"},{"location":"plugins/#options_3","text":"usage: from-coco-od [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED] optional arguments: -I FILENAME, --inputs-file FILENAME Files containing lists of input files (can use glob syntax) -i FILENAME, --input FILENAME Input files (can use glob syntax) -N FILENAME, --negatives-file FILENAME Files containing lists of negative files (can use glob syntax) -n FILENAME, --negative FILENAME Files that have no annotations (can use glob syntax) -o FILENAME, --output-file FILENAME optional file to write read filenames into --seed SEED the seed to use for randomisation","title":"Options:"},{"location":"plugins/#from-common-voice-sp","text":"Reads speech transcriptions in the Mozilla Common-Voice TSV-format","title":"FROM-COMMON-VOICE-SP"},{"location":"plugins/#domains_4","text":"Speech Domain","title":"Domain(s):"},{"location":"plugins/#options_4","text":"usage: from-common-voice-sp [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED] [--rel-path REL_PATH] optional arguments: -I FILENAME, --inputs-file FILENAME Files containing lists of input files (can use glob syntax) -i FILENAME, --input FILENAME Input files (can use glob syntax) -N FILENAME, --negatives-file FILENAME Files containing lists of negative files (can use glob syntax) -n FILENAME, --negative FILENAME Files that have no annotations (can use glob syntax) -o FILENAME, --output-file FILENAME optional file to write read filenames into --seed SEED the seed to use for randomisation --rel-path REL_PATH the relative path from the annotations file to the audio files","title":"Options:"},{"location":"plugins/#from-festvox-sp","text":"Reads speech transcriptions in the Festival FestVox format","title":"FROM-FESTVOX-SP"},{"location":"plugins/#domains_5","text":"Speech Domain","title":"Domain(s):"},{"location":"plugins/#options_5","text":"usage: from-festvox-sp [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED] [--rel-path REL_PATH] optional arguments: -I FILENAME, --inputs-file FILENAME Files containing lists of input files (can use glob syntax) -i FILENAME, --input FILENAME Input files (can use glob syntax) -N FILENAME, --negatives-file FILENAME Files containing lists of negative files (can use glob syntax) -n FILENAME, --negative FILENAME Files that have no annotations (can use glob syntax) -o FILENAME, --output-file FILENAME optional file to write read filenames into --seed SEED the seed to use for randomisation --rel-path REL_PATH the relative path from the annotations file to the audio files","title":"Options:"},{"location":"plugins/#from-indexed-png-is","text":"Reads image segmentation files in the indexed-PNG format","title":"FROM-INDEXED-PNG-IS"},{"location":"plugins/#domains_6","text":"Image Segmentation Domain","title":"Domain(s):"},{"location":"plugins/#options_6","text":"usage: from-indexed-png-is [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED] [--image-path-rel PATH] --labels LABEL [LABEL ...] optional arguments: -I FILENAME, --inputs-file FILENAME Files containing lists of input files (can use glob syntax) -i FILENAME, --input FILENAME Input files (can use glob syntax) -N FILENAME, --negatives-file FILENAME Files containing lists of negative files (can use glob syntax) -n FILENAME, --negative FILENAME Files that have no annotations (can use glob syntax) -o FILENAME, --output-file FILENAME optional file to write read filenames into --seed SEED the seed to use for randomisation --image-path-rel PATH Relative path to image files from annotations --labels LABEL [LABEL ...] specifies the labels for each index","title":"Options:"},{"location":"plugins/#from-layer-segments-is","text":"Reads in the layer-segments image-segmentation format from disk, where each label has a binary PNG storing the mask for that label","title":"FROM-LAYER-SEGMENTS-IS"},{"location":"plugins/#domains_7","text":"Image Segmentation Domain","title":"Domain(s):"},{"location":"plugins/#options_7","text":"usage: from-layer-segments-is [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED] [--label-separator SEPARATOR] --labels LABEL [LABEL ...] [--image-path-rel PATH] optional arguments: -I FILENAME, --inputs-file FILENAME Files containing lists of input files (can use glob syntax) -i FILENAME, --input FILENAME Input files (can use glob syntax) -N FILENAME, --negatives-file FILENAME Files containing lists of negative files (can use glob syntax) -n FILENAME, --negative FILENAME Files that have no annotations (can use glob syntax) -o FILENAME, --output-file FILENAME optional file to write read filenames into --seed SEED the seed to use for randomisation --label-separator SEPARATOR the separator between the base filename and the label --labels LABEL [LABEL ...] specifies the labels for each index --image-path-rel PATH Relative path to image files from annotations","title":"Options:"},{"location":"plugins/#from-roi-od","text":"Reads image object-detection annotations in the ROI CSV-format","title":"FROM-ROI-OD"},{"location":"plugins/#domains_8","text":"Image Object-Detection Domain","title":"Domain(s):"},{"location":"plugins/#options_8","text":"usage: from-roi-od [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED] [-e FORMAT FORMAT FORMAT] [--prefix READER_PREFIX] [--suffix READER_SUFFIX] optional arguments: -I FILENAME, --inputs-file FILENAME Files containing lists of input files (can use glob syntax) -i FILENAME, --input FILENAME Input files (can use glob syntax) -N FILENAME, --negatives-file FILENAME Files containing lists of negative files (can use glob syntax) -n FILENAME, --negative FILENAME Files that have no annotations (can use glob syntax) -o FILENAME, --output-file FILENAME optional file to write read filenames into --seed SEED the seed to use for randomisation -e FORMAT FORMAT FORMAT, --extensions FORMAT FORMAT FORMAT image format extensions in order of preference --prefix READER_PREFIX the prefix for output filenames (default = '') --suffix READER_SUFFIX the suffix for output filenames (default = '-rois.csv')","title":"Options:"},{"location":"plugins/#from-subdir-ic","text":"Reads images from sub-directories named after their class labels.","title":"FROM-SUBDIR-IC"},{"location":"plugins/#domains_9","text":"Image Classification Domain","title":"Domain(s):"},{"location":"plugins/#options_9","text":"usage: from-subdir-ic [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED] optional arguments: -I FILENAME, --inputs-file FILENAME Files containing lists of input files (can use glob syntax) -i FILENAME, --input FILENAME Input files (can use glob syntax) -N FILENAME, --negatives-file FILENAME Files containing lists of negative files (can use glob syntax) -n FILENAME, --negative FILENAME Files that have no annotations (can use glob syntax) -o FILENAME, --output-file FILENAME optional file to write read filenames into --seed SEED the seed to use for randomisation","title":"Options:"},{"location":"plugins/#from-tf-od","text":"Reads image object-detection annotations in the TFRecords binary format","title":"FROM-TF-OD"},{"location":"plugins/#domains_10","text":"Image Object-Detection Domain","title":"Domain(s):"},{"location":"plugins/#options_10","text":"usage: from-tf-od [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED] [--mask-threshold THRESHOLD] [--sample-stride STRIDE] optional arguments: -I FILENAME, --inputs-file FILENAME Files containing lists of input files (can use glob syntax) -i FILENAME, --input FILENAME Input files (can use glob syntax) -N FILENAME, --negatives-file FILENAME Files containing lists of negative files (can use glob syntax) -n FILENAME, --negative FILENAME Files that have no annotations (can use glob syntax) -o FILENAME, --output-file FILENAME optional file to write read filenames into --seed SEED the seed to use for randomisation --mask-threshold THRESHOLD the threshold to use when calculating polygons from masks --sample-stride STRIDE the stride to use when calculating polygons from masks","title":"Options:"},{"location":"plugins/#from-vgg-od","text":"Reads image object-detection annotations in the VGG JSON-format","title":"FROM-VGG-OD"},{"location":"plugins/#domains_11","text":"Image Object-Detection Domain","title":"Domain(s):"},{"location":"plugins/#options_11","text":"usage: from-vgg-od [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED] optional arguments: -I FILENAME, --inputs-file FILENAME Files containing lists of input files (can use glob syntax) -i FILENAME, --input FILENAME Input files (can use glob syntax) -N FILENAME, --negatives-file FILENAME Files containing lists of negative files (can use glob syntax) -n FILENAME, --negative FILENAME Files that have no annotations (can use glob syntax) -o FILENAME, --output-file FILENAME optional file to write read filenames into --seed SEED the seed to use for randomisation","title":"Options:"},{"location":"plugins/#from-voc-od","text":"Reads image object-detection annotations in the Pascal VOC XML-format","title":"FROM-VOC-OD"},{"location":"plugins/#domains_12","text":"Image Object-Detection Domain","title":"Domain(s):"},{"location":"plugins/#options_12","text":"usage: from-voc-od [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED] optional arguments: -I FILENAME, --inputs-file FILENAME Files containing lists of input files (can use glob syntax) -i FILENAME, --input FILENAME Input files (can use glob syntax) -N FILENAME, --negatives-file FILENAME Files containing lists of negative files (can use glob syntax) -n FILENAME, --negative FILENAME Files that have no annotations (can use glob syntax) -o FILENAME, --output-file FILENAME optional file to write read filenames into --seed SEED the seed to use for randomisation","title":"Options:"},{"location":"plugins/#from-yolo-od","text":"Reads image object-detection annotations in the YOLO format","title":"FROM-YOLO-OD"},{"location":"plugins/#domains_13","text":"Image Object-Detection Domain","title":"Domain(s):"},{"location":"plugins/#options_13","text":"usage: from-yolo-od [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED] [--image-path-rel PATH] [-l PATH] optional arguments: -I FILENAME, --inputs-file FILENAME Files containing lists of input files (can use glob syntax) -i FILENAME, --input FILENAME Input files (can use glob syntax) -N FILENAME, --negatives-file FILENAME Files containing lists of negative files (can use glob syntax) -n FILENAME, --negative FILENAME Files that have no annotations (can use glob syntax) -o FILENAME, --output-file FILENAME optional file to write read filenames into --seed SEED the seed to use for randomisation --image-path-rel PATH Relative path to image files from annotations -l PATH, --labels PATH Path to the labels file","title":"Options:"},{"location":"plugins/#processor-stage","text":"","title":"Processor stage"},{"location":"plugins/#check-duplicate-filenames","text":"Causes the conversion stream to halt when multiple dataset items have the same filename","title":"CHECK-DUPLICATE-FILENAMES"},{"location":"plugins/#domains_14","text":"Speech Domain Image Segmentation Domain Image Object-Detection Domain Image Classification Domain","title":"Domain(s):"},{"location":"plugins/#options_14","text":"usage: check-duplicate-filenames","title":"Options:"},{"location":"plugins/#coerce-box","text":"Converts all annotation bounds into box regions","title":"COERCE-BOX"},{"location":"plugins/#domains_15","text":"Image Object-Detection Domain","title":"Domain(s):"},{"location":"plugins/#options_15","text":"usage: coerce-box","title":"Options:"},{"location":"plugins/#coerce-mask","text":"Converts all annotation bounds into polygon regions","title":"COERCE-MASK"},{"location":"plugins/#domains_16","text":"Image Object-Detection Domain","title":"Domain(s):"},{"location":"plugins/#options_16","text":"usage: coerce-mask","title":"Options:"},{"location":"plugins/#convert-image-format","text":"Converts images from one format to another","title":"CONVERT-IMAGE-FORMAT"},{"location":"plugins/#domains_17","text":"Image Segmentation Domain Image Object-Detection Domain Image Classification Domain","title":"Domain(s):"},{"location":"plugins/#options_17","text":"usage: convert-image-format -f FORMAT optional arguments: -f FORMAT, --format FORMAT format to convert images to","title":"Options:"},{"location":"plugins/#crop","text":"Crops images.","title":"CROP"},{"location":"plugins/#domains_18","text":"Image Object-Detection Domain Image Classification Domain","title":"Domain(s):"},{"location":"plugins/#options_18","text":"usage: crop [-m IMGAUG_MODE] [--suffix IMGAUG_SUFFIX] [-f PERCENT_FROM] [-t PERCENT_TO] [-s SEED] [-a] [-T THRESHOLD] [-u] optional arguments: -m IMGAUG_MODE, --mode IMGAUG_MODE the image augmentation mode to use, available modes: replace, add --suffix IMGAUG_SUFFIX the suffix to use for the file names in case of augmentation mode add -f PERCENT_FROM, --from-percent PERCENT_FROM the minimum percent to crop from images -t PERCENT_TO, --to-percent PERCENT_TO the maximum percent to crop from images -s SEED, --seed SEED the seed value to use for the random number generator; randomly seeded if not provided -a, --seed-augmentation whether to seed the augmentation; if specified, uses the seeded random generator to produce a seed value from 0 to 1000 for the augmentation. -T THRESHOLD, --threshold THRESHOLD the threshold to use for Random.rand(): if equal or above, augmentation gets applied; range: 0-1; default: 0 (= always) -u, --update-size whether to update the image size after the crop operation or scale back to original size","title":"Options:"},{"location":"plugins/#dimension-discarder","text":"Removes annotations which fall outside certain size constraints","title":"DIMENSION-DISCARDER"},{"location":"plugins/#domains_19","text":"Image Object-Detection Domain","title":"Domain(s):"},{"location":"plugins/#options_19","text":"usage: dimension-discarder [--max-area MAX_AREA] [--max-height MAX_HEIGHT] [--max-width MAX_WIDTH] [--min-area MIN_AREA] [--min-height MIN_HEIGHT] [--min-width MIN_WIDTH] [--verbose] optional arguments: --max-area MAX_AREA the maximum area of annotations to convert --max-height MAX_HEIGHT the maximum height of annotations to convert --max-width MAX_WIDTH the maximum width of annotations to convert --min-area MIN_AREA the minimum area of annotations to convert --min-height MIN_HEIGHT the minimum height of annotations to convert --min-width MIN_WIDTH the minimum width of annotations to convert --verbose outputs information when discarding annotations","title":"Options:"},{"location":"plugins/#discard-negatives","text":"Discards negative examples (those without annotations) from the stream","title":"DISCARD-NEGATIVES"},{"location":"plugins/#domains_20","text":"Speech Domain Image Segmentation Domain Image Object-Detection Domain Image Classification Domain","title":"Domain(s):"},{"location":"plugins/#options_20","text":"usage: discard-negatives","title":"Options:"},{"location":"plugins/#filter-labels","text":"Filters detected objects down to those with specified labels.","title":"FILTER-LABELS"},{"location":"plugins/#domains_21","text":"Image Object-Detection Domain","title":"Domain(s):"},{"location":"plugins/#options_21","text":"usage: filter-labels [-l LABELS [LABELS ...]] [-r regexp] optional arguments: -l LABELS [LABELS ...], --labels LABELS [LABELS ...] labels to use -r regexp, --regexp regexp regular expression for using only a subset of labels","title":"Options:"},{"location":"plugins/#flip","text":"Flips images either left-to-right, up-to-down or both.","title":"FLIP"},{"location":"plugins/#domains_22","text":"Image Object-Detection Domain Image Classification Domain","title":"Domain(s):"},{"location":"plugins/#options_22","text":"usage: flip [-d DIRECTION] [-m IMGAUG_MODE] [--suffix IMGAUG_SUFFIX] [-s SEED] [-a] [-T THRESHOLD] optional arguments: -d DIRECTION, --direction DIRECTION the direction to flip, available options: lr, up, lrup -m IMGAUG_MODE, --mode IMGAUG_MODE the image augmentation mode to use, available modes: replace, add --suffix IMGAUG_SUFFIX the suffix to use for the file names in case of augmentation mode add -s SEED, --seed SEED the seed value to use for the random number generator; randomly seeded if not provided -a, --seed-augmentation whether to seed the augmentation; if specified, uses the seeded random generator to produce a seed value from 0 to 1000 for the augmentation. -T THRESHOLD, --threshold THRESHOLD the threshold to use for Random.rand(): if equal or above, augmentation gets applied; range: 0-1; default: 0 (= always)","title":"Options:"},{"location":"plugins/#gaussian-blur","text":"Applies gaussian blur to images.","title":"GAUSSIAN-BLUR"},{"location":"plugins/#domains_23","text":"Image Object-Detection Domain Image Classification Domain","title":"Domain(s):"},{"location":"plugins/#options_23","text":"usage: gaussian-blur [-m IMGAUG_MODE] [--suffix IMGAUG_SUFFIX] [-s SEED] [-a] [-f SIGMA_FROM] [-t SIGMA_TO] [-T THRESHOLD] optional arguments: -m IMGAUG_MODE, --mode IMGAUG_MODE the image augmentation mode to use, available modes: replace, add --suffix IMGAUG_SUFFIX the suffix to use for the file names in case of augmentation mode add -s SEED, --seed SEED the seed value to use for the random number generator; randomly seeded if not provided -a, --seed-augmentation whether to seed the augmentation; if specified, uses the seeded random generator to produce a seed value from 0 to 1000 for the augmentation. -f SIGMA_FROM, --from-sigma SIGMA_FROM the minimum sigma for the blur to apply to the images -t SIGMA_TO, --to-sigma SIGMA_TO the maximum sigma for the blur to apply to the images -T THRESHOLD, --threshold THRESHOLD the threshold to use for Random.rand(): if equal or above, augmentation gets applied; range: 0-1; default: 0 (= always)","title":"Options:"},{"location":"plugins/#hsl-grayscale","text":"Turns RGB images into fake grayscale ones by converting them to HSL and then using the L channel for all channels. The brightness can be influenced and varied even.","title":"HSL-GRAYSCALE"},{"location":"plugins/#domains_24","text":"Image Object-Detection Domain Image Classification Domain","title":"Domain(s):"},{"location":"plugins/#options_24","text":"usage: hsl-grayscale [-f FACTOR_FROM] [-t FACTOR_TO] [-m IMGAUG_MODE] [--suffix IMGAUG_SUFFIX] [-s SEED] [-a] [-T THRESHOLD] optional arguments: -f FACTOR_FROM, --from-factor FACTOR_FROM the start of the factor range to apply to the L channel to darken or lighten the image (<1: darker, >1: lighter) -t FACTOR_TO, --to-factor FACTOR_TO the end of the factor range to apply to the L channel to darken or lighten the image (<1: darker, >1: lighter) -m IMGAUG_MODE, --mode IMGAUG_MODE the image augmentation mode to use, available modes: replace, add --suffix IMGAUG_SUFFIX the suffix to use for the file names in case of augmentation mode add -s SEED, --seed SEED the seed value to use for the random number generator; randomly seeded if not provided -a, --seed-augmentation whether to seed the augmentation; if specified, uses the seeded random generator to produce a seed value from 0 to 1000 for the augmentation. -T THRESHOLD, --threshold THRESHOLD the threshold to use for Random.rand(): if equal or above, augmentation gets applied; range: 0-1; default: 0 (= always)","title":"Options:"},{"location":"plugins/#linear-contrast","text":"Applies linear contrast to images.","title":"LINEAR-CONTRAST"},{"location":"plugins/#domains_25","text":"Image Object-Detection Domain Image Classification Domain","title":"Domain(s):"},{"location":"plugins/#options_25","text":"usage: linear-contrast [-f ALPHA_FROM] [-t ALPHA_TO] [-m IMGAUG_MODE] [--suffix IMGAUG_SUFFIX] [-s SEED] [-a] [-T THRESHOLD] optional arguments: -f ALPHA_FROM, --from-alpha ALPHA_FROM the minimum alpha to apply to the images -t ALPHA_TO, --to-alpha ALPHA_TO the maximum alpha to apply to the images -m IMGAUG_MODE, --mode IMGAUG_MODE the image augmentation mode to use, available modes: replace, add --suffix IMGAUG_SUFFIX the suffix to use for the file names in case of augmentation mode add -s SEED, --seed SEED the seed value to use for the random number generator; randomly seeded if not provided -a, --seed-augmentation whether to seed the augmentation; if specified, uses the seeded random generator to produce a seed value from 0 to 1000 for the augmentation. -T THRESHOLD, --threshold THRESHOLD the threshold to use for Random.rand(): if equal or above, augmentation gets applied; range: 0-1; default: 0 (= always)","title":"Options:"},{"location":"plugins/#map-labels","text":"Maps object-detection labels from one set to another","title":"MAP-LABELS"},{"location":"plugins/#domains_26","text":"Image Object-Detection Domain","title":"Domain(s):"},{"location":"plugins/#options_26","text":"usage: map-labels [-m old=new] optional arguments: -m old=new, --mapping old=new mapping for labels, for replacing one label string with another (eg when fixing/collapsing labels)","title":"Options:"},{"location":"plugins/#od-to-ic","text":"Converts image object-detection instances into image classification instances","title":"OD-TO-IC"},{"location":"plugins/#domains_27","text":"Image Object-Detection Domain","title":"Domain(s):"},{"location":"plugins/#options_27","text":"usage: od-to-ic [-m HANDLER] optional arguments: -m HANDLER, --multiplicity HANDLER how to handle instances with more than one located object","title":"Options:"},{"location":"plugins/#od-to-is","text":"Converts image object-detection instances into image segmentation instances","title":"OD-TO-IS"},{"location":"plugins/#domains_28","text":"Image Object-Detection Domain","title":"Domain(s):"},{"location":"plugins/#options_28","text":"usage: od-to-is [--label-error] --labels LABEL [LABEL ...] optional arguments: --label-error whether to raise errors when an unspecified label is encountered (default is to ignore) --labels LABEL [LABEL ...] specifies the labels for each index","title":"Options:"},{"location":"plugins/#passthrough","text":"Dummy ISP which has no effect on the conversion stream","title":"PASSTHROUGH"},{"location":"plugins/#domains_29","text":"Speech Domain Image Segmentation Domain Image Object-Detection Domain Image Classification Domain","title":"Domain(s):"},{"location":"plugins/#options_29","text":"usage: passthrough","title":"Options:"},{"location":"plugins/#polygon-discarder","text":"Removes annotations with polygons which fall outside certain point limit constraints","title":"POLYGON-DISCARDER"},{"location":"plugins/#domains_30","text":"Image Object-Detection Domain","title":"Domain(s):"},{"location":"plugins/#options_30","text":"usage: polygon-discarder [--max-points MAX_POINTS] [--min-points MIN_POINTS] [--verbose] optional arguments: --max-points MAX_POINTS the maximum number of points in the polygon --min-points MIN_POINTS the minimum number of points in the polygon --verbose outputs information when discarding annotations","title":"Options:"},{"location":"plugins/#remove-classes","text":"Removes classes from classification/image-segmentation instances","title":"REMOVE-CLASSES"},{"location":"plugins/#domains_31","text":"Image Segmentation Domain Image Classification Domain","title":"Domain(s):"},{"location":"plugins/#options_31","text":"usage: remove-classes -c CLASS [CLASS ...] optional arguments: -c CLASS [CLASS ...], --classes CLASS [CLASS ...] the classes to remove","title":"Options:"},{"location":"plugins/#rotate","text":"Rotates images randomly within a range of degrees or by a specified degree. Specify seed value and force augmentation to be seeded to generate repeatable augmentations.","title":"ROTATE"},{"location":"plugins/#domains_32","text":"Image Object-Detection Domain Image Classification Domain","title":"Domain(s):"},{"location":"plugins/#options_32","text":"usage: rotate [-f DEGREE_FROM] [-t DEGREE_TO] [-m IMGAUG_MODE] [--suffix IMGAUG_SUFFIX] [-s SEED] [-a] [-T THRESHOLD] optional arguments: -f DEGREE_FROM, --from-degree DEGREE_FROM the start of the degree range to use for rotating the images -t DEGREE_TO, --to-degree DEGREE_TO the end of the degree range to use for rotating the images -m IMGAUG_MODE, --mode IMGAUG_MODE the image augmentation mode to use, available modes: replace, add --suffix IMGAUG_SUFFIX the suffix to use for the file names in case of augmentation mode add -s SEED, --seed SEED the seed value to use for the random number generator; randomly seeded if not provided -a, --seed-augmentation whether to seed the augmentation; if specified, uses the seeded random generator to produce a seed value from 0 to 1000 for the augmentation. -T THRESHOLD, --threshold THRESHOLD the threshold to use for Random.rand(): if equal or above, augmentation gets applied; range: 0-1; default: 0 (= always)","title":"Options:"},{"location":"plugins/#scale","text":"Scales images randomly within a range of percentages or by a specified percentage. Specify seed value and force augmentation to be seeded to generate repeatable augmentations.","title":"SCALE"},{"location":"plugins/#domains_33","text":"Image Object-Detection Domain Image Classification Domain","title":"Domain(s):"},{"location":"plugins/#options_33","text":"usage: scale [-m IMGAUG_MODE] [--suffix IMGAUG_SUFFIX] [-k] [-f PERCENTAGE_FROM] [-t PERCENTAGE_TO] [-s SEED] [-a] [-T THRESHOLD] [-u] optional arguments: -m IMGAUG_MODE, --mode IMGAUG_MODE the image augmentation mode to use, available modes: replace, add --suffix IMGAUG_SUFFIX the suffix to use for the file names in case of augmentation mode add -k, --keep-aspect whether to keep the aspect ratio -f PERCENTAGE_FROM, --from-percentage PERCENTAGE_FROM the start of the percentage range to use for scaling the images -t PERCENTAGE_TO, --to-percentage PERCENTAGE_TO the end of the percentage range to use for scaling the images -s SEED, --seed SEED the seed value to use for the random number generator; randomly seeded if not provided -a, --seed-augmentation whether to seed the augmentation; if specified, uses the seeded random generator to produce a seed value from 0 to 1000 for the augmentation. -T THRESHOLD, --threshold THRESHOLD the threshold to use for Random.rand(): if equal or above, augmentation gets applied; range: 0-1; default: 0 (= always) -u, --update-size whether to update the image size after the scaling operation or use original size","title":"Options:"},{"location":"plugins/#strip-annotations","text":"ISP which removes annotations from instances","title":"STRIP-ANNOTATIONS"},{"location":"plugins/#domains_34","text":"Speech Domain Image Segmentation Domain Image Object-Detection Domain Image Classification Domain","title":"Domain(s):"},{"location":"plugins/#options_34","text":"usage: strip-annotations","title":"Options:"},{"location":"plugins/#sink-stage","text":"","title":"Sink stage"},{"location":"plugins/#to-adams-ic","text":"Writes image classification annotations in the ADAMS report-format","title":"TO-ADAMS-IC"},{"location":"plugins/#domains_35","text":"Image Classification Domain","title":"Domain(s):"},{"location":"plugins/#options_35","text":"usage: to-adams-ic -c FIELD [--annotations-only] -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]] optional arguments: -c FIELD, --class-field FIELD the report field containing the image class --annotations-only skip the writing of data files, outputting only the annotation files -o PATH, --output PATH output directory to write files to --split-names SPLIT NAME [SPLIT NAME ...] the names to use for the splits --split-ratios RATIO [RATIO ...] the ratios to use for the splits","title":"Options:"},{"location":"plugins/#to-adams-od","text":"Writes image object-detection annotations in the ADAMS report-format","title":"TO-ADAMS-OD"},{"location":"plugins/#domains_36","text":"Image Object-Detection Domain","title":"Domain(s):"},{"location":"plugins/#options_36","text":"usage: to-adams-od [--annotations-only] -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]] optional arguments: --annotations-only skip the writing of data files, outputting only the annotation files -o PATH, --output PATH output directory to write files to --split-names SPLIT NAME [SPLIT NAME ...] the names to use for the splits --split-ratios RATIO [RATIO ...] the ratios to use for the splits","title":"Options:"},{"location":"plugins/#to-blue-channel-is","text":"Writes image segmentation files in the blue-channel format","title":"TO-BLUE-CHANNEL-IS"},{"location":"plugins/#domains_37","text":"Image Segmentation Domain","title":"Domain(s):"},{"location":"plugins/#options_37","text":"usage: to-blue-channel-is [--annotations-only] -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]] optional arguments: --annotations-only skip the writing of data files, outputting only the annotation files -o PATH, --output PATH the directory to write the annotation images to --split-names SPLIT NAME [SPLIT NAME ...] the names to use for the splits --split-ratios RATIO [RATIO ...] the ratios to use for the splits","title":"Options:"},{"location":"plugins/#to-coco-od","text":"Writes image object-detection annotations in the MS-COCO JSON-format","title":"TO-COCO-OD"},{"location":"plugins/#domains_38","text":"Image Object-Detection Domain","title":"Domain(s):"},{"location":"plugins/#options_38","text":"usage: to-coco-od [--annotations-only] [--categories CATEGORY [CATEGORY ...]] [--category-output-file FILENAME] [--default-supercategory SUPERCATEGORY] [--error-on-new-category] [--license-name LICENSE_NAME] [--license-url LICENSE_URL] -o PATH [--pretty] [--sort-categories] [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]] optional arguments: --annotations-only skip the writing of data files, outputting only the annotation files --categories CATEGORY [CATEGORY ...] defines the order of the categories --category-output-file FILENAME file to write the categories into, as a simple comma-separated list --default-supercategory SUPERCATEGORY the supercategory to use for pre-defined categories --error-on-new-category whether unspecified categories should raise an error --license-name LICENSE_NAME the license of the images --license-url LICENSE_URL the license of the images -o PATH, --output PATH output file to write annotations to (images are placed in same directory) --pretty whether to format the JSON annotations file with indentation --sort-categories whether to put the categories in alphabetical order --split-names SPLIT NAME [SPLIT NAME ...] the names to use for the splits --split-ratios RATIO [RATIO ...] the ratios to use for the splits","title":"Options:"},{"location":"plugins/#to-common-voice-sp","text":"Writes speech transcriptions in the Mozilla Common-Voice TSV-format","title":"TO-COMMON-VOICE-SP"},{"location":"plugins/#domains_39","text":"Speech Domain","title":"Domain(s):"},{"location":"plugins/#options_39","text":"usage: to-common-voice-sp [--annotations-only] -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]] optional arguments: --annotations-only skip the writing of data files, outputting only the annotation files -o PATH, --output PATH the filename of the TSV file to write the annotations into --split-names SPLIT NAME [SPLIT NAME ...] the names to use for the splits --split-ratios RATIO [RATIO ...] the ratios to use for the splits","title":"Options:"},{"location":"plugins/#to-festvox-sp","text":"Writes speech transcriptions in the Festival FestVox format","title":"TO-FESTVOX-SP"},{"location":"plugins/#domains_40","text":"Speech Domain","title":"Domain(s):"},{"location":"plugins/#options_40","text":"usage: to-festvox-sp [--annotations-only] -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]] optional arguments: --annotations-only skip the writing of data files, outputting only the annotation files -o PATH, --output PATH the filename of the FestVox file to write the annotations into --split-names SPLIT NAME [SPLIT NAME ...] the names to use for the splits --split-ratios RATIO [RATIO ...] the ratios to use for the splits","title":"Options:"},{"location":"plugins/#to-indexed-png-is","text":"Writes image segmentation files in the indexed-PNG format","title":"TO-INDEXED-PNG-IS"},{"location":"plugins/#domains_41","text":"Image Segmentation Domain","title":"Domain(s):"},{"location":"plugins/#options_41","text":"usage: to-indexed-png-is [--annotations-only] -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]] optional arguments: --annotations-only skip the writing of data files, outputting only the annotation files -o PATH, --output PATH the directory to write the annotation images to --split-names SPLIT NAME [SPLIT NAME ...] the names to use for the splits --split-ratios RATIO [RATIO ...] the ratios to use for the splits","title":"Options:"},{"location":"plugins/#to-layer-segments-is","text":"Writes the layer-segments image-segmentation format to disk","title":"TO-LAYER-SEGMENTS-IS"},{"location":"plugins/#domains_42","text":"Image Segmentation Domain","title":"Domain(s):"},{"location":"plugins/#options_42","text":"usage: to-layer-segments-is [--annotations-only] [--label-separator SEPARATOR] -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]] optional arguments: --annotations-only skip the writing of data files, outputting only the annotation files --label-separator SEPARATOR the separator between the base filename and the label -o PATH, --output PATH the directory to write the annotation images to --split-names SPLIT NAME [SPLIT NAME ...] the names to use for the splits --split-ratios RATIO [RATIO ...] the ratios to use for the splits","title":"Options:"},{"location":"plugins/#to-roi-od","text":"Writes image object-detection annotations in the ROI CSV-format","title":"TO-ROI-OD"},{"location":"plugins/#domains_43","text":"Image Object-Detection Domain","title":"Domain(s):"},{"location":"plugins/#options_43","text":"usage: to-roi-od [-d WIDTH HEIGHT] [--annotations-only] [--comments COMMENTS [COMMENTS ...]] -o PATH [--size-mode] [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]] [--prefix WRITER_PREFIX] [--suffix WRITER_SUFFIX] optional arguments: -d WIDTH HEIGHT, --image-dimensions WIDTH HEIGHT image dimensions to use if none can be inferred --annotations-only skip the writing of data files, outputting only the annotation files --comments COMMENTS [COMMENTS ...] comments to write to the beginning of the ROI file -o PATH, --output PATH output directory to write files to --size-mode writes the ROI files with x,y,w,h headers instead of x0,y0,x1,y1 --split-names SPLIT NAME [SPLIT NAME ...] the names to use for the splits --split-ratios RATIO [RATIO ...] the ratios to use for the splits --prefix WRITER_PREFIX the prefix for output filenames (default = '') --suffix WRITER_SUFFIX the suffix for output filenames (default = '-rois.csv')","title":"Options:"},{"location":"plugins/#to-subdir-ic","text":"Writes images to sub-directories named after their class labels.","title":"TO-SUBDIR-IC"},{"location":"plugins/#domains_44","text":"Image Classification Domain","title":"Domain(s):"},{"location":"plugins/#options_44","text":"usage: to-subdir-ic -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]] optional arguments: -o PATH, --output PATH the directory to store the class directories in --split-names SPLIT NAME [SPLIT NAME ...] the names to use for the splits --split-ratios RATIO [RATIO ...] the ratios to use for the splits","title":"Options:"},{"location":"plugins/#to-tf-od","text":"Writes image object-detection annotations in the TFRecords binary format","title":"TO-TF-OD"},{"location":"plugins/#domains_45","text":"Image Object-Detection Domain","title":"Domain(s):"},{"location":"plugins/#options_45","text":"usage: to-tf-od [--dense] [--source-id-type {filename,numeric-dummy}] -o PATH [-p FILENAME] [-s FILENAME [FILENAME ...]] [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]] optional arguments: --dense outputs masks in the dense numerical format instead of PNG-encoded --source-id-type {filename,numeric-dummy} by default, the filename gets stored in the 'source_id' field, but some algorithms try to convert it into a number and fail with 'StringToNumberOp could not correctly convert string'; in which case you can use 'numeric-dummy' (see https://github.com/google/automl/issues/307) -o PATH, --output PATH name of output file for TFRecords -p FILENAME, --protobuf FILENAME for storing the label strings and IDs -s FILENAME [FILENAME ...], --shards FILENAME [FILENAME ...] additional shards to write to --split-names SPLIT NAME [SPLIT NAME ...] the names to use for the splits --split-ratios RATIO [RATIO ...] the ratios to use for the splits","title":"Options:"},{"location":"plugins/#to-vgg-od","text":"Writes image object-detection annotations in the VGG JSON-format","title":"TO-VGG-OD"},{"location":"plugins/#domains_46","text":"Image Object-Detection Domain","title":"Domain(s):"},{"location":"plugins/#options_46","text":"usage: to-vgg-od [--annotations-only] -o PATH [--pretty] [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]] optional arguments: --annotations-only skip the writing of data files, outputting only the annotation files -o PATH, --output PATH output file to write annotations to (images are placed in same directory) --pretty whether to format the JSON annotations file with indentation --split-names SPLIT NAME [SPLIT NAME ...] the names to use for the splits --split-ratios RATIO [RATIO ...] the ratios to use for the splits","title":"Options:"},{"location":"plugins/#to-voc-od","text":"Writes image object-detection annotations in the Pascal VOC XML-format","title":"TO-VOC-OD"},{"location":"plugins/#domains_47","text":"Image Object-Detection Domain","title":"Domain(s):"},{"location":"plugins/#options_47","text":"usage: to-voc-od [--annotations-only] -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]] optional arguments: --annotations-only skip the writing of data files, outputting only the annotation files -o PATH, --output PATH output directory to write annotations to (images are placed in same directory) --split-names SPLIT NAME [SPLIT NAME ...] the names to use for the splits --split-ratios RATIO [RATIO ...] the ratios to use for the splits","title":"Options:"},{"location":"plugins/#to-void-ic","text":"Consumes instances without writing them.","title":"TO-VOID-IC"},{"location":"plugins/#domains_48","text":"Image Classification Domain","title":"Domain(s):"},{"location":"plugins/#options_48","text":"usage: to-void-ic","title":"Options:"},{"location":"plugins/#to-void-is","text":"Consumes instances without writing them.","title":"TO-VOID-IS"},{"location":"plugins/#domains_49","text":"Image Segmentation Domain","title":"Domain(s):"},{"location":"plugins/#options_49","text":"usage: to-void-is","title":"Options:"},{"location":"plugins/#to-void-od","text":"Consumes instances without writing them.","title":"TO-VOID-OD"},{"location":"plugins/#domains_50","text":"Image Object-Detection Domain","title":"Domain(s):"},{"location":"plugins/#options_50","text":"usage: to-void-od","title":"Options:"},{"location":"plugins/#to-void-sp","text":"Consumes instances without writing them.","title":"TO-VOID-SP"},{"location":"plugins/#domains_51","text":"Speech Domain","title":"Domain(s):"},{"location":"plugins/#options_51","text":"usage: to-void-sp","title":"Options:"},{"location":"plugins/#to-yolo-od","text":"Writes image object-detection annotations in the YOLO format","title":"TO-YOLO-OD"},{"location":"plugins/#domains_52","text":"Image Object-Detection Domain","title":"Domain(s):"},{"location":"plugins/#options_52","text":"usage: to-yolo-od [-c PATH] [-l PATH] [--annotations-only] -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]] optional arguments: -c PATH, --labels-csv PATH Path to the labels CSV file to write -l PATH, --labels PATH Path to the labels file to write --annotations-only skip the writing of data files, outputting only the annotation files -o PATH, --output PATH output directory to write images and annotations to --split-names SPLIT NAME [SPLIT NAME ...] the names to use for the splits --split-ratios RATIO [RATIO ...] the ratios to use for the splits","title":"Options:"},{"location":"stream/","text":"Stream Layer The stream layer provides classes for creating custom stream-processing pipelines. Each pipeline consists of: a source, which injects items into the pipeline for processing; processors, which take items and process them; and a sink, which consumes the items coming out of the pipeline. There are 3 base-classes representing sources, processors and sinks (respectively: StreamSource, StreamProcessor and StreamSink). These classes should be inherited to provide customised stream-processing functionality. The Pipeline class gathers the individual stream elements into a whole, connects each element to the previous and next elements, and ensures that the elements follow the pipeline's calling semantics (see below). Note that while the stream-processing elements are typed on the items they consume/produce, this is only for linting purposes and not enforced at run-time. Calling semantics For sources and processors, the ability to pass items on to later elements in the processing pipeline is provided through 2 callback functions, then and done . then forwards an item to the next element of the pipeline, and done signals that no more items will be forwarded. This design was chosen over e.g. iterators as it ensures that when an error occurs, the relevant information which led to the error is retained on the call-stack. This is a useful aid for debugging. However, this does mean that the potential exists for the callbacks to called in an arbitrary order, when only certain permutations are sensible. The intended calling semantics of the 2 callbacks are: 0 or more calls to then to forward items, followed by exactly 1 call to done to signal termination. The pipeline class constructs these callbacks so that, if they are not called in the correct order, an error occurs. Specifically, calling then after done has been called will raise an error, as will not calling done at all. In practice, done is written to be idempotent, such that calling it multiple times is the same as calling it once. StreamSource Stream sources should implement the produce method to inject items into the pipeline. The method should call the then callback with each item to inject as its argument. Once all items have been produced, the source should then call the done callback. StreamProcessor Stream processors should implement process_element method to receive items from the previous processing-element in the pipeline for processing. They should also implement the finish method to finalise processing after all items have been received. Both methods take the then and done callbacks as arguments, so processors can process items and forward the processed results as they arrive, or batch them and perform processing/forwarding in bulk. An optional start method is available, which can be overridden to perform any set-up required before the processor starts receiving items. StreamSink Stream sinks should implement the consume_element method to consume items produced by the pipeline. They should also implement the finish method to perform any tidy-up once the pipeline has terminated. An optional start method is available, which can be overridden to perform any set-up required before the sink starts receiving items. Pipeline The Pipeline class take an optional source, zero or more processors, and an optional sink as its constructor arguments. When the process method is called, the processing elements are connected together, the start methods for each processor and the sink are called, and the source is instructed to start producing items. Optionally, an iterable can be passed to the process method to replace the pipeline's own source, and/or a function can be passed to replace the pipeline's sink. When the pipeline is connecting the processing elements together, it also inserts checks for the calling semantics, which will raise an exception if they are not adhered to. Utilities RequiresNoFinalisation Mixin class that can be used with StreamProcessor/StreamSink to automatically implement the finish method. It will call the done callback automatically for processors if it has not been called already. ProcessState Descriptor class which adds per-stream state to a stream-processing element. Takes an initialiser function as its only constructor argument. The initialiser is used to re-initialise the state before each stream is processed by the pipeline that contains the element. The state can be modified during stream processing to track per-stream state, but the changes are discarded once a new stream is processed.","title":"Stream Layer"},{"location":"stream/#stream-layer","text":"The stream layer provides classes for creating custom stream-processing pipelines. Each pipeline consists of: a source, which injects items into the pipeline for processing; processors, which take items and process them; and a sink, which consumes the items coming out of the pipeline. There are 3 base-classes representing sources, processors and sinks (respectively: StreamSource, StreamProcessor and StreamSink). These classes should be inherited to provide customised stream-processing functionality. The Pipeline class gathers the individual stream elements into a whole, connects each element to the previous and next elements, and ensures that the elements follow the pipeline's calling semantics (see below). Note that while the stream-processing elements are typed on the items they consume/produce, this is only for linting purposes and not enforced at run-time.","title":"Stream Layer"},{"location":"stream/#calling-semantics","text":"For sources and processors, the ability to pass items on to later elements in the processing pipeline is provided through 2 callback functions, then and done . then forwards an item to the next element of the pipeline, and done signals that no more items will be forwarded. This design was chosen over e.g. iterators as it ensures that when an error occurs, the relevant information which led to the error is retained on the call-stack. This is a useful aid for debugging. However, this does mean that the potential exists for the callbacks to called in an arbitrary order, when only certain permutations are sensible. The intended calling semantics of the 2 callbacks are: 0 or more calls to then to forward items, followed by exactly 1 call to done to signal termination. The pipeline class constructs these callbacks so that, if they are not called in the correct order, an error occurs. Specifically, calling then after done has been called will raise an error, as will not calling done at all. In practice, done is written to be idempotent, such that calling it multiple times is the same as calling it once.","title":"Calling semantics"},{"location":"stream/#streamsource","text":"Stream sources should implement the produce method to inject items into the pipeline. The method should call the then callback with each item to inject as its argument. Once all items have been produced, the source should then call the done callback.","title":"StreamSource"},{"location":"stream/#streamprocessor","text":"Stream processors should implement process_element method to receive items from the previous processing-element in the pipeline for processing. They should also implement the finish method to finalise processing after all items have been received. Both methods take the then and done callbacks as arguments, so processors can process items and forward the processed results as they arrive, or batch them and perform processing/forwarding in bulk. An optional start method is available, which can be overridden to perform any set-up required before the processor starts receiving items.","title":"StreamProcessor"},{"location":"stream/#streamsink","text":"Stream sinks should implement the consume_element method to consume items produced by the pipeline. They should also implement the finish method to perform any tidy-up once the pipeline has terminated. An optional start method is available, which can be overridden to perform any set-up required before the sink starts receiving items.","title":"StreamSink"},{"location":"stream/#pipeline","text":"The Pipeline class take an optional source, zero or more processors, and an optional sink as its constructor arguments. When the process method is called, the processing elements are connected together, the start methods for each processor and the sink are called, and the source is instructed to start producing items. Optionally, an iterable can be passed to the process method to replace the pipeline's own source, and/or a function can be passed to replace the pipeline's sink. When the pipeline is connecting the processing elements together, it also inserts checks for the calling semantics, which will raise an exception if they are not adhered to.","title":"Pipeline"},{"location":"stream/#utilities","text":"","title":"Utilities"},{"location":"stream/#requiresnofinalisation","text":"Mixin class that can be used with StreamProcessor/StreamSink to automatically implement the finish method. It will call the done callback automatically for processors if it has not been called already.","title":"RequiresNoFinalisation"},{"location":"stream/#processstate","text":"Descriptor class which adds per-stream state to a stream-processing element. Takes an initialiser function as its only constructor argument. The initialiser is used to re-initialise the state before each stream is processed by the pipeline that contains the element. The state can be modified during stream processing to track per-stream state, but the changes are discarded once a new stream is processed.","title":"ProcessState"},{"location":"usage/","text":"How to use wai-annotations from the command-line To convert a dataset using wai-annotations from the command-line, run the following command: wai-annotations convert [CONVERSION OPTIONS] \\ input-type [INPUT OPTIONS] \\ [ISP/XDC [ISP/XDC OPTIONS]]... \\ output-type [OUTPUT OPTIONS] (ISP=inline-stream-processor, XDC=cross-domain-conversion) For the available conversion options, see here . To list of available plugins in your environment, run: wai-annotations plugins For the available domains in your environment, run: wai-annotations domains The -h/--help option can be given at any point in a command-string to provide the options available at that point in the command. Examples of how to run wai-annotations can be found here .","title":"Usage"},{"location":"usage/#how-to-use-wai-annotations-from-the-command-line","text":"To convert a dataset using wai-annotations from the command-line, run the following command: wai-annotations convert [CONVERSION OPTIONS] \\ input-type [INPUT OPTIONS] \\ [ISP/XDC [ISP/XDC OPTIONS]]... \\ output-type [OUTPUT OPTIONS] (ISP=inline-stream-processor, XDC=cross-domain-conversion) For the available conversion options, see here . To list of available plugins in your environment, run: wai-annotations plugins For the available domains in your environment, run: wai-annotations domains The -h/--help option can be given at any point in a command-string to provide the options available at that point in the command. Examples of how to run wai-annotations can be found here .","title":"How to use wai-annotations from the command-line"}]}
<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="shortcut icon" href="../img/favicon.ico">
  <title>Plugins - wai-annotations manual</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Plugins";
    var mkdocs_page_input_path = "plugins.md";
    var mkdocs_page_url = "/wai-annotations-manual/plugins/";
  </script>
  
  <script src="../js/jquery-2.1.1.min.js" defer></script>
  <script src="../js/modernizr-2.8.3.min.js" defer></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> wai-annotations manual</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="..">Home</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../install/">Installation</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../usage/">Usage</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Examples</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../examples_overview/">Overview</a>
                </li>
                <li class="">
                    
    <a class="" href="../examples_formats/">Format conversions</a>
                </li>
                <li class="">
                    
    <a class="" href="../examples_imgaug/">Image dataset augmentation</a>
                </li>
                <li class="">
                    
    <a class="" href="../examples_imgstats/">Image dataset statistics</a>
                </li>
                <li class="">
                    
    <a class="" href="../examples_imgvis/">Image dataset visualizations</a>
                </li>
                <li class="">
                    
    <a class="" href="../examples_video/">Video handling</a>
                </li>
                <li class="">
                    
    <a class="" href="../examples_redis_predictions/">Predictions via Redis</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../docker/">Docker</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../architecture_overview/">Architecture overview</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../plugin/">Plugin guide</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../domains/">Domains</a>
	    </li>
          
            <li class="toctree-l1 current">
		
    <a class="current" href="./">Plugins</a>
    <ul class="subnav">
            
    <li class="toctree-l2"><a href="#plugins">Plugins</a></li>
    
        <ul>
        
            <li><a class="toctree-l3" href="#source-stage">Source stage</a></li>
        
            <li><a class="toctree-l3" href="#processor-stage">Processor stage</a></li>
        
            <li><a class="toctree-l3" href="#sink-stage">Sink stage</a></li>
        
        </ul>
    

    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../glossary/">Glossary</a>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">wai-annotations manual</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
    
    <li>Plugins</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h3 id="plugins">Plugins</h3>
<h4 id="source-stage">Source stage</h4>
<h5 id="from-adams-ic">FROM-ADAMS-IC</h5>
<p>Reads image classification annotations in the ADAMS report-format</p>
<h6 id="domains">Domain(s):</h6>
<ul>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options">Options:</h6>
<pre><code>usage: from-adams-ic [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME]
                     [--seed SEED] [-e FORMAT FORMAT FORMAT] -c FIELD

optional arguments:
  -I FILENAME, --inputs-file FILENAME
                        Files containing lists of input files (can use glob syntax) (default: [])
  -i FILENAME, --input FILENAME
                        Input files (can use glob syntax) (default: [])
  -N FILENAME, --negatives-file FILENAME
                        Files containing lists of negative files (can use glob syntax) (default: [])
  -n FILENAME, --negative FILENAME
                        Files that have no annotations (can use glob syntax) (default: [])
  -o FILENAME, --output-file FILENAME
                        optional file to write read filenames into (default: None)
  --seed SEED           the seed to use for randomisation (default: None)
  -e FORMAT FORMAT FORMAT, --extensions FORMAT FORMAT FORMAT
                        image format extensions in order of preference (default: [&lt;ImageFormat.PNG:
                        (frozenset({'png', 'PNG'}), 'PNG')&gt;, &lt;ImageFormat.JPG: (frozenset({'jpeg',
                        'JPG', 'JPEG', 'jpg'}), 'JPEG')&gt;, &lt;ImageFormat.BMP: (frozenset({'bmp',
                        'BMP'}), 'BMP')&gt;])
  -c FIELD, --class-field FIELD
                        the report field containing the image class (default: None)
</code></pre>
<h5 id="from-adams-od">FROM-ADAMS-OD</h5>
<p>Reads image object-detection annotations in the ADAMS report-format</p>
<h6 id="domains_1">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_1">Options:</h6>
<pre><code>usage: from-adams-od [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME]
                     [--seed SEED] [-e FORMAT FORMAT FORMAT] [-p PREFIXES [PREFIXES ...]]

optional arguments:
  -I FILENAME, --inputs-file FILENAME
                        Files containing lists of input files (can use glob syntax) (default: [])
  -i FILENAME, --input FILENAME
                        Input files (can use glob syntax) (default: [])
  -N FILENAME, --negatives-file FILENAME
                        Files containing lists of negative files (can use glob syntax) (default: [])
  -n FILENAME, --negative FILENAME
                        Files that have no annotations (can use glob syntax) (default: [])
  -o FILENAME, --output-file FILENAME
                        optional file to write read filenames into (default: None)
  --seed SEED           the seed to use for randomisation (default: None)
  -e FORMAT FORMAT FORMAT, --extensions FORMAT FORMAT FORMAT
                        image format extensions in order of preference (default: [&lt;ImageFormat.PNG:
                        (frozenset({'png', 'PNG'}), 'PNG')&gt;, &lt;ImageFormat.JPG: (frozenset({'jpeg',
                        'JPG', 'JPEG', 'jpg'}), 'JPEG')&gt;, &lt;ImageFormat.BMP: (frozenset({'bmp',
                        'BMP'}), 'BMP')&gt;])
  -p PREFIXES [PREFIXES ...], --prefixes PREFIXES [PREFIXES ...]
                        prefixes to parse (default: [])
</code></pre>
<h5 id="from-blue-channel-is">FROM-BLUE-CHANNEL-IS</h5>
<p>Reads image segmentation files in the blue-channel format</p>
<h6 id="domains_2">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
</ul>
<h6 id="options_2">Options:</h6>
<pre><code>usage: from-blue-channel-is [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME]
                            [--seed SEED] [--image-path-rel PATH] --labels LABEL [LABEL ...]

optional arguments:
  -I FILENAME, --inputs-file FILENAME
                        Files containing lists of input files (can use glob syntax) (default: [])
  -i FILENAME, --input FILENAME
                        Input files (can use glob syntax) (default: [])
  -N FILENAME, --negatives-file FILENAME
                        Files containing lists of negative files (can use glob syntax) (default: [])
  -n FILENAME, --negative FILENAME
                        Files that have no annotations (can use glob syntax) (default: [])
  -o FILENAME, --output-file FILENAME
                        optional file to write read filenames into (default: None)
  --seed SEED           the seed to use for randomisation (default: None)
  --image-path-rel PATH
                        Relative path to image files from annotations (default: .)
  --labels LABEL [LABEL ...]
                        specifies the labels for each index (default: None)
</code></pre>
<h5 id="from-coco-od">FROM-COCO-OD</h5>
<p>Reads image object-detection annotations in the MS-COCO JSON-format</p>
<h6 id="domains_3">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_3">Options:</h6>
<pre><code>usage: from-coco-od [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME]
                    [--seed SEED]

optional arguments:
  -I FILENAME, --inputs-file FILENAME
                        Files containing lists of input files (can use glob syntax) (default: [])
  -i FILENAME, --input FILENAME
                        Input files (can use glob syntax) (default: [])
  -N FILENAME, --negatives-file FILENAME
                        Files containing lists of negative files (can use glob syntax) (default: [])
  -n FILENAME, --negative FILENAME
                        Files that have no annotations (can use glob syntax) (default: [])
  -o FILENAME, --output-file FILENAME
                        optional file to write read filenames into (default: None)
  --seed SEED           the seed to use for randomisation (default: None)
</code></pre>
<h5 id="from-common-voice-sp">FROM-COMMON-VOICE-SP</h5>
<p>Reads speech transcriptions in the Mozilla Common-Voice TSV-format</p>
<h6 id="domains_4">Domain(s):</h6>
<ul>
<li><strong>Speech Domain</strong></li>
</ul>
<h6 id="options_4">Options:</h6>
<pre><code>usage: from-common-voice-sp [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME]
                            [--seed SEED] [--rel-path REL_PATH]

optional arguments:
  -I FILENAME, --inputs-file FILENAME
                        Files containing lists of input files (can use glob syntax) (default: [])
  -i FILENAME, --input FILENAME
                        Input files (can use glob syntax) (default: [])
  -N FILENAME, --negatives-file FILENAME
                        Files containing lists of negative files (can use glob syntax) (default: [])
  -n FILENAME, --negative FILENAME
                        Files that have no annotations (can use glob syntax) (default: [])
  -o FILENAME, --output-file FILENAME
                        optional file to write read filenames into (default: None)
  --seed SEED           the seed to use for randomisation (default: None)
  --rel-path REL_PATH   the relative path from the annotations file to the audio files (default: .)
</code></pre>
<h5 id="from-festvox-sp">FROM-FESTVOX-SP</h5>
<p>Reads speech transcriptions in the Festival FestVox format</p>
<h6 id="domains_5">Domain(s):</h6>
<ul>
<li><strong>Speech Domain</strong></li>
</ul>
<h6 id="options_5">Options:</h6>
<pre><code>usage: from-festvox-sp [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME]
                       [--seed SEED] [--rel-path REL_PATH]

optional arguments:
  -I FILENAME, --inputs-file FILENAME
                        Files containing lists of input files (can use glob syntax) (default: [])
  -i FILENAME, --input FILENAME
                        Input files (can use glob syntax) (default: [])
  -N FILENAME, --negatives-file FILENAME
                        Files containing lists of negative files (can use glob syntax) (default: [])
  -n FILENAME, --negative FILENAME
                        Files that have no annotations (can use glob syntax) (default: [])
  -o FILENAME, --output-file FILENAME
                        optional file to write read filenames into (default: None)
  --seed SEED           the seed to use for randomisation (default: None)
  --rel-path REL_PATH   the relative path from the annotations file to the audio files (default: .)
</code></pre>
<h5 id="from-grayscale-is">FROM-GRAYSCALE-IS</h5>
<p>Reads image segmentation files in the grayscale format</p>
<h6 id="domains_6">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
</ul>
<h6 id="options_6">Options:</h6>
<pre><code>usage: from-grayscale-is [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME]
                         [--seed SEED] [--image-path-rel PATH] --labels LABEL [LABEL ...]

optional arguments:
  -I FILENAME, --inputs-file FILENAME
                        Files containing lists of input files (can use glob syntax) (default: [])
  -i FILENAME, --input FILENAME
                        Input files (can use glob syntax) (default: [])
  -N FILENAME, --negatives-file FILENAME
                        Files containing lists of negative files (can use glob syntax) (default: [])
  -n FILENAME, --negative FILENAME
                        Files that have no annotations (can use glob syntax) (default: [])
  -o FILENAME, --output-file FILENAME
                        optional file to write read filenames into (default: None)
  --seed SEED           the seed to use for randomisation (default: None)
  --image-path-rel PATH
                        Relative path to image files from annotations (default: .)
  --labels LABEL [LABEL ...]
                        specifies the labels for each index (default: None)
</code></pre>
<h5 id="from-images-ic">FROM-IMAGES-IC</h5>
<p>Dummy reader that turns images into an image classification dataset.</p>
<h6 id="domains_7">Domain(s):</h6>
<ul>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_7">Options:</h6>
<pre><code>usage: from-images-ic [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME]
                      [--seed SEED]

optional arguments:
  -I FILENAME, --inputs-file FILENAME
                        Files containing lists of input files (can use glob syntax) (default: [])
  -i FILENAME, --input FILENAME
                        Input files (can use glob syntax) (default: [])
  -N FILENAME, --negatives-file FILENAME
                        Files containing lists of negative files (can use glob syntax) (default: [])
  -n FILENAME, --negative FILENAME
                        Files that have no annotations (can use glob syntax) (default: [])
  -o FILENAME, --output-file FILENAME
                        optional file to write read filenames into (default: None)
  --seed SEED           the seed to use for randomisation (default: None)
</code></pre>
<h5 id="from-images-is">FROM-IMAGES-IS</h5>
<p>Dummy reader that turns images into an image segmentation dataset.</p>
<h6 id="domains_8">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
</ul>
<h6 id="options_8">Options:</h6>
<pre><code>usage: from-images-is [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME]
                      [--seed SEED]

optional arguments:
  -I FILENAME, --inputs-file FILENAME
                        Files containing lists of input files (can use glob syntax) (default: [])
  -i FILENAME, --input FILENAME
                        Input files (can use glob syntax) (default: [])
  -N FILENAME, --negatives-file FILENAME
                        Files containing lists of negative files (can use glob syntax) (default: [])
  -n FILENAME, --negative FILENAME
                        Files that have no annotations (can use glob syntax) (default: [])
  -o FILENAME, --output-file FILENAME
                        optional file to write read filenames into (default: None)
  --seed SEED           the seed to use for randomisation (default: None)
</code></pre>
<h5 id="from-images-od">FROM-IMAGES-OD</h5>
<p>Dummy reader that turns images into an object detection dataset.</p>
<h6 id="domains_9">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_9">Options:</h6>
<pre><code>usage: from-images-od [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME]
                      [--seed SEED]

optional arguments:
  -I FILENAME, --inputs-file FILENAME
                        Files containing lists of input files (can use glob syntax) (default: [])
  -i FILENAME, --input FILENAME
                        Input files (can use glob syntax) (default: [])
  -N FILENAME, --negatives-file FILENAME
                        Files containing lists of negative files (can use glob syntax) (default: [])
  -n FILENAME, --negative FILENAME
                        Files that have no annotations (can use glob syntax) (default: [])
  -o FILENAME, --output-file FILENAME
                        optional file to write read filenames into (default: None)
  --seed SEED           the seed to use for randomisation (default: None)
</code></pre>
<h5 id="from-indexed-png-is">FROM-INDEXED-PNG-IS</h5>
<p>Reads image segmentation files in the indexed-PNG format</p>
<h6 id="domains_10">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
</ul>
<h6 id="options_10">Options:</h6>
<pre><code>usage: from-indexed-png-is [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME]
                           [--seed SEED] [--image-path-rel PATH] --labels LABEL [LABEL ...]

optional arguments:
  -I FILENAME, --inputs-file FILENAME
                        Files containing lists of input files (can use glob syntax) (default: [])
  -i FILENAME, --input FILENAME
                        Input files (can use glob syntax) (default: [])
  -N FILENAME, --negatives-file FILENAME
                        Files containing lists of negative files (can use glob syntax) (default: [])
  -n FILENAME, --negative FILENAME
                        Files that have no annotations (can use glob syntax) (default: [])
  -o FILENAME, --output-file FILENAME
                        optional file to write read filenames into (default: None)
  --seed SEED           the seed to use for randomisation (default: None)
  --image-path-rel PATH
                        Relative path to image files from annotations (default: .)
  --labels LABEL [LABEL ...]
                        specifies the labels for each index (default: None)
</code></pre>
<h5 id="from-layer-segments-is">FROM-LAYER-SEGMENTS-IS</h5>
<p>Reads in the layer-segments image-segmentation format from disk, where each label has a binary PNG storing the mask for that label</p>
<h6 id="domains_11">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
</ul>
<h6 id="options_11">Options:</h6>
<pre><code>usage: from-layer-segments-is [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME]
                              [--seed SEED] [--label-separator SEPARATOR] --labels LABEL [LABEL ...]
                              [--image-path-rel PATH]

optional arguments:
  -I FILENAME, --inputs-file FILENAME
                        Files containing lists of input files (can use glob syntax) (default: [])
  -i FILENAME, --input FILENAME
                        Input files (can use glob syntax) (default: [])
  -N FILENAME, --negatives-file FILENAME
                        Files containing lists of negative files (can use glob syntax) (default: [])
  -n FILENAME, --negative FILENAME
                        Files that have no annotations (can use glob syntax) (default: [])
  -o FILENAME, --output-file FILENAME
                        optional file to write read filenames into (default: None)
  --seed SEED           the seed to use for randomisation (default: None)
  --label-separator SEPARATOR
                        the separator between the base filename and the label (default: -)
  --labels LABEL [LABEL ...]
                        specifies the labels for each index (default: None)
  --image-path-rel PATH
                        Relative path to image files from annotations (default: .)
</code></pre>
<h5 id="from-opex-od">FROM-OPEX-OD</h5>
<p>Reads image object-detection annotations in the OPEX format</p>
<h6 id="domains_12">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_12">Options:</h6>
<pre><code>usage: from-opex-od [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME]
                    [--seed SEED]

optional arguments:
  -I FILENAME, --inputs-file FILENAME
                        Files containing lists of input files (can use glob syntax) (default: [])
  -i FILENAME, --input FILENAME
                        Input files (can use glob syntax) (default: [])
  -N FILENAME, --negatives-file FILENAME
                        Files containing lists of negative files (can use glob syntax) (default: [])
  -n FILENAME, --negative FILENAME
                        Files that have no annotations (can use glob syntax) (default: [])
  -o FILENAME, --output-file FILENAME
                        optional file to write read filenames into (default: None)
  --seed SEED           the seed to use for randomisation (default: None)
</code></pre>
<h5 id="from-roi-od">FROM-ROI-OD</h5>
<p>Reads image object-detection annotations in the ROI CSV-format</p>
<h6 id="domains_13">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_13">Options:</h6>
<pre><code>usage: from-roi-od [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME]
                   [--seed SEED] [-e FORMAT FORMAT FORMAT] [--prefix READER_PREFIX]
                   [--suffix READER_SUFFIX]

optional arguments:
  -I FILENAME, --inputs-file FILENAME
                        Files containing lists of input files (can use glob syntax) (default: [])
  -i FILENAME, --input FILENAME
                        Input files (can use glob syntax) (default: [])
  -N FILENAME, --negatives-file FILENAME
                        Files containing lists of negative files (can use glob syntax) (default: [])
  -n FILENAME, --negative FILENAME
                        Files that have no annotations (can use glob syntax) (default: [])
  -o FILENAME, --output-file FILENAME
                        optional file to write read filenames into (default: None)
  --seed SEED           the seed to use for randomisation (default: None)
  -e FORMAT FORMAT FORMAT, --extensions FORMAT FORMAT FORMAT
                        image format extensions in order of preference (default: [&lt;ImageFormat.PNG:
                        (frozenset({'png', 'PNG'}), 'PNG')&gt;, &lt;ImageFormat.JPG: (frozenset({'jpeg',
                        'JPG', 'JPEG', 'jpg'}), 'JPEG')&gt;, &lt;ImageFormat.BMP: (frozenset({'bmp',
                        'BMP'}), 'BMP')&gt;])
  --prefix READER_PREFIX
                        the prefix for output filenames (default = '') (default: None)
  --suffix READER_SUFFIX
                        the suffix for output filenames (default = '-rois.csv') (default: None)
</code></pre>
<h5 id="from-subdir-ic">FROM-SUBDIR-IC</h5>
<p>Reads images from sub-directories named after their class labels.</p>
<h6 id="domains_14">Domain(s):</h6>
<ul>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_14">Options:</h6>
<pre><code>usage: from-subdir-ic [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME]
                      [--seed SEED]

optional arguments:
  -I FILENAME, --inputs-file FILENAME
                        Files containing lists of input files (can use glob syntax) (default: [])
  -i FILENAME, --input FILENAME
                        Input files (can use glob syntax) (default: [])
  -N FILENAME, --negatives-file FILENAME
                        Files containing lists of negative files (can use glob syntax) (default: [])
  -n FILENAME, --negative FILENAME
                        Files that have no annotations (can use glob syntax) (default: [])
  -o FILENAME, --output-file FILENAME
                        optional file to write read filenames into (default: None)
  --seed SEED           the seed to use for randomisation (default: None)
</code></pre>
<h5 id="from-tf-od">FROM-TF-OD</h5>
<p>Reads image object-detection annotations in the TFRecords binary format</p>
<h6 id="domains_15">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_15">Options:</h6>
<pre><code>usage: from-tf-od [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME]
                  [--seed SEED] [--mask-threshold THRESHOLD] [--sample-stride STRIDE]

optional arguments:
  -I FILENAME, --inputs-file FILENAME
                        Files containing lists of input files (can use glob syntax) (default: [])
  -i FILENAME, --input FILENAME
                        Input files (can use glob syntax) (default: [])
  -N FILENAME, --negatives-file FILENAME
                        Files containing lists of negative files (can use glob syntax) (default: [])
  -n FILENAME, --negative FILENAME
                        Files that have no annotations (can use glob syntax) (default: [])
  -o FILENAME, --output-file FILENAME
                        optional file to write read filenames into (default: None)
  --seed SEED           the seed to use for randomisation (default: None)
  --mask-threshold THRESHOLD
                        the threshold to use when calculating polygons from masks (default: 0.9)
  --sample-stride STRIDE
                        the stride to use when calculating polygons from masks (default: 1)
</code></pre>
<h5 id="from-vgg-od">FROM-VGG-OD</h5>
<p>Reads image object-detection annotations in the VGG JSON-format</p>
<h6 id="domains_16">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_16">Options:</h6>
<pre><code>usage: from-vgg-od [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME]
                   [--seed SEED]

optional arguments:
  -I FILENAME, --inputs-file FILENAME
                        Files containing lists of input files (can use glob syntax) (default: [])
  -i FILENAME, --input FILENAME
                        Input files (can use glob syntax) (default: [])
  -N FILENAME, --negatives-file FILENAME
                        Files containing lists of negative files (can use glob syntax) (default: [])
  -n FILENAME, --negative FILENAME
                        Files that have no annotations (can use glob syntax) (default: [])
  -o FILENAME, --output-file FILENAME
                        optional file to write read filenames into (default: None)
  --seed SEED           the seed to use for randomisation (default: None)
</code></pre>
<h5 id="from-video-file-od">FROM-VIDEO-FILE-OD</h5>
<p>Reads frames from a video file.</p>
<h6 id="domains_17">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_17">Options:</h6>
<pre><code>usage: from-video-file-od [-f FROM_FRAME] [-i INPUT_FILE] [-m MAX_FRAMES] [-n NTH_FRAME] [-p PREFIX]
                          [-t TO_FRAME]

optional arguments:
  -f FROM_FRAME, --from-frame FROM_FRAME
                        determines with which frame to start the stream (1-based index) (default: 1)
  -i INPUT_FILE, --input INPUT_FILE
                        the video file to read (default: )
  -m MAX_FRAMES, --max-frames MAX_FRAMES
                        determines the maximum number of frames to read; ignored if &lt;=0 (default:
                        -1)
  -n NTH_FRAME, --nth-frame NTH_FRAME
                        determines whether frames get skipped and only evert nth frame gets
                        forwarded (default: 1)
  -p PREFIX, --prefix PREFIX
                        the prefix to use for the frames (default: )
  -t TO_FRAME, --to-frame TO_FRAME
                        determines after which frame to stop (1-based index); ignored if &lt;=0
                        (default: -1)
</code></pre>
<h5 id="from-voc-od">FROM-VOC-OD</h5>
<p>Reads image object-detection annotations in the Pascal VOC XML-format</p>
<h6 id="domains_18">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_18">Options:</h6>
<pre><code>usage: from-voc-od [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME]
                   [--seed SEED]

optional arguments:
  -I FILENAME, --inputs-file FILENAME
                        Files containing lists of input files (can use glob syntax) (default: [])
  -i FILENAME, --input FILENAME
                        Input files (can use glob syntax) (default: [])
  -N FILENAME, --negatives-file FILENAME
                        Files containing lists of negative files (can use glob syntax) (default: [])
  -n FILENAME, --negative FILENAME
                        Files that have no annotations (can use glob syntax) (default: [])
  -o FILENAME, --output-file FILENAME
                        optional file to write read filenames into (default: None)
  --seed SEED           the seed to use for randomisation (default: None)
</code></pre>
<h5 id="from-webcam-od">FROM-WEBCAM-OD</h5>
<p>Reads frames from a webcam.</p>
<h6 id="domains_19">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_19">Options:</h6>
<pre><code>usage: from-webcam-od [-f FROM_FRAME] [-m MAX_FRAMES] [-n NTH_FRAME] [-p PREFIX] [-t TO_FRAME]
                      [-i WEBCAM_ID]

optional arguments:
  -f FROM_FRAME, --from-frame FROM_FRAME
                        determines with which frame to start the stream (1-based index) (default: 1)
  -m MAX_FRAMES, --max-frames MAX_FRAMES
                        determines the maximum number of frames to read; ignored if &lt;=0 (default:
                        -1)
  -n NTH_FRAME, --nth-frame NTH_FRAME
                        determines whether frames get skipped and only evert nth frame gets
                        forwarded (default: 1)
  -p PREFIX, --prefix PREFIX
                        the prefix to use for the frames (default: webcam-)
  -t TO_FRAME, --to-frame TO_FRAME
                        determines after which frame to stop (1-based index); ignored if &lt;=0
                        (default: -1)
  -i WEBCAM_ID, --webcam-id WEBCAM_ID
                        the webcam ID to read from (default: 0)
</code></pre>
<h5 id="from-yolo-od">FROM-YOLO-OD</h5>
<p>Reads image object-detection annotations in the YOLO format</p>
<h6 id="domains_20">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_20">Options:</h6>
<pre><code>usage: from-yolo-od [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME]
                    [--seed SEED] [--image-path-rel PATH] [-l PATH]

optional arguments:
  -I FILENAME, --inputs-file FILENAME
                        Files containing lists of input files (can use glob syntax) (default: [])
  -i FILENAME, --input FILENAME
                        Input files (can use glob syntax) (default: [])
  -N FILENAME, --negatives-file FILENAME
                        Files containing lists of negative files (can use glob syntax) (default: [])
  -n FILENAME, --negative FILENAME
                        Files that have no annotations (can use glob syntax) (default: [])
  -o FILENAME, --output-file FILENAME
                        optional file to write read filenames into (default: None)
  --seed SEED           the seed to use for randomisation (default: None)
  --image-path-rel PATH
                        Relative path to image files from annotations (default: None)
  -l PATH, --labels PATH
                        Path to the labels file (default: None)
</code></pre>
<h4 id="processor-stage">Processor stage</h4>
<h5 id="add-annotation-overlay-ic">ADD-ANNOTATION-OVERLAY-IC</h5>
<p>Adds the image classification label on top of images passing through.</p>
<h6 id="domains_21">Domain(s):</h6>
<ul>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_21">Options:</h6>
<pre><code>usage: add-annotation-overlay-ic [--background-color BACKGROUND_COLOR]
                                 [--background-margin BACKGROUND_MARGIN] [--fill-background]
                                 [--font-color FONT_COLOR] [--font-family FONT_FAMILY]
                                 [--font-size FONT_SIZE] [--position TEXT_PLACEMENT]

optional arguments:
  --background-color BACKGROUND_COLOR
                        the RGB color triplet to use for the background. (default: 0,0,0)
  --background-margin BACKGROUND_MARGIN
                        the margin in pixels around the background. (default: 2)
  --fill-background     whether to fill the background of the text with the specified color.
                        (default: False)
  --font-color FONT_COLOR
                        the RGB color triplet to use for the font. (default: 255,255,255)
  --font-family FONT_FAMILY
                        the name of the TTF font-family to use, note: any hyphens need escaping with
                        backslash. (default: sans\-serif)
  --font-size FONT_SIZE
                        the size of the font. (default: 14)
  --position TEXT_PLACEMENT
                        the position of the label (X,Y). (default: 5,5)
</code></pre>
<h5 id="add-annotation-overlay-is">ADD-ANNOTATION-OVERLAY-IS</h5>
<p>Adds the image segmentation annotations on top of images passing through.</p>
<h6 id="domains_22">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
</ul>
<h6 id="options_22">Options:</h6>
<pre><code>usage: add-annotation-overlay-is [--alpha ALPHA] [--colors COLORS [COLORS ...]]
                                 [--labels LABELS [LABELS ...]]

optional arguments:
  --alpha ALPHA         the alpha value to use for overlaying the annotations (0: transparent, 255:
                        opaque). (default: 64)
  --colors COLORS [COLORS ...]
                        the RGB triplets (R,G,B) of custom colors to use, uses default colors if not
                        supplied (default: [])
  --labels LABELS [LABELS ...]
                        the labels of annotations to overlay, overlays all if omitted (default: [])
</code></pre>
<h5 id="add-annotation-overlay-od">ADD-ANNOTATION-OVERLAY-OD</h5>
<p>Adds object detection overlays to images passing through.</p>
<h6 id="domains_23">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_23">Options:</h6>
<pre><code>usage: add-annotation-overlay-od [--colors COLORS [COLORS ...]] [--fill] [--fill-alpha FILL_ALPHA]
                                 [--font-family FONT_FAMILY] [--font-size FONT_SIZE] [--force-bbox]
                                 [--label-key LABEL_KEY] [--labels LABELS [LABELS ...]]
                                 [--num-decimals NUM_DECIMALS] [--outline-alpha OUTLINE_ALPHA]
                                 [--outline-thickness OUTLINE_THICKNESS] [--text-format TEXT_FORMAT]
                                 [--text-placement TEXT_PLACEMENT] [--vary-colors]

optional arguments:
  --colors COLORS [COLORS ...]
                        the RGB triplets (R,G,B) of custom colors to use, uses default colors if not
                        supplied (default: [])
  --fill                whether to fill the bounding boxes/polygons (default: False)
  --fill-alpha FILL_ALPHA
                        the alpha value to use for the filling (0: transparent, 255: opaque).
                        (default: 128)
  --font-family FONT_FAMILY
                        the name of the TTF font-family to use, note: any hyphens need escaping with
                        backslash. (default: sans\-serif)
  --font-size FONT_SIZE
                        the size of the font. (default: 14)
  --force-bbox          whether to force a bounding box even if there is a polygon available
                        (default: False)
  --label-key LABEL_KEY
                        the key in the meta-data that contains the label. (default: type)
  --labels LABELS [LABELS ...]
                        the labels of annotations to overlay, overlays all if omitted (default: [])
  --num-decimals NUM_DECIMALS
                        the number of decimals to use for float numbers in the text format string.
                        (default: 3)
  --outline-alpha OUTLINE_ALPHA
                        the alpha value to use for the outline (0: transparent, 255: opaque).
                        (default: 255)
  --outline-thickness OUTLINE_THICKNESS
                        the line thickness to use for the outline, &lt;1 to turn off. (default: 3)
  --text-format TEXT_FORMAT
                        template for the text to print on top of the bounding box or polygon, '{PH}'
                        is a placeholder for the 'PH' value from the meta-data or 'label' for the
                        current label; ignored if empty. (default: {label})
  --text-placement TEXT_PLACEMENT
                        comma-separated list of vertical (T=top, C=center, B=bottom) and horizontal
                        (L=left, C=center, R=right) anchoring. (default: T,L)
  --vary-colors         whether to vary the colors of the outline/filling regardless of label
                        (default: False)
</code></pre>
<h5 id="check-duplicate-filenames">CHECK-DUPLICATE-FILENAMES</h5>
<p>Causes the conversion stream to halt when multiple dataset items have the same filename</p>
<h6 id="domains_24">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
<li><strong>Image Object-Detection Domain</strong></li>
<li><strong>Speech Domain</strong></li>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_24">Options:</h6>
<pre><code>usage: check-duplicate-filenames
</code></pre>
<h5 id="coerce-box">COERCE-BOX</h5>
<p>Converts all annotation bounds into box regions</p>
<h6 id="domains_25">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_25">Options:</h6>
<pre><code>usage: coerce-box
</code></pre>
<h5 id="coerce-mask">COERCE-MASK</h5>
<p>Converts all annotation bounds into polygon regions</p>
<h6 id="domains_26">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_26">Options:</h6>
<pre><code>usage: coerce-mask
</code></pre>
<h5 id="combine-annotations-od">COMBINE-ANNOTATIONS-OD</h5>
<p>Combines object detection annotations from images passing through into a single annotation.</p>
<h6 id="domains_27">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_27">Options:</h6>
<pre><code>usage: combine-annotations-od [--combination COMBINATION] [--min-iou MIN_IOU]

optional arguments:
  --combination COMBINATION
                        how to combine the annotations (union|intersect); the 'stream_index' key in
                        the meta-data contains the stream index (default: intersect)
  --min-iou MIN_IOU     the minimum IoU (intersect over union) to use for identifying objects that
                        overlap (default: 0.7)
</code></pre>
<h5 id="convert-image-format">CONVERT-IMAGE-FORMAT</h5>
<p>Converts images from one format to another</p>
<h6 id="domains_28">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
<li><strong>Image Object-Detection Domain</strong></li>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_28">Options:</h6>
<pre><code>usage: convert-image-format -f FORMAT

optional arguments:
  -f FORMAT, --format FORMAT
                        format to convert images to (default: None)
</code></pre>
<h5 id="crop">CROP</h5>
<p>Crops images.</p>
<h6 id="domains_29">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_29">Options:</h6>
<pre><code>usage: crop [-m IMGAUG_MODE] [--suffix IMGAUG_SUFFIX] [-f PERCENT_FROM] [-t PERCENT_TO] [-s SEED]
            [-a] [-T THRESHOLD] [-u]

optional arguments:
  -m IMGAUG_MODE, --mode IMGAUG_MODE
                        the image augmentation mode to use, available modes: replace, add (default:
                        replace)
  --suffix IMGAUG_SUFFIX
                        the suffix to use for the file names in case of augmentation mode add
                        (default: None)
  -f PERCENT_FROM, --from-percent PERCENT_FROM
                        the minimum percent to crop from images (default: None)
  -t PERCENT_TO, --to-percent PERCENT_TO
                        the maximum percent to crop from images (default: None)
  -s SEED, --seed SEED  the seed value to use for the random number generator; randomly seeded if
                        not provided (default: None)
  -a, --seed-augmentation
                        whether to seed the augmentation; if specified, uses the seeded random
                        generator to produce a seed value from 0 to 1000 for the augmentation.
                        (default: False)
  -T THRESHOLD, --threshold THRESHOLD
                        the threshold to use for Random.rand(): if equal or above, augmentation gets
                        applied; range: 0-1; default: 0 (= always) (default: None)
  -u, --update-size     whether to update the image size after the crop operation or scale back to
                        original size (default: False)
</code></pre>
<h5 id="dimension-discarder">DIMENSION-DISCARDER</h5>
<p>Removes annotations which fall outside certain size constraints</p>
<h6 id="domains_30">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_30">Options:</h6>
<pre><code>usage: dimension-discarder [--max-area MAX_AREA] [--max-height MAX_HEIGHT] [--max-width MAX_WIDTH]
                           [--min-area MIN_AREA] [--min-height MIN_HEIGHT] [--min-width MIN_WIDTH]
                           [--verbose]

optional arguments:
  --max-area MAX_AREA   the maximum area of annotations to convert (default: None)
  --max-height MAX_HEIGHT
                        the maximum height of annotations to convert (default: None)
  --max-width MAX_WIDTH
                        the maximum width of annotations to convert (default: None)
  --min-area MIN_AREA   the minimum area of annotations to convert (default: None)
  --min-height MIN_HEIGHT
                        the minimum height of annotations to convert (default: None)
  --min-width MIN_WIDTH
                        the minimum width of annotations to convert (default: None)
  --verbose             outputs information when discarding annotations (default: False)
</code></pre>
<h5 id="discard-invalid-images">DISCARD-INVALID-IMAGES</h5>
<p>Discards images that cannot be loaded (e.g., corrupt image file or annotations with no image)</p>
<h6 id="domains_31">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
<li><strong>Image Object-Detection Domain</strong></li>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_31">Options:</h6>
<pre><code>usage: discard-invalid-images [-v]

optional arguments:
  -v, --verbose  whether to output debugging information (default: False)
</code></pre>
<h5 id="discard-negatives">DISCARD-NEGATIVES</h5>
<p>Discards negative examples (those without annotations) from the stream</p>
<h6 id="domains_32">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
<li><strong>Image Object-Detection Domain</strong></li>
<li><strong>Speech Domain</strong></li>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_32">Options:</h6>
<pre><code>usage: discard-negatives
</code></pre>
<h5 id="drop-frames">DROP-FRAMES</h5>
<p>Drops frames from the stream.</p>
<h6 id="domains_33">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
<li><strong>Image Object-Detection Domain</strong></li>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_33">Options:</h6>
<pre><code>usage: drop-frames [-n NTH_FRAME]

optional arguments:
  -n NTH_FRAME, --nth-frame NTH_FRAME
                        which nth frame to drop, e..g, '2' means to drop every 2nd frame; passes
                        frames through if &lt;=1 (default: 0)
</code></pre>
<h5 id="filter-frames-by-label-od">FILTER-FRAMES-BY-LABEL-OD</h5>
<p>Filters frames from the stream using the labels in the annotations, i.e., keeps or drops frames depending on presence/absence of labels.</p>
<h6 id="domains_34">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
<li><strong>Image Object-Detection Domain</strong></li>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_34">Options:</h6>
<pre><code>usage: filter-frames-by-label-od [--excluded-labels EXCLUDED_LABELS] [--key-label KEY_LABEL]
                                 [--key-score KEY_SCORE] [--min-score MIN_SCORE]
                                 [--required-labels REQUIRED_LABELS] [-v]

optional arguments:
  --excluded-labels EXCLUDED_LABELS
                        the comma-separated list of labels that will automatically drop the frame
                        when present in the frame (default: )
  --key-label KEY_LABEL
                        the meta-data key in the annotations that contains the label. (default:
                        type)
  --key-score KEY_SCORE
                        the meta-data key in the annotations to use for storing the prediction
                        score. (default: score)
  --min-score MIN_SCORE
                        the minimum score that predictions must have in order to be included in the
                        label checks, ignored if not supplied (default: None)
  --required-labels REQUIRED_LABELS
                        the comma-separated list of labels that must be present in the frame,
                        otherwise it gets dropped (default: )
  -v, --verbose         whether to output debugging information. (default: False)
</code></pre>
<h5 id="filter-labels">FILTER-LABELS</h5>
<p>Filters detected objects down to those with specified labels.</p>
<h6 id="domains_35">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_35">Options:</h6>
<pre><code>usage: filter-labels [-l LABELS [LABELS ...]] [-r regexp]

optional arguments:
  -l LABELS [LABELS ...], --labels LABELS [LABELS ...]
                        labels to use (default: [])
  -r regexp, --regexp regexp
                        regular expression for using only a subset of labels (default: None)
</code></pre>
<h5 id="filter-metadata">FILTER-METADATA</h5>
<p>Filters detected objects based on their meta-data.</p>
<h6 id="domains_36">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_36">Options:</h6>
<pre><code>usage: filter-metadata [-c COMPARISON] [-k KEY] [-t VALUE_TYPE]

optional arguments:
  -c COMPARISON, --comparison COMPARISON
                        the comparison to apply to the value: for bool/numeric/string '=OTHER' and
                        '!=OTHER' can be used, for numeric furthermore '&lt;OTHER', '&lt;=OTHER',
                        '&gt;=OTHER', '&gt;OTHER'. E.g.: '&lt;3.0' for numeric types will discard any
                        annotations that have a value of 3.0 or larger (default: None)
  -k KEY, --key KEY     the key of the meta-data value to use for the filtering (default: None)
  -t VALUE_TYPE, --value-type VALUE_TYPE
                        the data type that the value represents, available options:
                        bool|numeric|string (default: None)
</code></pre>
<h5 id="flip">FLIP</h5>
<p>Flips images either left-to-right, up-to-down or both.</p>
<h6 id="domains_37">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_37">Options:</h6>
<pre><code>usage: flip [-d DIRECTION] [-m IMGAUG_MODE] [--suffix IMGAUG_SUFFIX] [-s SEED] [-a] [-T THRESHOLD]

optional arguments:
  -d DIRECTION, --direction DIRECTION
                        the direction to flip, available options: lr, up, lrup (default: None)
  -m IMGAUG_MODE, --mode IMGAUG_MODE
                        the image augmentation mode to use, available modes: replace, add (default:
                        replace)
  --suffix IMGAUG_SUFFIX
                        the suffix to use for the file names in case of augmentation mode add
                        (default: None)
  -s SEED, --seed SEED  the seed value to use for the random number generator; randomly seeded if
                        not provided (default: None)
  -a, --seed-augmentation
                        whether to seed the augmentation; if specified, uses the seeded random
                        generator to produce a seed value from 0 to 1000 for the augmentation.
                        (default: False)
  -T THRESHOLD, --threshold THRESHOLD
                        the threshold to use for Random.rand(): if equal or above, augmentation gets
                        applied; range: 0-1; default: 0 (= always) (default: None)
</code></pre>
<h5 id="gaussian-blur">GAUSSIAN-BLUR</h5>
<p>Applies gaussian blur to images.</p>
<h6 id="domains_38">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_38">Options:</h6>
<pre><code>usage: gaussian-blur [-m IMGAUG_MODE] [--suffix IMGAUG_SUFFIX] [-s SEED] [-a] [-f SIGMA_FROM]
                     [-t SIGMA_TO] [-T THRESHOLD]

optional arguments:
  -m IMGAUG_MODE, --mode IMGAUG_MODE
                        the image augmentation mode to use, available modes: replace, add (default:
                        replace)
  --suffix IMGAUG_SUFFIX
                        the suffix to use for the file names in case of augmentation mode add
                        (default: None)
  -s SEED, --seed SEED  the seed value to use for the random number generator; randomly seeded if
                        not provided (default: None)
  -a, --seed-augmentation
                        whether to seed the augmentation; if specified, uses the seeded random
                        generator to produce a seed value from 0 to 1000 for the augmentation.
                        (default: False)
  -f SIGMA_FROM, --from-sigma SIGMA_FROM
                        the minimum sigma for the blur to apply to the images (default: None)
  -t SIGMA_TO, --to-sigma SIGMA_TO
                        the maximum sigma for the blur to apply to the images (default: None)
  -T THRESHOLD, --threshold THRESHOLD
                        the threshold to use for Random.rand(): if equal or above, augmentation gets
                        applied; range: 0-1; default: 0 (= always) (default: None)
</code></pre>
<h5 id="hsl-grayscale">HSL-GRAYSCALE</h5>
<p>Turns RGB images into fake grayscale ones by converting them to HSL and then using the L channel for all channels. The brightness can be influenced and varied even.</p>
<h6 id="domains_39">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_39">Options:</h6>
<pre><code>usage: hsl-grayscale [-f FACTOR_FROM] [-t FACTOR_TO] [-m IMGAUG_MODE] [--suffix IMGAUG_SUFFIX]
                     [-s SEED] [-a] [-T THRESHOLD]

optional arguments:
  -f FACTOR_FROM, --from-factor FACTOR_FROM
                        the start of the factor range to apply to the L channel to darken or lighten
                        the image (&lt;1: darker, &gt;1: lighter) (default: None)
  -t FACTOR_TO, --to-factor FACTOR_TO
                        the end of the factor range to apply to the L channel to darken or lighten
                        the image (&lt;1: darker, &gt;1: lighter) (default: None)
  -m IMGAUG_MODE, --mode IMGAUG_MODE
                        the image augmentation mode to use, available modes: replace, add (default:
                        replace)
  --suffix IMGAUG_SUFFIX
                        the suffix to use for the file names in case of augmentation mode add
                        (default: None)
  -s SEED, --seed SEED  the seed value to use for the random number generator; randomly seeded if
                        not provided (default: None)
  -a, --seed-augmentation
                        whether to seed the augmentation; if specified, uses the seeded random
                        generator to produce a seed value from 0 to 1000 for the augmentation.
                        (default: False)
  -T THRESHOLD, --threshold THRESHOLD
                        the threshold to use for Random.rand(): if equal or above, augmentation gets
                        applied; range: 0-1; default: 0 (= always) (default: None)
</code></pre>
<h5 id="linear-contrast">LINEAR-CONTRAST</h5>
<p>Applies linear contrast to images.</p>
<h6 id="domains_40">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_40">Options:</h6>
<pre><code>usage: linear-contrast [-f ALPHA_FROM] [-t ALPHA_TO] [-m IMGAUG_MODE] [--suffix IMGAUG_SUFFIX]
                       [-s SEED] [-a] [-T THRESHOLD]

optional arguments:
  -f ALPHA_FROM, --from-alpha ALPHA_FROM
                        the minimum alpha to apply to the images (default: None)
  -t ALPHA_TO, --to-alpha ALPHA_TO
                        the maximum alpha to apply to the images (default: None)
  -m IMGAUG_MODE, --mode IMGAUG_MODE
                        the image augmentation mode to use, available modes: replace, add (default:
                        replace)
  --suffix IMGAUG_SUFFIX
                        the suffix to use for the file names in case of augmentation mode add
                        (default: None)
  -s SEED, --seed SEED  the seed value to use for the random number generator; randomly seeded if
                        not provided (default: None)
  -a, --seed-augmentation
                        whether to seed the augmentation; if specified, uses the seeded random
                        generator to produce a seed value from 0 to 1000 for the augmentation.
                        (default: False)
  -T THRESHOLD, --threshold THRESHOLD
                        the threshold to use for Random.rand(): if equal or above, augmentation gets
                        applied; range: 0-1; default: 0 (= always) (default: None)
</code></pre>
<h5 id="map-labels">MAP-LABELS</h5>
<p>Maps object-detection labels from one set to another</p>
<h6 id="domains_41">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_41">Options:</h6>
<pre><code>usage: map-labels [-m old=new]

optional arguments:
  -m old=new, --mapping old=new
                        mapping for labels, for replacing one label string with another (eg when
                        fixing/collapsing labels) (default: [])
</code></pre>
<h5 id="od-to-ic">OD-TO-IC</h5>
<p>Converts image object-detection instances into image classification instances</p>
<h6 id="domains_42">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_42">Options:</h6>
<pre><code>usage: od-to-ic [-m HANDLER]

optional arguments:
  -m HANDLER, --multiplicity HANDLER
                        how to handle instances with more than one located object (default: error)
</code></pre>
<h5 id="od-to-is">OD-TO-IS</h5>
<p>Converts image object-detection instances into image segmentation instances</p>
<h6 id="domains_43">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_43">Options:</h6>
<pre><code>usage: od-to-is [--label-error] --labels LABEL [LABEL ...]

optional arguments:
  --label-error         whether to raise errors when an unspecified label is encountered (default is
                        to ignore) (default: False)
  --labels LABEL [LABEL ...]
                        specifies the labels for each index (default: None)
</code></pre>
<h5 id="passthrough">PASSTHROUGH</h5>
<p>Dummy ISP which has no effect on the conversion stream</p>
<h6 id="domains_44">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
<li><strong>Image Object-Detection Domain</strong></li>
<li><strong>Speech Domain</strong></li>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_44">Options:</h6>
<pre><code>usage: passthrough
</code></pre>
<h5 id="polygon-discarder">POLYGON-DISCARDER</h5>
<p>Removes annotations with polygons which fall outside certain point limit constraints</p>
<h6 id="domains_45">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_45">Options:</h6>
<pre><code>usage: polygon-discarder [--max-points MAX_POINTS] [--min-points MIN_POINTS] [--verbose]

optional arguments:
  --max-points MAX_POINTS
                        the maximum number of points in the polygon (default: None)
  --min-points MIN_POINTS
                        the minimum number of points in the polygon (default: None)
  --verbose             outputs information when discarding annotations (default: False)
</code></pre>
<h5 id="redis-predict-ic">REDIS-PREDICT-IC</h5>
<p>Makes image classification predictions via Redis backend, passing in an image and receiving JSON predictions back (at least one of 'label: probability').
Predictions example:
{"dog": 0.9, "cat": 0.1}</p>
<h6 id="domains_46">Domain(s):</h6>
<ul>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_46">Options:</h6>
<pre><code>usage: redis-predict-ic [--channel-in CHANNEL_IN] [--channel-out CHANNEL_OUT] [-d REDIS_DB]
                        [-h REDIS_HOST] [-p REDIS_PORT] [-t TIMEOUT] [-v]

optional arguments:
  --channel-in CHANNEL_IN
                        the Redis channel on which to receive predictions. (default: predictions)
  --channel-out CHANNEL_OUT
                        the Redis channel to send the images out (default: images)
  -d REDIS_DB, --redis-db REDIS_DB
                        the database to use (default: 0)
  -h REDIS_HOST, --redis-host REDIS_HOST
                        the Redis server to connect to (default: localhost)
  -p REDIS_PORT, --redis-port REDIS_PORT
                        the port the Redis server is running on (default: 6379)
  -t TIMEOUT, --timeout TIMEOUT
                        the timeout in seconds to wait for a prediction to arrive (default: 5.0)
  -v, --verbose         whether to output debugging information. (default: False)
</code></pre>
<h5 id="redis-predict-is">REDIS-PREDICT-IS</h5>
<p>Makes image segmentation predictions via Redis backend, passing in an image and receiving an image with predicted segmentations.</p>
<h6 id="domains_47">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
</ul>
<h6 id="options_47">Options:</h6>
<pre><code>usage: redis-predict-is [--channel-in CHANNEL_IN] [--channel-out CHANNEL_OUT]
                        [--image-format IMAGE_FORMAT] --labels LABEL [LABEL ...] [-d REDIS_DB]
                        [-h REDIS_HOST] [-p REDIS_PORT] [-t TIMEOUT] [-v]

optional arguments:
  --channel-in CHANNEL_IN
                        the Redis channel on which to receive predictions. (default: predictions)
  --channel-out CHANNEL_OUT
                        the Redis channel to send the images out (default: images)
  --image-format IMAGE_FORMAT
                        the format of the image that comes back as prediction:
                        indexedpng,bluechannel,grayscale (default: indexedpng)
  --labels LABEL [LABEL ...]
                        specifies the labels for each index (default: None)
  -d REDIS_DB, --redis-db REDIS_DB
                        the database to use (default: 0)
  -h REDIS_HOST, --redis-host REDIS_HOST
                        the Redis server to connect to (default: localhost)
  -p REDIS_PORT, --redis-port REDIS_PORT
                        the port the Redis server is running on (default: 6379)
  -t TIMEOUT, --timeout TIMEOUT
                        the timeout in seconds to wait for a prediction to arrive (default: 5.0)
  -v, --verbose         whether to output debugging information. (default: False)
</code></pre>
<h5 id="redis-predict-od">REDIS-PREDICT-OD</h5>
<p>Makes object detection predictions via Redis backend, passing in an image and receiving OPEX predictions back:
https://github.com/WaikatoLink2020/objdet-predictions-exchange-format</p>
<h6 id="domains_48">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_48">Options:</h6>
<pre><code>usage: redis-predict-od [--channel-in CHANNEL_IN] [--channel-out CHANNEL_OUT]
                        [--key-label KEY_LABEL] [--key-score KEY_SCORE] [-d REDIS_DB]
                        [-h REDIS_HOST] [-p REDIS_PORT] [-t TIMEOUT] [-v]

optional arguments:
  --channel-in CHANNEL_IN
                        the Redis channel on which to receive predictions. (default: predictions)
  --channel-out CHANNEL_OUT
                        the Redis channel to send the images out (default: images)
  --key-label KEY_LABEL
                        the meta-data key in the annotations to use for storing the label. (default:
                        type)
  --key-score KEY_SCORE
                        the meta-data key in the annotations to use for storing the prediction
                        score. (default: score)
  -d REDIS_DB, --redis-db REDIS_DB
                        the database to use (default: 0)
  -h REDIS_HOST, --redis-host REDIS_HOST
                        the Redis server to connect to (default: localhost)
  -p REDIS_PORT, --redis-port REDIS_PORT
                        the port the Redis server is running on (default: 6379)
  -t TIMEOUT, --timeout TIMEOUT
                        the timeout in seconds to wait for a prediction to arrive (default: 5.0)
  -v, --verbose         whether to output debugging information. (default: False)
</code></pre>
<h5 id="remove-classes">REMOVE-CLASSES</h5>
<p>Removes classes from classification/image-segmentation instances</p>
<h6 id="domains_49">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_49">Options:</h6>
<pre><code>usage: remove-classes -c CLASS [CLASS ...]

optional arguments:
  -c CLASS [CLASS ...], --classes CLASS [CLASS ...]
                        the classes to remove (default: None)
</code></pre>
<h5 id="rotate">ROTATE</h5>
<p>Rotates images randomly within a range of degrees or by a specified degree. Specify seed value and force augmentation to be seeded to generate repeatable augmentations.</p>
<h6 id="domains_50">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_50">Options:</h6>
<pre><code>usage: rotate [-f DEGREE_FROM] [-t DEGREE_TO] [-m IMGAUG_MODE] [--suffix IMGAUG_SUFFIX] [-s SEED]
              [-a] [-T THRESHOLD]

optional arguments:
  -f DEGREE_FROM, --from-degree DEGREE_FROM
                        the start of the degree range to use for rotating the images (default: None)
  -t DEGREE_TO, --to-degree DEGREE_TO
                        the end of the degree range to use for rotating the images (default: None)
  -m IMGAUG_MODE, --mode IMGAUG_MODE
                        the image augmentation mode to use, available modes: replace, add (default:
                        replace)
  --suffix IMGAUG_SUFFIX
                        the suffix to use for the file names in case of augmentation mode add
                        (default: None)
  -s SEED, --seed SEED  the seed value to use for the random number generator; randomly seeded if
                        not provided (default: None)
  -a, --seed-augmentation
                        whether to seed the augmentation; if specified, uses the seeded random
                        generator to produce a seed value from 0 to 1000 for the augmentation.
                        (default: False)
  -T THRESHOLD, --threshold THRESHOLD
                        the threshold to use for Random.rand(): if equal or above, augmentation gets
                        applied; range: 0-1; default: 0 (= always) (default: None)
</code></pre>
<h5 id="scale">SCALE</h5>
<p>Scales images randomly within a range of percentages or by a specified percentage. Specify seed value and force augmentation to be seeded to generate repeatable augmentations.</p>
<h6 id="domains_51">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_51">Options:</h6>
<pre><code>usage: scale [-m IMGAUG_MODE] [--suffix IMGAUG_SUFFIX] [-k] [-f PERCENTAGE_FROM] [-t PERCENTAGE_TO]
             [-s SEED] [-a] [-T THRESHOLD] [-u]

optional arguments:
  -m IMGAUG_MODE, --mode IMGAUG_MODE
                        the image augmentation mode to use, available modes: replace, add (default:
                        replace)
  --suffix IMGAUG_SUFFIX
                        the suffix to use for the file names in case of augmentation mode add
                        (default: None)
  -k, --keep-aspect     whether to keep the aspect ratio (default: False)
  -f PERCENTAGE_FROM, --from-percentage PERCENTAGE_FROM
                        the start of the percentage range to use for scaling the images (default:
                        None)
  -t PERCENTAGE_TO, --to-percentage PERCENTAGE_TO
                        the end of the percentage range to use for scaling the images (default:
                        None)
  -s SEED, --seed SEED  the seed value to use for the random number generator; randomly seeded if
                        not provided (default: None)
  -a, --seed-augmentation
                        whether to seed the augmentation; if specified, uses the seeded random
                        generator to produce a seed value from 0 to 1000 for the augmentation.
                        (default: False)
  -T THRESHOLD, --threshold THRESHOLD
                        the threshold to use for Random.rand(): if equal or above, augmentation gets
                        applied; range: 0-1; default: 0 (= always) (default: None)
  -u, --update-size     whether to update the image size after the scaling operation or use original
                        size (default: False)
</code></pre>
<h5 id="skip-similar-frames">SKIP-SIMILAR-FRAMES</h5>
<p>Skips frames in the stream that are deemed too similar.</p>
<h6 id="domains_52">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
<li><strong>Image Object-Detection Domain</strong></li>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_52">Options:</h6>
<pre><code>usage: skip-similar-frames [-b BW_THRESHOLD] [-t CHANGE_THRESHOLD] [-c CONVERSION] [-v]

optional arguments:
  -b BW_THRESHOLD, --bw-threshold BW_THRESHOLD
                        the threshold to use for converting a gray-scale like image to black and
                        white (0-255) (default: 128)
  -t CHANGE_THRESHOLD, --change-threshold CHANGE_THRESHOLD
                        the percentage of pixels that changed relative to size of image (0-1)
                        (default: 0.01)
  -c CONVERSION, --conversion CONVERSION
                        how to convert the BGR image to a single channel image (gray/r/g/b)
                        (default: gray)
  -v, --verbose         whether to output some debugging output. (default: False)
</code></pre>
<h5 id="strip-annotations">STRIP-ANNOTATIONS</h5>
<p>ISP which removes annotations from instances</p>
<h6 id="domains_53">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
<li><strong>Image Object-Detection Domain</strong></li>
<li><strong>Speech Domain</strong></li>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_53">Options:</h6>
<pre><code>usage: strip-annotations
</code></pre>
<h5 id="sub-images">SUB-IMAGES</h5>
<p>Extracts sub-images (incl their annotations) from the images coming through, using the defined regions.</p>
<h6 id="domains_54">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_54">Options:</h6>
<pre><code>usage: sub-images [-p] [-s REGION_SORTING] [-r REGIONS [REGIONS ...]] [-e]

optional arguments:
  -p, --include-partial
                        whether to include only annotations that fit fully into a region or also
                        partial ones (default: False)
  -s REGION_SORTING, --region-sorting REGION_SORTING
                        how to sort the supplied region definitions: none|x-then-y|y-then-x
                        (default: none)
  -r REGIONS [REGIONS ...], --regions REGIONS [REGIONS ...]
                        the regions (X,Y,WIDTH,HEIGHT) to crop and forward with their annotations
                        (default: [])
  -e, --suppress-empty  suppresses sub-images that have no annotations (object detection) (default:
                        False)
</code></pre>
<h4 id="sink-stage">Sink stage</h4>
<h5 id="area-histogram-is">AREA-HISTOGRAM-IS</h5>
<p>Generates histograms of the area (normalized or absolute) occupied by the annotations.</p>
<h6 id="domains_55">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
</ul>
<h6 id="options_55">Options:</h6>
<pre><code>usage: area-histogram-is [-a ALL_LABEL] [-b] [--label-key LABEL_KEY] [-n] [--num-bins NUM_BINS]
                         [-o OUTPUT_FILE] [-f OUTPUT_FORMAT]

optional arguments:
  -a ALL_LABEL, --all-label ALL_LABEL
                        the label to use for all the labels combined (default: ALL)
  -b, --force-bbox      whether to use the bounding box even if a polygon is present (object
                        detection domain only) (default: False)
  --label-key LABEL_KEY
                        the key in the meta-data that contains the label. (default: type)
  -n, --normalized      whether to use normalized areas (using the image size as base). (default:
                        False)
  --num-bins NUM_BINS   the number of bins to use for the histogram. (default: 20)
  -o OUTPUT_FILE, --output OUTPUT_FILE
                        the file to write the histogram to; uses stdout if omitted (default: )
  -f OUTPUT_FORMAT, --format OUTPUT_FORMAT
                        the format to use for the output, available modes: csv, json (default: text)
</code></pre>
<h5 id="area-histogram-od">AREA-HISTOGRAM-OD</h5>
<p>Generates histograms of the area (normalized or absolute) occupied by the annotations.</p>
<h6 id="domains_56">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_56">Options:</h6>
<pre><code>usage: area-histogram-od [-a ALL_LABEL] [-b] [--label-key LABEL_KEY] [-n] [--num-bins NUM_BINS]
                         [-o OUTPUT_FILE] [-f OUTPUT_FORMAT]

optional arguments:
  -a ALL_LABEL, --all-label ALL_LABEL
                        the label to use for all the labels combined (default: ALL)
  -b, --force-bbox      whether to use the bounding box even if a polygon is present (object
                        detection domain only) (default: False)
  --label-key LABEL_KEY
                        the key in the meta-data that contains the label. (default: type)
  -n, --normalized      whether to use normalized areas (using the image size as base). (default:
                        False)
  --num-bins NUM_BINS   the number of bins to use for the histogram. (default: 20)
  -o OUTPUT_FILE, --output OUTPUT_FILE
                        the file to write the histogram to; uses stdout if omitted (default: )
  -f OUTPUT_FORMAT, --format OUTPUT_FORMAT
                        the format to use for the output, available modes: csv, json (default: text)
</code></pre>
<h5 id="calc-frame-changes">CALC-FRAME-CHANGES</h5>
<p>Calculates the changes between frames, which can be used with the skip-similar-frames ISP.</p>
<h6 id="domains_57">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_57">Options:</h6>
<pre><code>usage: calc-frame-changes [-b BW_THRESHOLD] [-t CHANGE_THRESHOLD] [-c CONVERSION] [-B NUM_BINS]
                          [-o OUTPUT_FILE] [-f OUTPUT_FORMAT] [-v]

optional arguments:
  -b BW_THRESHOLD, --bw-threshold BW_THRESHOLD
                        the threshold to use for converting a gray-scale like image to black and
                        white (0-255) (default: 128)
  -t CHANGE_THRESHOLD, --change-threshold CHANGE_THRESHOLD
                        the percentage of pixels that changed relative to size of image (0-1)
                        (default: 0.01)
  -c CONVERSION, --conversion CONVERSION
                        how to convert the BGR image to a single channel image (gray/r/g/b)
                        (default: gray)
  -B NUM_BINS, --num-bins NUM_BINS
                        the number of bins to use for the histogram (default: 20)
  -o OUTPUT_FILE, --output OUTPUT_FILE
                        the file to write to statistics to, stdout if not provided (default: )
  -f OUTPUT_FORMAT, --output-format OUTPUT_FORMAT
                        how to output the statistics (text/csv/json) (default: text)
  -v, --verbose         whether to output some debugging output. (default: False)
</code></pre>
<h5 id="image-viewer-ic">IMAGE-VIEWER-IC</h5>
<p>Displays image classification images.</p>
<h6 id="domains_58">Domain(s):</h6>
<ul>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_58">Options:</h6>
<pre><code>usage: image-viewer-ic [--delay DELAY] [--position POSITION] [--size SIZE] [--title TITLE]

optional arguments:
  --delay DELAY        the delay in milli-seconds between images, use 0 to wait for keypress,
                       ignored if &lt;0 (default: 500)
  --position POSITION  the position of the window on screen (X,Y) (default: 0,0)
  --size SIZE          the maximum size for the image: WIDTH,HEIGHT (default: 640,480)
  --title TITLE        the title for the window (default: wai.annotations)
</code></pre>
<h5 id="image-viewer-is">IMAGE-VIEWER-IS</h5>
<p>Displays image segmentation images.</p>
<h6 id="domains_59">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
</ul>
<h6 id="options_59">Options:</h6>
<pre><code>usage: image-viewer-is [--delay DELAY] [--position POSITION] [--size SIZE] [--title TITLE]

optional arguments:
  --delay DELAY        the delay in milli-seconds between images, use 0 to wait for keypress,
                       ignored if &lt;0 (default: 500)
  --position POSITION  the position of the window on screen (X,Y) (default: 0,0)
  --size SIZE          the maximum size for the image: WIDTH,HEIGHT (default: 640,480)
  --title TITLE        the title for the window (default: wai.annotations)
</code></pre>
<h5 id="image-viewer-od">IMAGE-VIEWER-OD</h5>
<p>Displays object detection images.</p>
<h6 id="domains_60">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_60">Options:</h6>
<pre><code>usage: image-viewer-od [--delay DELAY] [--position POSITION] [--size SIZE] [--title TITLE]

optional arguments:
  --delay DELAY        the delay in milli-seconds between images, use 0 to wait for keypress,
                       ignored if &lt;0 (default: 500)
  --position POSITION  the position of the window on screen (X,Y) (default: 0,0)
  --size SIZE          the maximum size for the image: WIDTH,HEIGHT (default: 640,480)
  --title TITLE        the title for the window (default: wai.annotations)
</code></pre>
<h5 id="label-dist-ic">LABEL-DIST-IC</h5>
<p>Generates a label distribution.</p>
<h6 id="domains_61">Domain(s):</h6>
<ul>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_61">Options:</h6>
<pre><code>usage: label-dist-ic [--label-key LABEL_KEY] [-o OUTPUT_FILE] [-f OUTPUT_FORMAT] [-p]

optional arguments:
  --label-key LABEL_KEY
                        the key in the meta-data that contains the label. (default: type)
  -o OUTPUT_FILE, --output OUTPUT_FILE
                        the file to write the statistics to; uses stdout if omitted (default: )
  -f OUTPUT_FORMAT, --format OUTPUT_FORMAT
                        the format to use for the output, available modes: csv, json (default: text)
  -p, --percentages     whether to output percentages instead of counts. (default: False)
</code></pre>
<h5 id="label-dist-is">LABEL-DIST-IS</h5>
<p>Generates a label distribution.</p>
<h6 id="domains_62">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
</ul>
<h6 id="options_62">Options:</h6>
<pre><code>usage: label-dist-is [--label-key LABEL_KEY] [-o OUTPUT_FILE] [-f OUTPUT_FORMAT] [-p]

optional arguments:
  --label-key LABEL_KEY
                        the key in the meta-data that contains the label. (default: type)
  -o OUTPUT_FILE, --output OUTPUT_FILE
                        the file to write the statistics to; uses stdout if omitted (default: )
  -f OUTPUT_FORMAT, --format OUTPUT_FORMAT
                        the format to use for the output, available modes: csv, json (default: text)
  -p, --percentages     whether to output percentages instead of counts. (default: False)
</code></pre>
<h5 id="label-dist-od">LABEL-DIST-OD</h5>
<p>Generates a label distribution.</p>
<h6 id="domains_63">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_63">Options:</h6>
<pre><code>usage: label-dist-od [--label-key LABEL_KEY] [-o OUTPUT_FILE] [-f OUTPUT_FORMAT] [-p]

optional arguments:
  --label-key LABEL_KEY
                        the key in the meta-data that contains the label. (default: type)
  -o OUTPUT_FILE, --output OUTPUT_FILE
                        the file to write the statistics to; uses stdout if omitted (default: )
  -f OUTPUT_FORMAT, --format OUTPUT_FORMAT
                        the format to use for the output, available modes: csv, json (default: text)
  -p, --percentages     whether to output percentages instead of counts. (default: False)
</code></pre>
<h5 id="to-adams-ic">TO-ADAMS-IC</h5>
<p>Writes image classification annotations in the ADAMS report-format</p>
<h6 id="domains_64">Domain(s):</h6>
<ul>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_64">Options:</h6>
<pre><code>usage: to-adams-ic -c FIELD [--annotations-only] -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]]
                   [--split-ratios RATIO [RATIO ...]]

optional arguments:
  -c FIELD, --class-field FIELD
                        the report field containing the image class (default: None)
  --annotations-only    skip the writing of data files, outputting only the annotation files
                        (default: False)
  -o PATH, --output PATH
                        output directory to write files to (default: None)
  --split-names SPLIT NAME [SPLIT NAME ...]
                        the names to use for the splits (default: [])
  --split-ratios RATIO [RATIO ...]
                        the ratios to use for the splits (default: [])
</code></pre>
<h5 id="to-adams-od">TO-ADAMS-OD</h5>
<p>Writes image object-detection annotations in the ADAMS report-format</p>
<h6 id="domains_65">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_65">Options:</h6>
<pre><code>usage: to-adams-od [--annotations-only] -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]]
                   [--split-ratios RATIO [RATIO ...]]

optional arguments:
  --annotations-only    skip the writing of data files, outputting only the annotation files
                        (default: False)
  -o PATH, --output PATH
                        output directory to write files to (default: None)
  --split-names SPLIT NAME [SPLIT NAME ...]
                        the names to use for the splits (default: [])
  --split-ratios RATIO [RATIO ...]
                        the ratios to use for the splits (default: [])
</code></pre>
<h5 id="to-annotation-overlay-od">TO-ANNOTATION-OVERLAY-OD</h5>
<p>Generates an image with all the annotation shapes (bbox or polygon) overlayed.</p>
<h6 id="domains_66">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_66">Options:</h6>
<pre><code>usage: to-annotation-overlay-od [-b BACKGROUND_COLOR] [-c COLOR] [-o OUTPUT_FILE] [-s SCALE_TO]

optional arguments:
  -b BACKGROUND_COLOR, --background-color BACKGROUND_COLOR
                        the color to use for the background as RGBA byte-quadruplet, e.g.:
                        255,255,255,255 (default: 255,255,255,255)
  -c COLOR, --color COLOR
                        the color to use for drawing the shapes as RGBA byte-quadruplet, e.g.:
                        255,0,0,64 (default: 255,0,0,64)
  -o OUTPUT_FILE, --output OUTPUT_FILE
                        the PNG image to write the generated overlay to (default: ./overlay.png)
  -s SCALE_TO, --scale-to SCALE_TO
                        the dimensions to scale all images to before overlaying them (format:
                        width,height) (default: )
</code></pre>
<h5 id="to-blue-channel-is">TO-BLUE-CHANNEL-IS</h5>
<p>Writes image segmentation files in the blue-channel format</p>
<h6 id="domains_67">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
</ul>
<h6 id="options_67">Options:</h6>
<pre><code>usage: to-blue-channel-is [--annotations-only] -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]]
                          [--split-ratios RATIO [RATIO ...]]

optional arguments:
  --annotations-only    skip the writing of data files, outputting only the annotation files
                        (default: False)
  -o PATH, --output PATH
                        the directory to write the annotation images to (default: None)
  --split-names SPLIT NAME [SPLIT NAME ...]
                        the names to use for the splits (default: [])
  --split-ratios RATIO [RATIO ...]
                        the ratios to use for the splits (default: [])
</code></pre>
<h5 id="to-coco-od">TO-COCO-OD</h5>
<p>Writes image object-detection annotations in the MS-COCO JSON-format</p>
<h6 id="domains_68">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_68">Options:</h6>
<pre><code>usage: to-coco-od [--annotations-only] [--categories CATEGORY [CATEGORY ...]]
                  [--category-output-file FILENAME] [--default-supercategory SUPERCATEGORY]
                  [--error-on-new-category] [--license-name LICENSE_NAME]
                  [--license-url LICENSE_URL] -o PATH [--pretty] [--sort-categories]
                  [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]]

optional arguments:
  --annotations-only    skip the writing of data files, outputting only the annotation files
                        (default: False)
  --categories CATEGORY [CATEGORY ...]
                        defines the order of the categories (default: [])
  --category-output-file FILENAME
                        file to write the categories into, as a simple comma-separated list
                        (default: None)
  --default-supercategory SUPERCATEGORY
                        the supercategory to use for pre-defined categories (default: Object)
  --error-on-new-category
                        whether unspecified categories should raise an error (default: False)
  --license-name LICENSE_NAME
                        the license of the images (default: default)
  --license-url LICENSE_URL
                        the license of the images (default: )
  -o PATH, --output PATH
                        output file to write annotations to (images are placed in same directory)
                        (default: None)
  --pretty              whether to format the JSON annotations file with indentation (default:
                        False)
  --sort-categories     whether to put the categories in alphabetical order (default: False)
  --split-names SPLIT NAME [SPLIT NAME ...]
                        the names to use for the splits (default: [])
  --split-ratios RATIO [RATIO ...]
                        the ratios to use for the splits (default: [])
</code></pre>
<h5 id="to-common-voice-sp">TO-COMMON-VOICE-SP</h5>
<p>Writes speech transcriptions in the Mozilla Common-Voice TSV-format</p>
<h6 id="domains_69">Domain(s):</h6>
<ul>
<li><strong>Speech Domain</strong></li>
</ul>
<h6 id="options_69">Options:</h6>
<pre><code>usage: to-common-voice-sp [--annotations-only] -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]]
                          [--split-ratios RATIO [RATIO ...]]

optional arguments:
  --annotations-only    skip the writing of data files, outputting only the annotation files
                        (default: False)
  -o PATH, --output PATH
                        the filename of the TSV file to write the annotations into (default: None)
  --split-names SPLIT NAME [SPLIT NAME ...]
                        the names to use for the splits (default: [])
  --split-ratios RATIO [RATIO ...]
                        the ratios to use for the splits (default: [])
</code></pre>
<h5 id="to-festvox-sp">TO-FESTVOX-SP</h5>
<p>Writes speech transcriptions in the Festival FestVox format</p>
<h6 id="domains_70">Domain(s):</h6>
<ul>
<li><strong>Speech Domain</strong></li>
</ul>
<h6 id="options_70">Options:</h6>
<pre><code>usage: to-festvox-sp [--annotations-only] -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]]
                     [--split-ratios RATIO [RATIO ...]]

optional arguments:
  --annotations-only    skip the writing of data files, outputting only the annotation files
                        (default: False)
  -o PATH, --output PATH
                        the filename of the FestVox file to write the annotations into (default:
                        None)
  --split-names SPLIT NAME [SPLIT NAME ...]
                        the names to use for the splits (default: [])
  --split-ratios RATIO [RATIO ...]
                        the ratios to use for the splits (default: [])
</code></pre>
<h5 id="to-grayscale-is">TO-GRAYSCALE-IS</h5>
<p>Writes image segmentation files in the grayscale format</p>
<h6 id="domains_71">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
</ul>
<h6 id="options_71">Options:</h6>
<pre><code>usage: to-grayscale-is [--annotations-only] -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]]
                       [--split-ratios RATIO [RATIO ...]]

optional arguments:
  --annotations-only    skip the writing of data files, outputting only the annotation files
                        (default: False)
  -o PATH, --output PATH
                        the directory to write the annotation images to (default: None)
  --split-names SPLIT NAME [SPLIT NAME ...]
                        the names to use for the splits (default: [])
  --split-ratios RATIO [RATIO ...]
                        the ratios to use for the splits (default: [])
</code></pre>
<h5 id="to-images-ic">TO-IMAGES-IC</h5>
<p>Dummy writer that just outputs images from image classification datasets.</p>
<h6 id="domains_72">Domain(s):</h6>
<ul>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_72">Options:</h6>
<pre><code>usage: to-images-ic [-o OUTPUT_DIR]

optional arguments:
  -o OUTPUT_DIR, --output-dir OUTPUT_DIR
                        the directory to write the images to (default: .)
</code></pre>
<h5 id="to-images-is">TO-IMAGES-IS</h5>
<p>Dummy writer that just outputs images from image segmentation datasets.</p>
<h6 id="domains_73">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
</ul>
<h6 id="options_73">Options:</h6>
<pre><code>usage: to-images-is [-o OUTPUT_DIR]

optional arguments:
  -o OUTPUT_DIR, --output-dir OUTPUT_DIR
                        the directory to write the images to (default: .)
</code></pre>
<h5 id="to-images-od">TO-IMAGES-OD</h5>
<p>Dummy writer that just outputs images from object detection datasets.</p>
<h6 id="domains_74">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_74">Options:</h6>
<pre><code>usage: to-images-od [-o OUTPUT_DIR]

optional arguments:
  -o OUTPUT_DIR, --output-dir OUTPUT_DIR
                        the directory to write the images to (default: .)
</code></pre>
<h5 id="to-indexed-png-is">TO-INDEXED-PNG-IS</h5>
<p>Writes image segmentation files in the indexed-PNG format</p>
<h6 id="domains_75">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
</ul>
<h6 id="options_75">Options:</h6>
<pre><code>usage: to-indexed-png-is [--annotations-only] -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]]
                         [--split-ratios RATIO [RATIO ...]]

optional arguments:
  --annotations-only    skip the writing of data files, outputting only the annotation files
                        (default: False)
  -o PATH, --output PATH
                        the directory to write the annotation images to (default: None)
  --split-names SPLIT NAME [SPLIT NAME ...]
                        the names to use for the splits (default: [])
  --split-ratios RATIO [RATIO ...]
                        the ratios to use for the splits (default: [])
</code></pre>
<h5 id="to-layer-segments-is">TO-LAYER-SEGMENTS-IS</h5>
<p>Writes the layer-segments image-segmentation format to disk</p>
<h6 id="domains_76">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
</ul>
<h6 id="options_76">Options:</h6>
<pre><code>usage: to-layer-segments-is [--annotations-only] [--label-separator SEPARATOR] -o PATH
                            [--split-names SPLIT NAME [SPLIT NAME ...]]
                            [--split-ratios RATIO [RATIO ...]]

optional arguments:
  --annotations-only    skip the writing of data files, outputting only the annotation files
                        (default: False)
  --label-separator SEPARATOR
                        the separator between the base filename and the label (default: -)
  -o PATH, --output PATH
                        the directory to write the annotation images to (default: None)
  --split-names SPLIT NAME [SPLIT NAME ...]
                        the names to use for the splits (default: [])
  --split-ratios RATIO [RATIO ...]
                        the ratios to use for the splits (default: [])
</code></pre>
<h5 id="to-opex-od">TO-OPEX-OD</h5>
<p>Writes image object-detection annotations in the OPEX format</p>
<h6 id="domains_77">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_77">Options:</h6>
<pre><code>usage: to-opex-od [-c PATH] [-l PATH] [--annotations-only] -o PATH
                  [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]]

optional arguments:
  -c PATH, --labels-csv PATH
                        Path to the labels CSV file to write (default: None)
  -l PATH, --labels PATH
                        Path to the labels file to write (default: None)
  --annotations-only    skip the writing of data files, outputting only the annotation files
                        (default: False)
  -o PATH, --output PATH
                        output directory to write images and annotations to (default: None)
  --split-names SPLIT NAME [SPLIT NAME ...]
                        the names to use for the splits (default: [])
  --split-ratios RATIO [RATIO ...]
                        the ratios to use for the splits (default: [])
</code></pre>
<h5 id="to-roi-od">TO-ROI-OD</h5>
<p>Writes image object-detection annotations in the ROI CSV-format</p>
<h6 id="domains_78">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_78">Options:</h6>
<pre><code>usage: to-roi-od [-d WIDTH HEIGHT] [--annotations-only] [--comments COMMENTS [COMMENTS ...]] -o PATH
                 [--size-mode] [--split-names SPLIT NAME [SPLIT NAME ...]]
                 [--split-ratios RATIO [RATIO ...]] [--prefix WRITER_PREFIX]
                 [--suffix WRITER_SUFFIX]

optional arguments:
  -d WIDTH HEIGHT, --image-dimensions WIDTH HEIGHT
                        image dimensions to use if none can be inferred (default: [])
  --annotations-only    skip the writing of data files, outputting only the annotation files
                        (default: False)
  --comments COMMENTS [COMMENTS ...]
                        comments to write to the beginning of the ROI file (default: [])
  -o PATH, --output PATH
                        output directory to write files to (default: None)
  --size-mode           writes the ROI files with x,y,w,h headers instead of x0,y0,x1,y1 (default:
                        False)
  --split-names SPLIT NAME [SPLIT NAME ...]
                        the names to use for the splits (default: [])
  --split-ratios RATIO [RATIO ...]
                        the ratios to use for the splits (default: [])
  --prefix WRITER_PREFIX
                        the prefix for output filenames (default = '') (default: None)
  --suffix WRITER_SUFFIX
                        the suffix for output filenames (default = '-rois.csv') (default: None)
</code></pre>
<h5 id="to-subdir-ic">TO-SUBDIR-IC</h5>
<p>Writes images to sub-directories named after their class labels.</p>
<h6 id="domains_79">Domain(s):</h6>
<ul>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_79">Options:</h6>
<pre><code>usage: to-subdir-ic -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]]
                    [--split-ratios RATIO [RATIO ...]]

optional arguments:
  -o PATH, --output PATH
                        the directory to store the class directories in (default: None)
  --split-names SPLIT NAME [SPLIT NAME ...]
                        the names to use for the splits (default: [])
  --split-ratios RATIO [RATIO ...]
                        the ratios to use for the splits (default: [])
</code></pre>
<h5 id="to-tf-od">TO-TF-OD</h5>
<p>Writes image object-detection annotations in the TFRecords binary format</p>
<h6 id="domains_80">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_80">Options:</h6>
<pre><code>usage: to-tf-od [--dense] [--source-id-type {filename,numeric-dummy}] -o PATH [-p FILENAME]
                [-s FILENAME [FILENAME ...]] [--split-names SPLIT NAME [SPLIT NAME ...]]
                [--split-ratios RATIO [RATIO ...]]

optional arguments:
  --dense               outputs masks in the dense numerical format instead of PNG-encoded (default:
                        False)
  --source-id-type {filename,numeric-dummy}
                        by default, the filename gets stored in the 'source_id' field, but some
                        algorithms try to convert it into a number and fail with 'StringToNumberOp
                        could not correctly convert string'; in which case you can use 'numeric-
                        dummy' (see https://github.com/google/automl/issues/307) (default: filename)
  -o PATH, --output PATH
                        name of output file for TFRecords (default: None)
  -p FILENAME, --protobuf FILENAME
                        for storing the label strings and IDs (default: None)
  -s FILENAME [FILENAME ...], --shards FILENAME [FILENAME ...]
                        additional shards to write to (default: [])
  --split-names SPLIT NAME [SPLIT NAME ...]
                        the names to use for the splits (default: [])
  --split-ratios RATIO [RATIO ...]
                        the ratios to use for the splits (default: [])
</code></pre>
<h5 id="to-vgg-od">TO-VGG-OD</h5>
<p>Writes image object-detection annotations in the VGG JSON-format</p>
<h6 id="domains_81">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_81">Options:</h6>
<pre><code>usage: to-vgg-od [--annotations-only] -o PATH [--pretty] [--split-names SPLIT NAME [SPLIT NAME ...]]
                 [--split-ratios RATIO [RATIO ...]]

optional arguments:
  --annotations-only    skip the writing of data files, outputting only the annotation files
                        (default: False)
  -o PATH, --output PATH
                        output file to write annotations to (images are placed in same directory)
                        (default: None)
  --pretty              whether to format the JSON annotations file with indentation (default:
                        False)
  --split-names SPLIT NAME [SPLIT NAME ...]
                        the names to use for the splits (default: [])
  --split-ratios RATIO [RATIO ...]
                        the ratios to use for the splits (default: [])
</code></pre>
<h5 id="to-video-file-od">TO-VIDEO-FILE-OD</h5>
<p>Writes frames to a MJPG video file.</p>
<h6 id="domains_82">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_82">Options:</h6>
<pre><code>usage: to-video-file-od [-f FPS] [-o OUTPUT_FILE]

optional arguments:
  -f FPS, --fps FPS     the frames per second to use (default: 25)
  -o OUTPUT_FILE, --output OUTPUT_FILE
                        the MJPG video file to write to (default: )
</code></pre>
<h5 id="to-voc-od">TO-VOC-OD</h5>
<p>Writes image object-detection annotations in the Pascal VOC XML-format</p>
<h6 id="domains_83">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_83">Options:</h6>
<pre><code>usage: to-voc-od [--annotations-only] -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]]
                 [--split-ratios RATIO [RATIO ...]]

optional arguments:
  --annotations-only    skip the writing of data files, outputting only the annotation files
                        (default: False)
  -o PATH, --output PATH
                        output directory to write annotations to (images are placed in same
                        directory) (default: None)
  --split-names SPLIT NAME [SPLIT NAME ...]
                        the names to use for the splits (default: [])
  --split-ratios RATIO [RATIO ...]
                        the ratios to use for the splits (default: [])
</code></pre>
<h5 id="to-void-ic">TO-VOID-IC</h5>
<p>Consumes instances without writing them.</p>
<h6 id="domains_84">Domain(s):</h6>
<ul>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_84">Options:</h6>
<pre><code>usage: to-void-ic
</code></pre>
<h5 id="to-void-is">TO-VOID-IS</h5>
<p>Consumes instances without writing them.</p>
<h6 id="domains_85">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
</ul>
<h6 id="options_85">Options:</h6>
<pre><code>usage: to-void-is
</code></pre>
<h5 id="to-void-od">TO-VOID-OD</h5>
<p>Consumes instances without writing them.</p>
<h6 id="domains_86">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_86">Options:</h6>
<pre><code>usage: to-void-od
</code></pre>
<h5 id="to-void-sp">TO-VOID-SP</h5>
<p>Consumes instances without writing them.</p>
<h6 id="domains_87">Domain(s):</h6>
<ul>
<li><strong>Speech Domain</strong></li>
</ul>
<h6 id="options_87">Options:</h6>
<pre><code>usage: to-void-sp
</code></pre>
<h5 id="to-yolo-od">TO-YOLO-OD</h5>
<p>Writes image object-detection annotations in the YOLO format</p>
<h6 id="domains_88">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_88">Options:</h6>
<pre><code>usage: to-yolo-od [-c PATH] [-l PATH] [--annotations-only] -o PATH
                  [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]]

optional arguments:
  -c PATH, --labels-csv PATH
                        Path to the labels CSV file to write (default: None)
  -l PATH, --labels PATH
                        Path to the labels file to write (default: None)
  --annotations-only    skip the writing of data files, outputting only the annotation files
                        (default: False)
  -o PATH, --output PATH
                        output directory to write images and annotations to (default: None)
  --split-names SPLIT NAME [SPLIT NAME ...]
                        the names to use for the splits (default: [])
  --split-ratios RATIO [RATIO ...]
                        the ratios to use for the splits (default: [])
</code></pre>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../glossary/" class="btn btn-neutral float-right" title="Glossary">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../domains/" class="btn btn-neutral" title="Domains"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href="../domains/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../glossary/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme.js" defer></script>
      <script src="../search/main.js" defer></script>

</body>
</html>

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="shortcut icon" href="../img/favicon.ico">
  <title>Plugins - wai-annotations manual</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Plugins";
    var mkdocs_page_input_path = "plugins.md";
    var mkdocs_page_url = "/wai-annotations-manual/plugins/";
  </script>
  
  <script src="../js/jquery-2.1.1.min.js" defer></script>
  <script src="../js/modernizr-2.8.3.min.js" defer></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> wai-annotations manual</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="..">Home</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../install/">Installation</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../usage/">Usage</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Examples</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../examples_overview/">Overview</a>
                </li>
                <li class="">
                    
    <a class="" href="../examples_formats/">Format conversions</a>
                </li>
                <li class="">
                    
    <a class="" href="../examples_imgaug/">Image dataset augmentation</a>
                </li>
                <li class="">
                    
    <a class="" href="../examples_imgstats/">Image dataset statistics</a>
                </li>
                <li class="">
                    
    <a class="" href="../examples_imgvis/">Image dataset visualizations</a>
                </li>
                <li class="">
                    
    <a class="" href="../examples_video/">Video handling</a>
                </li>
                <li class="">
                    
    <a class="" href="../examples_redis_predictions/">Predictions via Redis</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../docker/">Docker</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../architecture_overview/">Architecture overview</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../plugin/">Plugin guide</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../domains/">Domains</a>
	    </li>
          
            <li class="toctree-l1 current">
		
    <a class="current" href="./">Plugins</a>
    <ul class="subnav">
            
    <li class="toctree-l2"><a href="#plugins">Plugins</a></li>
    
        <ul>
        
            <li><a class="toctree-l3" href="#source-stage">Source stage</a></li>
        
            <li><a class="toctree-l3" href="#processor-stage">Processor stage</a></li>
        
            <li><a class="toctree-l3" href="#sink-stage">Sink stage</a></li>
        
        </ul>
    

    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../glossary/">Glossary</a>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">wai-annotations manual</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
    
    <li>Plugins</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h3 id="plugins">Plugins</h3>
<h4 id="source-stage">Source stage</h4>
<h5 id="from-adams-ic">FROM-ADAMS-IC</h5>
<p>Reads image classification annotations in the ADAMS report-format</p>
<h6 id="domains">Domain(s):</h6>
<ul>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options">Options:</h6>
<pre><code>usage: from-adams-ic [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED] [-e FORMAT FORMAT FORMAT] -c FIELD

optional arguments:
  -I FILENAME, --inputs-file FILENAME
                        Files containing lists of input files (can use glob syntax)
  -i FILENAME, --input FILENAME
                        Input files (can use glob syntax)
  -N FILENAME, --negatives-file FILENAME
                        Files containing lists of negative files (can use glob syntax)
  -n FILENAME, --negative FILENAME
                        Files that have no annotations (can use glob syntax)
  -o FILENAME, --output-file FILENAME
                        optional file to write read filenames into
  --seed SEED           the seed to use for randomisation
  -e FORMAT FORMAT FORMAT, --extensions FORMAT FORMAT FORMAT
                        image format extensions in order of preference
  -c FIELD, --class-field FIELD
                        the report field containing the image class
</code></pre>
<h5 id="from-adams-od">FROM-ADAMS-OD</h5>
<p>Reads image object-detection annotations in the ADAMS report-format</p>
<h6 id="domains_1">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_1">Options:</h6>
<pre><code>usage: from-adams-od [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED] [-e FORMAT FORMAT FORMAT] [-p PREFIXES [PREFIXES ...]]

optional arguments:
  -I FILENAME, --inputs-file FILENAME
                        Files containing lists of input files (can use glob syntax)
  -i FILENAME, --input FILENAME
                        Input files (can use glob syntax)
  -N FILENAME, --negatives-file FILENAME
                        Files containing lists of negative files (can use glob syntax)
  -n FILENAME, --negative FILENAME
                        Files that have no annotations (can use glob syntax)
  -o FILENAME, --output-file FILENAME
                        optional file to write read filenames into
  --seed SEED           the seed to use for randomisation
  -e FORMAT FORMAT FORMAT, --extensions FORMAT FORMAT FORMAT
                        image format extensions in order of preference
  -p PREFIXES [PREFIXES ...], --prefixes PREFIXES [PREFIXES ...]
                        prefixes to parse
</code></pre>
<h5 id="from-blue-channel-is">FROM-BLUE-CHANNEL-IS</h5>
<p>Reads image segmentation files in the blue-channel format</p>
<h6 id="domains_2">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
</ul>
<h6 id="options_2">Options:</h6>
<pre><code>usage: from-blue-channel-is [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED] [--image-path-rel PATH] --labels LABEL [LABEL ...]

optional arguments:
  -I FILENAME, --inputs-file FILENAME
                        Files containing lists of input files (can use glob syntax)
  -i FILENAME, --input FILENAME
                        Input files (can use glob syntax)
  -N FILENAME, --negatives-file FILENAME
                        Files containing lists of negative files (can use glob syntax)
  -n FILENAME, --negative FILENAME
                        Files that have no annotations (can use glob syntax)
  -o FILENAME, --output-file FILENAME
                        optional file to write read filenames into
  --seed SEED           the seed to use for randomisation
  --image-path-rel PATH
                        Relative path to image files from annotations
  --labels LABEL [LABEL ...]
                        specifies the labels for each index
</code></pre>
<h5 id="from-coco-od">FROM-COCO-OD</h5>
<p>Reads image object-detection annotations in the MS-COCO JSON-format</p>
<h6 id="domains_3">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_3">Options:</h6>
<pre><code>usage: from-coco-od [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED]

optional arguments:
  -I FILENAME, --inputs-file FILENAME
                        Files containing lists of input files (can use glob syntax)
  -i FILENAME, --input FILENAME
                        Input files (can use glob syntax)
  -N FILENAME, --negatives-file FILENAME
                        Files containing lists of negative files (can use glob syntax)
  -n FILENAME, --negative FILENAME
                        Files that have no annotations (can use glob syntax)
  -o FILENAME, --output-file FILENAME
                        optional file to write read filenames into
  --seed SEED           the seed to use for randomisation
</code></pre>
<h5 id="from-common-voice-sp">FROM-COMMON-VOICE-SP</h5>
<p>Reads speech transcriptions in the Mozilla Common-Voice TSV-format</p>
<h6 id="domains_4">Domain(s):</h6>
<ul>
<li><strong>Speech Domain</strong></li>
</ul>
<h6 id="options_4">Options:</h6>
<pre><code>usage: from-common-voice-sp [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED] [--rel-path REL_PATH]

optional arguments:
  -I FILENAME, --inputs-file FILENAME
                        Files containing lists of input files (can use glob syntax)
  -i FILENAME, --input FILENAME
                        Input files (can use glob syntax)
  -N FILENAME, --negatives-file FILENAME
                        Files containing lists of negative files (can use glob syntax)
  -n FILENAME, --negative FILENAME
                        Files that have no annotations (can use glob syntax)
  -o FILENAME, --output-file FILENAME
                        optional file to write read filenames into
  --seed SEED           the seed to use for randomisation
  --rel-path REL_PATH   the relative path from the annotations file to the audio files
</code></pre>
<h5 id="from-festvox-sp">FROM-FESTVOX-SP</h5>
<p>Reads speech transcriptions in the Festival FestVox format</p>
<h6 id="domains_5">Domain(s):</h6>
<ul>
<li><strong>Speech Domain</strong></li>
</ul>
<h6 id="options_5">Options:</h6>
<pre><code>usage: from-festvox-sp [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED] [--rel-path REL_PATH]

optional arguments:
  -I FILENAME, --inputs-file FILENAME
                        Files containing lists of input files (can use glob syntax)
  -i FILENAME, --input FILENAME
                        Input files (can use glob syntax)
  -N FILENAME, --negatives-file FILENAME
                        Files containing lists of negative files (can use glob syntax)
  -n FILENAME, --negative FILENAME
                        Files that have no annotations (can use glob syntax)
  -o FILENAME, --output-file FILENAME
                        optional file to write read filenames into
  --seed SEED           the seed to use for randomisation
  --rel-path REL_PATH   the relative path from the annotations file to the audio files
</code></pre>
<h5 id="from-images-ic">FROM-IMAGES-IC</h5>
<p>Dummy reader that turns images into an image classification dataset.</p>
<h6 id="domains_6">Domain(s):</h6>
<ul>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_6">Options:</h6>
<pre><code>usage: from-images-ic [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED]

optional arguments:
  -I FILENAME, --inputs-file FILENAME
                        Files containing lists of input files (can use glob syntax)
  -i FILENAME, --input FILENAME
                        Input files (can use glob syntax)
  -N FILENAME, --negatives-file FILENAME
                        Files containing lists of negative files (can use glob syntax)
  -n FILENAME, --negative FILENAME
                        Files that have no annotations (can use glob syntax)
  -o FILENAME, --output-file FILENAME
                        optional file to write read filenames into
  --seed SEED           the seed to use for randomisation
</code></pre>
<h5 id="from-images-is">FROM-IMAGES-IS</h5>
<p>Dummy reader that turns images into an image segmentation dataset.</p>
<h6 id="domains_7">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
</ul>
<h6 id="options_7">Options:</h6>
<pre><code>usage: from-images-is [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED]

optional arguments:
  -I FILENAME, --inputs-file FILENAME
                        Files containing lists of input files (can use glob syntax)
  -i FILENAME, --input FILENAME
                        Input files (can use glob syntax)
  -N FILENAME, --negatives-file FILENAME
                        Files containing lists of negative files (can use glob syntax)
  -n FILENAME, --negative FILENAME
                        Files that have no annotations (can use glob syntax)
  -o FILENAME, --output-file FILENAME
                        optional file to write read filenames into
  --seed SEED           the seed to use for randomisation
</code></pre>
<h5 id="from-images-od">FROM-IMAGES-OD</h5>
<p>Dummy reader that turns images into an object detection dataset.</p>
<h6 id="domains_8">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_8">Options:</h6>
<pre><code>usage: from-images-od [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED]

optional arguments:
  -I FILENAME, --inputs-file FILENAME
                        Files containing lists of input files (can use glob syntax)
  -i FILENAME, --input FILENAME
                        Input files (can use glob syntax)
  -N FILENAME, --negatives-file FILENAME
                        Files containing lists of negative files (can use glob syntax)
  -n FILENAME, --negative FILENAME
                        Files that have no annotations (can use glob syntax)
  -o FILENAME, --output-file FILENAME
                        optional file to write read filenames into
  --seed SEED           the seed to use for randomisation
</code></pre>
<h5 id="from-indexed-png-is">FROM-INDEXED-PNG-IS</h5>
<p>Reads image segmentation files in the indexed-PNG format</p>
<h6 id="domains_9">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
</ul>
<h6 id="options_9">Options:</h6>
<pre><code>usage: from-indexed-png-is [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED] [--image-path-rel PATH] --labels LABEL [LABEL ...]

optional arguments:
  -I FILENAME, --inputs-file FILENAME
                        Files containing lists of input files (can use glob syntax)
  -i FILENAME, --input FILENAME
                        Input files (can use glob syntax)
  -N FILENAME, --negatives-file FILENAME
                        Files containing lists of negative files (can use glob syntax)
  -n FILENAME, --negative FILENAME
                        Files that have no annotations (can use glob syntax)
  -o FILENAME, --output-file FILENAME
                        optional file to write read filenames into
  --seed SEED           the seed to use for randomisation
  --image-path-rel PATH
                        Relative path to image files from annotations
  --labels LABEL [LABEL ...]
                        specifies the labels for each index
</code></pre>
<h5 id="from-layer-segments-is">FROM-LAYER-SEGMENTS-IS</h5>
<p>Reads in the layer-segments image-segmentation format from disk, where each label has a binary PNG storing the mask for that label</p>
<h6 id="domains_10">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
</ul>
<h6 id="options_10">Options:</h6>
<pre><code>usage: from-layer-segments-is [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED] [--label-separator SEPARATOR] --labels LABEL [LABEL ...] [--image-path-rel PATH]

optional arguments:
  -I FILENAME, --inputs-file FILENAME
                        Files containing lists of input files (can use glob syntax)
  -i FILENAME, --input FILENAME
                        Input files (can use glob syntax)
  -N FILENAME, --negatives-file FILENAME
                        Files containing lists of negative files (can use glob syntax)
  -n FILENAME, --negative FILENAME
                        Files that have no annotations (can use glob syntax)
  -o FILENAME, --output-file FILENAME
                        optional file to write read filenames into
  --seed SEED           the seed to use for randomisation
  --label-separator SEPARATOR
                        the separator between the base filename and the label
  --labels LABEL [LABEL ...]
                        specifies the labels for each index
  --image-path-rel PATH
                        Relative path to image files from annotations
</code></pre>
<h5 id="from-opex-od">FROM-OPEX-OD</h5>
<p>Reads image object-detection annotations in the OPEX format</p>
<h6 id="domains_11">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_11">Options:</h6>
<pre><code>usage: from-opex-od [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED]

optional arguments:
  -I FILENAME, --inputs-file FILENAME
                        Files containing lists of input files (can use glob syntax)
  -i FILENAME, --input FILENAME
                        Input files (can use glob syntax)
  -N FILENAME, --negatives-file FILENAME
                        Files containing lists of negative files (can use glob syntax)
  -n FILENAME, --negative FILENAME
                        Files that have no annotations (can use glob syntax)
  -o FILENAME, --output-file FILENAME
                        optional file to write read filenames into
  --seed SEED           the seed to use for randomisation
</code></pre>
<h5 id="from-roi-od">FROM-ROI-OD</h5>
<p>Reads image object-detection annotations in the ROI CSV-format</p>
<h6 id="domains_12">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_12">Options:</h6>
<pre><code>usage: from-roi-od [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED] [-e FORMAT FORMAT FORMAT] [--prefix READER_PREFIX] [--suffix READER_SUFFIX]

optional arguments:
  -I FILENAME, --inputs-file FILENAME
                        Files containing lists of input files (can use glob syntax)
  -i FILENAME, --input FILENAME
                        Input files (can use glob syntax)
  -N FILENAME, --negatives-file FILENAME
                        Files containing lists of negative files (can use glob syntax)
  -n FILENAME, --negative FILENAME
                        Files that have no annotations (can use glob syntax)
  -o FILENAME, --output-file FILENAME
                        optional file to write read filenames into
  --seed SEED           the seed to use for randomisation
  -e FORMAT FORMAT FORMAT, --extensions FORMAT FORMAT FORMAT
                        image format extensions in order of preference
  --prefix READER_PREFIX
                        the prefix for output filenames (default = '')
  --suffix READER_SUFFIX
                        the suffix for output filenames (default = '-rois.csv')
</code></pre>
<h5 id="from-subdir-ic">FROM-SUBDIR-IC</h5>
<p>Reads images from sub-directories named after their class labels.</p>
<h6 id="domains_13">Domain(s):</h6>
<ul>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_13">Options:</h6>
<pre><code>usage: from-subdir-ic [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED]

optional arguments:
  -I FILENAME, --inputs-file FILENAME
                        Files containing lists of input files (can use glob syntax)
  -i FILENAME, --input FILENAME
                        Input files (can use glob syntax)
  -N FILENAME, --negatives-file FILENAME
                        Files containing lists of negative files (can use glob syntax)
  -n FILENAME, --negative FILENAME
                        Files that have no annotations (can use glob syntax)
  -o FILENAME, --output-file FILENAME
                        optional file to write read filenames into
  --seed SEED           the seed to use for randomisation
</code></pre>
<h5 id="from-tf-od">FROM-TF-OD</h5>
<p>Reads image object-detection annotations in the TFRecords binary format</p>
<h6 id="domains_14">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_14">Options:</h6>
<pre><code>usage: from-tf-od [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED] [--mask-threshold THRESHOLD] [--sample-stride STRIDE]

optional arguments:
  -I FILENAME, --inputs-file FILENAME
                        Files containing lists of input files (can use glob syntax)
  -i FILENAME, --input FILENAME
                        Input files (can use glob syntax)
  -N FILENAME, --negatives-file FILENAME
                        Files containing lists of negative files (can use glob syntax)
  -n FILENAME, --negative FILENAME
                        Files that have no annotations (can use glob syntax)
  -o FILENAME, --output-file FILENAME
                        optional file to write read filenames into
  --seed SEED           the seed to use for randomisation
  --mask-threshold THRESHOLD
                        the threshold to use when calculating polygons from masks
  --sample-stride STRIDE
                        the stride to use when calculating polygons from masks
</code></pre>
<h5 id="from-vgg-od">FROM-VGG-OD</h5>
<p>Reads image object-detection annotations in the VGG JSON-format</p>
<h6 id="domains_15">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_15">Options:</h6>
<pre><code>usage: from-vgg-od [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED]

optional arguments:
  -I FILENAME, --inputs-file FILENAME
                        Files containing lists of input files (can use glob syntax)
  -i FILENAME, --input FILENAME
                        Input files (can use glob syntax)
  -N FILENAME, --negatives-file FILENAME
                        Files containing lists of negative files (can use glob syntax)
  -n FILENAME, --negative FILENAME
                        Files that have no annotations (can use glob syntax)
  -o FILENAME, --output-file FILENAME
                        optional file to write read filenames into
  --seed SEED           the seed to use for randomisation
</code></pre>
<h5 id="from-video-file-od">FROM-VIDEO-FILE-OD</h5>
<p>Reads frames from a video file.</p>
<h6 id="domains_16">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_16">Options:</h6>
<pre><code>usage: from-video-file-od [-f FROM_FRAME] [-i INPUT_FILE] [-m MAX_FRAMES] [-n NTH_FRAME] [-p PREFIX] [-t TO_FRAME]

optional arguments:
  -f FROM_FRAME, --from-frame FROM_FRAME
                        determines with which frame to start the stream (1-based index)
  -i INPUT_FILE, --input INPUT_FILE
                        the video file to read
  -m MAX_FRAMES, --max-frames MAX_FRAMES
                        determines the maximum number of frames to read; ignored if &lt;=0
  -n NTH_FRAME, --nth-frame NTH_FRAME
                        determines whether frames get skipped and only evert nth frame gets forwarded
  -p PREFIX, --prefix PREFIX
                        the prefix to use for the frames
  -t TO_FRAME, --to-frame TO_FRAME
                        determines after which frame to stop (1-based index); ignored if &lt;=0
</code></pre>
<h5 id="from-voc-od">FROM-VOC-OD</h5>
<p>Reads image object-detection annotations in the Pascal VOC XML-format</p>
<h6 id="domains_17">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_17">Options:</h6>
<pre><code>usage: from-voc-od [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED]

optional arguments:
  -I FILENAME, --inputs-file FILENAME
                        Files containing lists of input files (can use glob syntax)
  -i FILENAME, --input FILENAME
                        Input files (can use glob syntax)
  -N FILENAME, --negatives-file FILENAME
                        Files containing lists of negative files (can use glob syntax)
  -n FILENAME, --negative FILENAME
                        Files that have no annotations (can use glob syntax)
  -o FILENAME, --output-file FILENAME
                        optional file to write read filenames into
  --seed SEED           the seed to use for randomisation
</code></pre>
<h5 id="from-webcam-od">FROM-WEBCAM-OD</h5>
<p>Reads frames from a webcam.</p>
<h6 id="domains_18">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_18">Options:</h6>
<pre><code>usage: from-webcam-od [-f FROM_FRAME] [-m MAX_FRAMES] [-n NTH_FRAME] [-p PREFIX] [-t TO_FRAME] [-i WEBCAM_ID]

optional arguments:
  -f FROM_FRAME, --from-frame FROM_FRAME
                        determines with which frame to start the stream (1-based index)
  -m MAX_FRAMES, --max-frames MAX_FRAMES
                        determines the maximum number of frames to read; ignored if &lt;=0
  -n NTH_FRAME, --nth-frame NTH_FRAME
                        determines whether frames get skipped and only evert nth frame gets forwarded
  -p PREFIX, --prefix PREFIX
                        the prefix to use for the frames
  -t TO_FRAME, --to-frame TO_FRAME
                        determines after which frame to stop (1-based index); ignored if &lt;=0
  -i WEBCAM_ID, --webcam-id WEBCAM_ID
                        the webcam ID to read from
</code></pre>
<h5 id="from-yolo-od">FROM-YOLO-OD</h5>
<p>Reads image object-detection annotations in the YOLO format</p>
<h6 id="domains_19">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_19">Options:</h6>
<pre><code>usage: from-yolo-od [-I FILENAME] [-i FILENAME] [-N FILENAME] [-n FILENAME] [-o FILENAME] [--seed SEED] [--image-path-rel PATH] [-l PATH]

optional arguments:
  -I FILENAME, --inputs-file FILENAME
                        Files containing lists of input files (can use glob syntax)
  -i FILENAME, --input FILENAME
                        Input files (can use glob syntax)
  -N FILENAME, --negatives-file FILENAME
                        Files containing lists of negative files (can use glob syntax)
  -n FILENAME, --negative FILENAME
                        Files that have no annotations (can use glob syntax)
  -o FILENAME, --output-file FILENAME
                        optional file to write read filenames into
  --seed SEED           the seed to use for randomisation
  --image-path-rel PATH
                        Relative path to image files from annotations
  -l PATH, --labels PATH
                        Path to the labels file
</code></pre>
<h4 id="processor-stage">Processor stage</h4>
<h5 id="add-annotation-overlay-ic">ADD-ANNOTATION-OVERLAY-IC</h5>
<p>Adds the image classification label on top of images passing through.</p>
<h6 id="domains_20">Domain(s):</h6>
<ul>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_20">Options:</h6>
<pre><code>usage: add-annotation-overlay-ic [--background-color BACKGROUND_COLOR] [--background-margin BACKGROUND_MARGIN] [--fill-background] [--font-color FONT_COLOR] [--font-family FONT_FAMILY] [--font-size FONT_SIZE] [--position TEXT_PLACEMENT]

optional arguments:
  --background-color BACKGROUND_COLOR
                        the RGB color triplet to use for the background.
  --background-margin BACKGROUND_MARGIN
                        the margin in pixels around the background.
  --fill-background     whether to fill the background of the text with the specified color.
  --font-color FONT_COLOR
                        the RGB color triplet to use for the font.
  --font-family FONT_FAMILY
                        the name of the TTF font-family to use, note: any hyphens need escaping with backslash.
  --font-size FONT_SIZE
                        the size of the font.
  --position TEXT_PLACEMENT
                        the position of the label (X,Y).
</code></pre>
<h5 id="add-annotation-overlay-is">ADD-ANNOTATION-OVERLAY-IS</h5>
<p>Adds the image segmentation annotations on top of images passing through.</p>
<h6 id="domains_21">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
</ul>
<h6 id="options_21">Options:</h6>
<pre><code>usage: add-annotation-overlay-is [--alpha ALPHA] [--colors COLORS] [--labels LABELS]

optional arguments:
  --alpha ALPHA    the alpha value to use for overlaying the annotations (0: transparent, 255: opaque).
  --colors COLORS  the blank-separated list of RGB triplets (R,G,B) of custom colors to use, leave empty for default colors
  --labels LABELS  the comma-separated list of labels of annotations to overlay, leave empty to overlay all
</code></pre>
<h5 id="add-annotation-overlay-od">ADD-ANNOTATION-OVERLAY-OD</h5>
<p>Adds object detection overlays to images passing through.</p>
<h6 id="domains_22">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_22">Options:</h6>
<pre><code>usage: add-annotation-overlay-od [--colors COLORS] [--fill] [--fill-alpha FILL_ALPHA] [--font-family FONT_FAMILY] [--font-size FONT_SIZE] [--force-bbox] [--label-key LABEL_KEY] [--labels LABELS] [--num-decimals NUM_DECIMALS] [--outline-alpha OUTLINE_ALPHA] [--outline-thickness OUTLINE_THICKNESS] [--text-format TEXT_FORMAT] [--text-placement TEXT_PLACEMENT] [--vary-colors]

optional arguments:
  --colors COLORS       the blank-separated list of RGB triplets (R,G,B) of custom colors to use, leave empty for default colors
  --fill                whether to fill the bounding boxes/polygons
  --fill-alpha FILL_ALPHA
                        the alpha value to use for the filling (0: transparent, 255: opaque).
  --font-family FONT_FAMILY
                        the name of the TTF font-family to use, note: any hyphens need escaping with backslash.
  --font-size FONT_SIZE
                        the size of the font.
  --force-bbox          whether to force a bounding box even if there is a polygon available
  --label-key LABEL_KEY
                        the key in the meta-data that contains the label.
  --labels LABELS       the comma-separated list of labels of annotations to overlay, leave empty to overlay all
  --num-decimals NUM_DECIMALS
                        the number of decimals to use for float numbers in the text format string.
  --outline-alpha OUTLINE_ALPHA
                        the alpha value to use for the outline (0: transparent, 255: opaque).
  --outline-thickness OUTLINE_THICKNESS
                        the line thickness to use for the outline, &lt;1 to turn off.
  --text-format TEXT_FORMAT
                        template for the text to print on top of the bounding box or polygon, '{PH}' is a placeholder for the 'PH' value from the meta-data or 'label' for the current label; ignored if empty.
  --text-placement TEXT_PLACEMENT
                        comma-separated list of vertical (T=top, C=center, B=bottom) and horizontal (L=left, C=center, R=right) anchoring.
  --vary-colors         whether to vary the colors of the outline/filling regardless of label
</code></pre>
<h5 id="check-duplicate-filenames">CHECK-DUPLICATE-FILENAMES</h5>
<p>Causes the conversion stream to halt when multiple dataset items have the same filename</p>
<h6 id="domains_23">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
<li><strong>Speech Domain</strong></li>
<li><strong>Image Classification Domain</strong></li>
<li><strong>Image Segmentation Domain</strong></li>
</ul>
<h6 id="options_23">Options:</h6>
<pre><code>usage: check-duplicate-filenames
</code></pre>
<h5 id="coerce-box">COERCE-BOX</h5>
<p>Converts all annotation bounds into box regions</p>
<h6 id="domains_24">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_24">Options:</h6>
<pre><code>usage: coerce-box
</code></pre>
<h5 id="coerce-mask">COERCE-MASK</h5>
<p>Converts all annotation bounds into polygon regions</p>
<h6 id="domains_25">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_25">Options:</h6>
<pre><code>usage: coerce-mask
</code></pre>
<h5 id="convert-image-format">CONVERT-IMAGE-FORMAT</h5>
<p>Converts images from one format to another</p>
<h6 id="domains_26">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
<li><strong>Image Classification Domain</strong></li>
<li><strong>Image Segmentation Domain</strong></li>
</ul>
<h6 id="options_26">Options:</h6>
<pre><code>usage: convert-image-format -f FORMAT

optional arguments:
  -f FORMAT, --format FORMAT
                        format to convert images to
</code></pre>
<h5 id="crop">CROP</h5>
<p>Crops images.</p>
<h6 id="domains_27">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_27">Options:</h6>
<pre><code>usage: crop [-m IMGAUG_MODE] [--suffix IMGAUG_SUFFIX] [-f PERCENT_FROM] [-t PERCENT_TO] [-s SEED] [-a] [-T THRESHOLD] [-u]

optional arguments:
  -m IMGAUG_MODE, --mode IMGAUG_MODE
                        the image augmentation mode to use, available modes: replace, add
  --suffix IMGAUG_SUFFIX
                        the suffix to use for the file names in case of augmentation mode add
  -f PERCENT_FROM, --from-percent PERCENT_FROM
                        the minimum percent to crop from images
  -t PERCENT_TO, --to-percent PERCENT_TO
                        the maximum percent to crop from images
  -s SEED, --seed SEED  the seed value to use for the random number generator; randomly seeded if not provided
  -a, --seed-augmentation
                        whether to seed the augmentation; if specified, uses the seeded random generator to produce a seed value from 0 to 1000 for the augmentation.
  -T THRESHOLD, --threshold THRESHOLD
                        the threshold to use for Random.rand(): if equal or above, augmentation gets applied; range: 0-1; default: 0 (= always)
  -u, --update-size     whether to update the image size after the crop operation or scale back to original size
</code></pre>
<h5 id="dimension-discarder">DIMENSION-DISCARDER</h5>
<p>Removes annotations which fall outside certain size constraints</p>
<h6 id="domains_28">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_28">Options:</h6>
<pre><code>usage: dimension-discarder [--max-area MAX_AREA] [--max-height MAX_HEIGHT] [--max-width MAX_WIDTH] [--min-area MIN_AREA] [--min-height MIN_HEIGHT] [--min-width MIN_WIDTH] [--verbose]

optional arguments:
  --max-area MAX_AREA   the maximum area of annotations to convert
  --max-height MAX_HEIGHT
                        the maximum height of annotations to convert
  --max-width MAX_WIDTH
                        the maximum width of annotations to convert
  --min-area MIN_AREA   the minimum area of annotations to convert
  --min-height MIN_HEIGHT
                        the minimum height of annotations to convert
  --min-width MIN_WIDTH
                        the minimum width of annotations to convert
  --verbose             outputs information when discarding annotations
</code></pre>
<h5 id="discard-negatives">DISCARD-NEGATIVES</h5>
<p>Discards negative examples (those without annotations) from the stream</p>
<h6 id="domains_29">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
<li><strong>Speech Domain</strong></li>
<li><strong>Image Classification Domain</strong></li>
<li><strong>Image Segmentation Domain</strong></li>
</ul>
<h6 id="options_29">Options:</h6>
<pre><code>usage: discard-negatives
</code></pre>
<h5 id="drop-frames">DROP-FRAMES</h5>
<p>Drops frames from the stream.</p>
<h6 id="domains_30">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
<li><strong>Image Classification Domain</strong></li>
<li><strong>Image Segmentation Domain</strong></li>
</ul>
<h6 id="options_30">Options:</h6>
<pre><code>usage: drop-frames [-n NTH_FRAME]

optional arguments:
  -n NTH_FRAME, --nth-frame NTH_FRAME
                        which nth frame to drop, e..g, '2' means to drop every 2nd frame; passes frames through if &lt;=1
</code></pre>
<h5 id="filter-labels">FILTER-LABELS</h5>
<p>Filters detected objects down to those with specified labels.</p>
<h6 id="domains_31">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_31">Options:</h6>
<pre><code>usage: filter-labels [-l LABELS [LABELS ...]] [-r regexp]

optional arguments:
  -l LABELS [LABELS ...], --labels LABELS [LABELS ...]
                        labels to use
  -r regexp, --regexp regexp
                        regular expression for using only a subset of labels
</code></pre>
<h5 id="flip">FLIP</h5>
<p>Flips images either left-to-right, up-to-down or both.</p>
<h6 id="domains_32">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_32">Options:</h6>
<pre><code>usage: flip [-d DIRECTION] [-m IMGAUG_MODE] [--suffix IMGAUG_SUFFIX] [-s SEED] [-a] [-T THRESHOLD]

optional arguments:
  -d DIRECTION, --direction DIRECTION
                        the direction to flip, available options: lr, up, lrup
  -m IMGAUG_MODE, --mode IMGAUG_MODE
                        the image augmentation mode to use, available modes: replace, add
  --suffix IMGAUG_SUFFIX
                        the suffix to use for the file names in case of augmentation mode add
  -s SEED, --seed SEED  the seed value to use for the random number generator; randomly seeded if not provided
  -a, --seed-augmentation
                        whether to seed the augmentation; if specified, uses the seeded random generator to produce a seed value from 0 to 1000 for the augmentation.
  -T THRESHOLD, --threshold THRESHOLD
                        the threshold to use for Random.rand(): if equal or above, augmentation gets applied; range: 0-1; default: 0 (= always)
</code></pre>
<h5 id="gaussian-blur">GAUSSIAN-BLUR</h5>
<p>Applies gaussian blur to images.</p>
<h6 id="domains_33">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_33">Options:</h6>
<pre><code>usage: gaussian-blur [-m IMGAUG_MODE] [--suffix IMGAUG_SUFFIX] [-s SEED] [-a] [-f SIGMA_FROM] [-t SIGMA_TO] [-T THRESHOLD]

optional arguments:
  -m IMGAUG_MODE, --mode IMGAUG_MODE
                        the image augmentation mode to use, available modes: replace, add
  --suffix IMGAUG_SUFFIX
                        the suffix to use for the file names in case of augmentation mode add
  -s SEED, --seed SEED  the seed value to use for the random number generator; randomly seeded if not provided
  -a, --seed-augmentation
                        whether to seed the augmentation; if specified, uses the seeded random generator to produce a seed value from 0 to 1000 for the augmentation.
  -f SIGMA_FROM, --from-sigma SIGMA_FROM
                        the minimum sigma for the blur to apply to the images
  -t SIGMA_TO, --to-sigma SIGMA_TO
                        the maximum sigma for the blur to apply to the images
  -T THRESHOLD, --threshold THRESHOLD
                        the threshold to use for Random.rand(): if equal or above, augmentation gets applied; range: 0-1; default: 0 (= always)
</code></pre>
<h5 id="hsl-grayscale">HSL-GRAYSCALE</h5>
<p>Turns RGB images into fake grayscale ones by converting them to HSL and then using the L channel for all channels. The brightness can be influenced and varied even.</p>
<h6 id="domains_34">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_34">Options:</h6>
<pre><code>usage: hsl-grayscale [-f FACTOR_FROM] [-t FACTOR_TO] [-m IMGAUG_MODE] [--suffix IMGAUG_SUFFIX] [-s SEED] [-a] [-T THRESHOLD]

optional arguments:
  -f FACTOR_FROM, --from-factor FACTOR_FROM
                        the start of the factor range to apply to the L channel to darken or lighten the image (&lt;1: darker, &gt;1: lighter)
  -t FACTOR_TO, --to-factor FACTOR_TO
                        the end of the factor range to apply to the L channel to darken or lighten the image (&lt;1: darker, &gt;1: lighter)
  -m IMGAUG_MODE, --mode IMGAUG_MODE
                        the image augmentation mode to use, available modes: replace, add
  --suffix IMGAUG_SUFFIX
                        the suffix to use for the file names in case of augmentation mode add
  -s SEED, --seed SEED  the seed value to use for the random number generator; randomly seeded if not provided
  -a, --seed-augmentation
                        whether to seed the augmentation; if specified, uses the seeded random generator to produce a seed value from 0 to 1000 for the augmentation.
  -T THRESHOLD, --threshold THRESHOLD
                        the threshold to use for Random.rand(): if equal or above, augmentation gets applied; range: 0-1; default: 0 (= always)
</code></pre>
<h5 id="linear-contrast">LINEAR-CONTRAST</h5>
<p>Applies linear contrast to images.</p>
<h6 id="domains_35">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_35">Options:</h6>
<pre><code>usage: linear-contrast [-f ALPHA_FROM] [-t ALPHA_TO] [-m IMGAUG_MODE] [--suffix IMGAUG_SUFFIX] [-s SEED] [-a] [-T THRESHOLD]

optional arguments:
  -f ALPHA_FROM, --from-alpha ALPHA_FROM
                        the minimum alpha to apply to the images
  -t ALPHA_TO, --to-alpha ALPHA_TO
                        the maximum alpha to apply to the images
  -m IMGAUG_MODE, --mode IMGAUG_MODE
                        the image augmentation mode to use, available modes: replace, add
  --suffix IMGAUG_SUFFIX
                        the suffix to use for the file names in case of augmentation mode add
  -s SEED, --seed SEED  the seed value to use for the random number generator; randomly seeded if not provided
  -a, --seed-augmentation
                        whether to seed the augmentation; if specified, uses the seeded random generator to produce a seed value from 0 to 1000 for the augmentation.
  -T THRESHOLD, --threshold THRESHOLD
                        the threshold to use for Random.rand(): if equal or above, augmentation gets applied; range: 0-1; default: 0 (= always)
</code></pre>
<h5 id="map-labels">MAP-LABELS</h5>
<p>Maps object-detection labels from one set to another</p>
<h6 id="domains_36">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_36">Options:</h6>
<pre><code>usage: map-labels [-m old=new]

optional arguments:
  -m old=new, --mapping old=new
                        mapping for labels, for replacing one label string with another (eg when fixing/collapsing labels)
</code></pre>
<h5 id="od-to-ic">OD-TO-IC</h5>
<p>Converts image object-detection instances into image classification instances</p>
<h6 id="domains_37">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_37">Options:</h6>
<pre><code>usage: od-to-ic [-m HANDLER]

optional arguments:
  -m HANDLER, --multiplicity HANDLER
                        how to handle instances with more than one located object
</code></pre>
<h5 id="od-to-is">OD-TO-IS</h5>
<p>Converts image object-detection instances into image segmentation instances</p>
<h6 id="domains_38">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_38">Options:</h6>
<pre><code>usage: od-to-is [--label-error] --labels LABEL [LABEL ...]

optional arguments:
  --label-error         whether to raise errors when an unspecified label is encountered (default is to ignore)
  --labels LABEL [LABEL ...]
                        specifies the labels for each index
</code></pre>
<h5 id="passthrough">PASSTHROUGH</h5>
<p>Dummy ISP which has no effect on the conversion stream</p>
<h6 id="domains_39">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
<li><strong>Speech Domain</strong></li>
<li><strong>Image Classification Domain</strong></li>
<li><strong>Image Segmentation Domain</strong></li>
</ul>
<h6 id="options_39">Options:</h6>
<pre><code>usage: passthrough
</code></pre>
<h5 id="polygon-discarder">POLYGON-DISCARDER</h5>
<p>Removes annotations with polygons which fall outside certain point limit constraints</p>
<h6 id="domains_40">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_40">Options:</h6>
<pre><code>usage: polygon-discarder [--max-points MAX_POINTS] [--min-points MIN_POINTS] [--verbose]

optional arguments:
  --max-points MAX_POINTS
                        the maximum number of points in the polygon
  --min-points MIN_POINTS
                        the minimum number of points in the polygon
  --verbose             outputs information when discarding annotations
</code></pre>
<h5 id="redis-predict-ic">REDIS-PREDICT-IC</h5>
<p>Makes image classification predictions via Redis backend, passing in an image and receiving JSON predictions back (at least one of 'label: probability').
Predictions example:
{"dog": 0.9, "cat": 0.1}</p>
<h6 id="domains_41">Domain(s):</h6>
<ul>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_41">Options:</h6>
<pre><code>usage: redis-predict-ic [--channel-in CHANNEL_IN] [--channel-out CHANNEL_OUT] [-d REDIS_DB] [-h REDIS_HOST] [-p REDIS_PORT] [-t TIMEOUT] [-v]

optional arguments:
  --channel-in CHANNEL_IN
                        the Redis channel on which to receive predictions.
  --channel-out CHANNEL_OUT
                        the Redis channel to send the images out
  -d REDIS_DB, --redis-db REDIS_DB
                        the database to use
  -h REDIS_HOST, --redis-host REDIS_HOST
                        the Redis server to connect to
  -p REDIS_PORT, --redis-port REDIS_PORT
                        the port the Redis server is running on
  -t TIMEOUT, --timeout TIMEOUT
                        the timeout in seconds to wait for a prediction to arrive
  -v, --verbose         whether to output debugging information.
</code></pre>
<h5 id="redis-predict-is">REDIS-PREDICT-IS</h5>
<p>Makes image segmentation predictions via Redis backend, passing in an image and receiving an image with predicted segmentations.</p>
<h6 id="domains_42">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
</ul>
<h6 id="options_42">Options:</h6>
<pre><code>usage: redis-predict-is [--channel-in CHANNEL_IN] [--channel-out CHANNEL_OUT] [--image-format IMAGE_FORMAT] --labels LABEL [LABEL ...] [-d REDIS_DB] [-h REDIS_HOST] [-p REDIS_PORT] [-t TIMEOUT] [-v]

optional arguments:
  --channel-in CHANNEL_IN
                        the Redis channel on which to receive predictions.
  --channel-out CHANNEL_OUT
                        the Redis channel to send the images out
  --image-format IMAGE_FORMAT
                        the format of the image that comes back as prediction: indexedpng,bluechannel
  --labels LABEL [LABEL ...]
                        specifies the labels for each index
  -d REDIS_DB, --redis-db REDIS_DB
                        the database to use
  -h REDIS_HOST, --redis-host REDIS_HOST
                        the Redis server to connect to
  -p REDIS_PORT, --redis-port REDIS_PORT
                        the port the Redis server is running on
  -t TIMEOUT, --timeout TIMEOUT
                        the timeout in seconds to wait for a prediction to arrive
  -v, --verbose         whether to output debugging information.
</code></pre>
<h5 id="redis-predict-od">REDIS-PREDICT-OD</h5>
<p>Makes object detection predictions via Redis backend, passing in an image and receiving OPEX predictions back:
https://github.com/WaikatoLink2020/objdet-predictions-exchange-format</p>
<h6 id="domains_43">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_43">Options:</h6>
<pre><code>usage: redis-predict-od [--channel-in CHANNEL_IN] [--channel-out CHANNEL_OUT] [--key-label KEY_LABEL] [--key-score KEY_SCORE] [-d REDIS_DB] [-h REDIS_HOST] [-p REDIS_PORT] [-t TIMEOUT] [-v]

optional arguments:
  --channel-in CHANNEL_IN
                        the Redis channel on which to receive predictions.
  --channel-out CHANNEL_OUT
                        the Redis channel to send the images out
  --key-label KEY_LABEL
                        the meta-data key in the annotations to use for storing the label.
  --key-score KEY_SCORE
                        the meta-data key in the annotations to use for storing the prediction score.
  -d REDIS_DB, --redis-db REDIS_DB
                        the database to use
  -h REDIS_HOST, --redis-host REDIS_HOST
                        the Redis server to connect to
  -p REDIS_PORT, --redis-port REDIS_PORT
                        the port the Redis server is running on
  -t TIMEOUT, --timeout TIMEOUT
                        the timeout in seconds to wait for a prediction to arrive
  -v, --verbose         whether to output debugging information.
</code></pre>
<h5 id="remove-classes">REMOVE-CLASSES</h5>
<p>Removes classes from classification/image-segmentation instances</p>
<h6 id="domains_44">Domain(s):</h6>
<ul>
<li><strong>Image Classification Domain</strong></li>
<li><strong>Image Segmentation Domain</strong></li>
</ul>
<h6 id="options_44">Options:</h6>
<pre><code>usage: remove-classes -c CLASS [CLASS ...]

optional arguments:
  -c CLASS [CLASS ...], --classes CLASS [CLASS ...]
                        the classes to remove
</code></pre>
<h5 id="rotate">ROTATE</h5>
<p>Rotates images randomly within a range of degrees or by a specified degree. Specify seed value and force augmentation to be seeded to generate repeatable augmentations.</p>
<h6 id="domains_45">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_45">Options:</h6>
<pre><code>usage: rotate [-f DEGREE_FROM] [-t DEGREE_TO] [-m IMGAUG_MODE] [--suffix IMGAUG_SUFFIX] [-s SEED] [-a] [-T THRESHOLD]

optional arguments:
  -f DEGREE_FROM, --from-degree DEGREE_FROM
                        the start of the degree range to use for rotating the images
  -t DEGREE_TO, --to-degree DEGREE_TO
                        the end of the degree range to use for rotating the images
  -m IMGAUG_MODE, --mode IMGAUG_MODE
                        the image augmentation mode to use, available modes: replace, add
  --suffix IMGAUG_SUFFIX
                        the suffix to use for the file names in case of augmentation mode add
  -s SEED, --seed SEED  the seed value to use for the random number generator; randomly seeded if not provided
  -a, --seed-augmentation
                        whether to seed the augmentation; if specified, uses the seeded random generator to produce a seed value from 0 to 1000 for the augmentation.
  -T THRESHOLD, --threshold THRESHOLD
                        the threshold to use for Random.rand(): if equal or above, augmentation gets applied; range: 0-1; default: 0 (= always)
</code></pre>
<h5 id="scale">SCALE</h5>
<p>Scales images randomly within a range of percentages or by a specified percentage. Specify seed value and force augmentation to be seeded to generate repeatable augmentations.</p>
<h6 id="domains_46">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_46">Options:</h6>
<pre><code>usage: scale [-m IMGAUG_MODE] [--suffix IMGAUG_SUFFIX] [-k] [-f PERCENTAGE_FROM] [-t PERCENTAGE_TO] [-s SEED] [-a] [-T THRESHOLD] [-u]

optional arguments:
  -m IMGAUG_MODE, --mode IMGAUG_MODE
                        the image augmentation mode to use, available modes: replace, add
  --suffix IMGAUG_SUFFIX
                        the suffix to use for the file names in case of augmentation mode add
  -k, --keep-aspect     whether to keep the aspect ratio
  -f PERCENTAGE_FROM, --from-percentage PERCENTAGE_FROM
                        the start of the percentage range to use for scaling the images
  -t PERCENTAGE_TO, --to-percentage PERCENTAGE_TO
                        the end of the percentage range to use for scaling the images
  -s SEED, --seed SEED  the seed value to use for the random number generator; randomly seeded if not provided
  -a, --seed-augmentation
                        whether to seed the augmentation; if specified, uses the seeded random generator to produce a seed value from 0 to 1000 for the augmentation.
  -T THRESHOLD, --threshold THRESHOLD
                        the threshold to use for Random.rand(): if equal or above, augmentation gets applied; range: 0-1; default: 0 (= always)
  -u, --update-size     whether to update the image size after the scaling operation or use original size
</code></pre>
<h5 id="skip-similar-frames">SKIP-SIMILAR-FRAMES</h5>
<p>Skips frames in the stream that are deemed too similar.</p>
<h6 id="domains_47">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
<li><strong>Image Classification Domain</strong></li>
<li><strong>Image Segmentation Domain</strong></li>
</ul>
<h6 id="options_47">Options:</h6>
<pre><code>usage: skip-similar-frames [-b BW_THRESHOLD] [-t CHANGE_THRESHOLD] [-c CONVERSION] [-v]

optional arguments:
  -b BW_THRESHOLD, --bw-threshold BW_THRESHOLD
                        the threshold to use for converting a gray-scale like image to black and white (0-255)
  -t CHANGE_THRESHOLD, --change-threshold CHANGE_THRESHOLD
                        the percentage of pixels that changed relative to size of image (0-1)
  -c CONVERSION, --conversion CONVERSION
                        how to convert the BGR image to a single channel image (gray/r/g/b)
  -v, --verbose         whether to output some debugging output.
</code></pre>
<h5 id="strip-annotations">STRIP-ANNOTATIONS</h5>
<p>ISP which removes annotations from instances</p>
<h6 id="domains_48">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
<li><strong>Speech Domain</strong></li>
<li><strong>Image Classification Domain</strong></li>
<li><strong>Image Segmentation Domain</strong></li>
</ul>
<h6 id="options_48">Options:</h6>
<pre><code>usage: strip-annotations
</code></pre>
<h4 id="sink-stage">Sink stage</h4>
<h5 id="calc-frame-changes">CALC-FRAME-CHANGES</h5>
<p>Calculates the changes between frames, which can be used with the skip-similar-frames ISP.</p>
<h6 id="domains_49">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_49">Options:</h6>
<pre><code>usage: calc-frame-changes [-b BW_THRESHOLD] [-t CHANGE_THRESHOLD] [-c CONVERSION] [-B NUM_BINS] [-o OUTPUT_FILE] [-f OUTPUT_FORMAT] [-v]

optional arguments:
  -b BW_THRESHOLD, --bw-threshold BW_THRESHOLD
                        the threshold to use for converting a gray-scale like image to black and white (0-255)
  -t CHANGE_THRESHOLD, --change-threshold CHANGE_THRESHOLD
                        the percentage of pixels that changed relative to size of image (0-1)
  -c CONVERSION, --conversion CONVERSION
                        how to convert the BGR image to a single channel image (gray/r/g/b)
  -B NUM_BINS, --num-bins NUM_BINS
                        the number of bins to use for the histogram
  -o OUTPUT_FILE, --output OUTPUT_FILE
                        the file to write to statistics to, stdout if not provided
  -f OUTPUT_FORMAT, --output-format OUTPUT_FORMAT
                        how to output the statistics (text/csv/json)
  -v, --verbose         whether to output some debugging output.
</code></pre>
<h5 id="image-viewer-ic">IMAGE-VIEWER-IC</h5>
<p>Displays image classification images.</p>
<h6 id="domains_50">Domain(s):</h6>
<ul>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_50">Options:</h6>
<pre><code>usage: image-viewer-ic [--delay DELAY] [--position POSITION] [--size SIZE] [--title TITLE]

optional arguments:
  --delay DELAY        the delay in milli-seconds between images, use 0 to wait for keypress, ignored if &lt;0
  --position POSITION  the position of the window on screen (X,Y)
  --size SIZE          the maximum size for the image: WIDTH,HEIGHT
  --title TITLE        the title for the window
</code></pre>
<h5 id="image-viewer-is">IMAGE-VIEWER-IS</h5>
<p>Displays image segmentation images.</p>
<h6 id="domains_51">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
</ul>
<h6 id="options_51">Options:</h6>
<pre><code>usage: image-viewer-is [--delay DELAY] [--position POSITION] [--size SIZE] [--title TITLE]

optional arguments:
  --delay DELAY        the delay in milli-seconds between images, use 0 to wait for keypress, ignored if &lt;0
  --position POSITION  the position of the window on screen (X,Y)
  --size SIZE          the maximum size for the image: WIDTH,HEIGHT
  --title TITLE        the title for the window
</code></pre>
<h5 id="image-viewer-od">IMAGE-VIEWER-OD</h5>
<p>Displays object detection images.</p>
<h6 id="domains_52">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_52">Options:</h6>
<pre><code>usage: image-viewer-od [--delay DELAY] [--position POSITION] [--size SIZE] [--title TITLE]

optional arguments:
  --delay DELAY        the delay in milli-seconds between images, use 0 to wait for keypress, ignored if &lt;0
  --position POSITION  the position of the window on screen (X,Y)
  --size SIZE          the maximum size for the image: WIDTH,HEIGHT
  --title TITLE        the title for the window
</code></pre>
<h5 id="label-dist-ic">LABEL-DIST-IC</h5>
<p>Generates a label distribution.</p>
<h6 id="domains_53">Domain(s):</h6>
<ul>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_53">Options:</h6>
<pre><code>usage: label-dist-ic [-o OUTPUT_FILE] [-f OUTPUT_FORMAT] [-p]

optional arguments:
  -o OUTPUT_FILE, --output OUTPUT_FILE
                        the file to write the statistics to; uses stdout if omitted
  -f OUTPUT_FORMAT, --format OUTPUT_FORMAT
                        the format to use for the output, available modes: csv, json
  -p, --percentages     whether to output percentages instead of counts.
</code></pre>
<h5 id="label-dist-is">LABEL-DIST-IS</h5>
<p>Generates a label distribution.</p>
<h6 id="domains_54">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
</ul>
<h6 id="options_54">Options:</h6>
<pre><code>usage: label-dist-is [-o OUTPUT_FILE] [-f OUTPUT_FORMAT] [-p]

optional arguments:
  -o OUTPUT_FILE, --output OUTPUT_FILE
                        the file to write the statistics to; uses stdout if omitted
  -f OUTPUT_FORMAT, --format OUTPUT_FORMAT
                        the format to use for the output, available modes: csv, json
  -p, --percentages     whether to output percentages instead of counts.
</code></pre>
<h5 id="label-dist-od">LABEL-DIST-OD</h5>
<p>Generates a label distribution.</p>
<h6 id="domains_55">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_55">Options:</h6>
<pre><code>usage: label-dist-od [-o OUTPUT_FILE] [-f OUTPUT_FORMAT] [-p]

optional arguments:
  -o OUTPUT_FILE, --output OUTPUT_FILE
                        the file to write the statistics to; uses stdout if omitted
  -f OUTPUT_FORMAT, --format OUTPUT_FORMAT
                        the format to use for the output, available modes: csv, json
  -p, --percentages     whether to output percentages instead of counts.
</code></pre>
<h5 id="to-adams-ic">TO-ADAMS-IC</h5>
<p>Writes image classification annotations in the ADAMS report-format</p>
<h6 id="domains_56">Domain(s):</h6>
<ul>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_56">Options:</h6>
<pre><code>usage: to-adams-ic -c FIELD [--annotations-only] -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]]

optional arguments:
  -c FIELD, --class-field FIELD
                        the report field containing the image class
  --annotations-only    skip the writing of data files, outputting only the annotation files
  -o PATH, --output PATH
                        output directory to write files to
  --split-names SPLIT NAME [SPLIT NAME ...]
                        the names to use for the splits
  --split-ratios RATIO [RATIO ...]
                        the ratios to use for the splits
</code></pre>
<h5 id="to-adams-od">TO-ADAMS-OD</h5>
<p>Writes image object-detection annotations in the ADAMS report-format</p>
<h6 id="domains_57">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_57">Options:</h6>
<pre><code>usage: to-adams-od [--annotations-only] -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]]

optional arguments:
  --annotations-only    skip the writing of data files, outputting only the annotation files
  -o PATH, --output PATH
                        output directory to write files to
  --split-names SPLIT NAME [SPLIT NAME ...]
                        the names to use for the splits
  --split-ratios RATIO [RATIO ...]
                        the ratios to use for the splits
</code></pre>
<h5 id="to-annotation-overlay-od">TO-ANNOTATION-OVERLAY-OD</h5>
<p>Generates an image with all the annotation shapes (bbox or polygon) overlayed.</p>
<h6 id="domains_58">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_58">Options:</h6>
<pre><code>usage: to-annotation-overlay-od [-b BACKGROUND_COLOR] [-c COLOR] [-o OUTPUT_FILE] [-s SCALE_TO]

optional arguments:
  -b BACKGROUND_COLOR, --background-color BACKGROUND_COLOR
                        the color to use for the background as RGBA byte-quadruplet, e.g.: 255,255,255,255
  -c COLOR, --color COLOR
                        the color to use for drawing the shapes as RGBA byte-quadruplet, e.g.: 255,0,0,64
  -o OUTPUT_FILE, --output OUTPUT_FILE
                        the PNG image to write the generated overlay to
  -s SCALE_TO, --scale-to SCALE_TO
                        the dimensions to scale all images to before overlaying them (format: width,height)
</code></pre>
<h5 id="to-blue-channel-is">TO-BLUE-CHANNEL-IS</h5>
<p>Writes image segmentation files in the blue-channel format</p>
<h6 id="domains_59">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
</ul>
<h6 id="options_59">Options:</h6>
<pre><code>usage: to-blue-channel-is [--annotations-only] -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]]

optional arguments:
  --annotations-only    skip the writing of data files, outputting only the annotation files
  -o PATH, --output PATH
                        the directory to write the annotation images to
  --split-names SPLIT NAME [SPLIT NAME ...]
                        the names to use for the splits
  --split-ratios RATIO [RATIO ...]
                        the ratios to use for the splits
</code></pre>
<h5 id="to-coco-od">TO-COCO-OD</h5>
<p>Writes image object-detection annotations in the MS-COCO JSON-format</p>
<h6 id="domains_60">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_60">Options:</h6>
<pre><code>usage: to-coco-od [--annotations-only] [--categories CATEGORY [CATEGORY ...]] [--category-output-file FILENAME] [--default-supercategory SUPERCATEGORY] [--error-on-new-category] [--license-name LICENSE_NAME] [--license-url LICENSE_URL] -o PATH [--pretty] [--sort-categories] [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]]

optional arguments:
  --annotations-only    skip the writing of data files, outputting only the annotation files
  --categories CATEGORY [CATEGORY ...]
                        defines the order of the categories
  --category-output-file FILENAME
                        file to write the categories into, as a simple comma-separated list
  --default-supercategory SUPERCATEGORY
                        the supercategory to use for pre-defined categories
  --error-on-new-category
                        whether unspecified categories should raise an error
  --license-name LICENSE_NAME
                        the license of the images
  --license-url LICENSE_URL
                        the license of the images
  -o PATH, --output PATH
                        output file to write annotations to (images are placed in same directory)
  --pretty              whether to format the JSON annotations file with indentation
  --sort-categories     whether to put the categories in alphabetical order
  --split-names SPLIT NAME [SPLIT NAME ...]
                        the names to use for the splits
  --split-ratios RATIO [RATIO ...]
                        the ratios to use for the splits
</code></pre>
<h5 id="to-common-voice-sp">TO-COMMON-VOICE-SP</h5>
<p>Writes speech transcriptions in the Mozilla Common-Voice TSV-format</p>
<h6 id="domains_61">Domain(s):</h6>
<ul>
<li><strong>Speech Domain</strong></li>
</ul>
<h6 id="options_61">Options:</h6>
<pre><code>usage: to-common-voice-sp [--annotations-only] -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]]

optional arguments:
  --annotations-only    skip the writing of data files, outputting only the annotation files
  -o PATH, --output PATH
                        the filename of the TSV file to write the annotations into
  --split-names SPLIT NAME [SPLIT NAME ...]
                        the names to use for the splits
  --split-ratios RATIO [RATIO ...]
                        the ratios to use for the splits
</code></pre>
<h5 id="to-festvox-sp">TO-FESTVOX-SP</h5>
<p>Writes speech transcriptions in the Festival FestVox format</p>
<h6 id="domains_62">Domain(s):</h6>
<ul>
<li><strong>Speech Domain</strong></li>
</ul>
<h6 id="options_62">Options:</h6>
<pre><code>usage: to-festvox-sp [--annotations-only] -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]]

optional arguments:
  --annotations-only    skip the writing of data files, outputting only the annotation files
  -o PATH, --output PATH
                        the filename of the FestVox file to write the annotations into
  --split-names SPLIT NAME [SPLIT NAME ...]
                        the names to use for the splits
  --split-ratios RATIO [RATIO ...]
                        the ratios to use for the splits
</code></pre>
<h5 id="to-images-ic">TO-IMAGES-IC</h5>
<p>Dummy writer that just outputs images from image classification datasets.</p>
<h6 id="domains_63">Domain(s):</h6>
<ul>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_63">Options:</h6>
<pre><code>usage: to-images-ic [-o OUTPUT_DIR]

optional arguments:
  -o OUTPUT_DIR, --output-dir OUTPUT_DIR
                        the directory to write the images to
</code></pre>
<h5 id="to-images-is">TO-IMAGES-IS</h5>
<p>Dummy writer that just outputs images from image segmentation datasets.</p>
<h6 id="domains_64">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
</ul>
<h6 id="options_64">Options:</h6>
<pre><code>usage: to-images-is [-o OUTPUT_DIR]

optional arguments:
  -o OUTPUT_DIR, --output-dir OUTPUT_DIR
                        the directory to write the images to
</code></pre>
<h5 id="to-images-od">TO-IMAGES-OD</h5>
<p>Dummy writer that just outputs images from object detection datasets.</p>
<h6 id="domains_65">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_65">Options:</h6>
<pre><code>usage: to-images-od [-o OUTPUT_DIR]

optional arguments:
  -o OUTPUT_DIR, --output-dir OUTPUT_DIR
                        the directory to write the images to
</code></pre>
<h5 id="to-indexed-png-is">TO-INDEXED-PNG-IS</h5>
<p>Writes image segmentation files in the indexed-PNG format</p>
<h6 id="domains_66">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
</ul>
<h6 id="options_66">Options:</h6>
<pre><code>usage: to-indexed-png-is [--annotations-only] -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]]

optional arguments:
  --annotations-only    skip the writing of data files, outputting only the annotation files
  -o PATH, --output PATH
                        the directory to write the annotation images to
  --split-names SPLIT NAME [SPLIT NAME ...]
                        the names to use for the splits
  --split-ratios RATIO [RATIO ...]
                        the ratios to use for the splits
</code></pre>
<h5 id="to-layer-segments-is">TO-LAYER-SEGMENTS-IS</h5>
<p>Writes the layer-segments image-segmentation format to disk</p>
<h6 id="domains_67">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
</ul>
<h6 id="options_67">Options:</h6>
<pre><code>usage: to-layer-segments-is [--annotations-only] [--label-separator SEPARATOR] -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]]

optional arguments:
  --annotations-only    skip the writing of data files, outputting only the annotation files
  --label-separator SEPARATOR
                        the separator between the base filename and the label
  -o PATH, --output PATH
                        the directory to write the annotation images to
  --split-names SPLIT NAME [SPLIT NAME ...]
                        the names to use for the splits
  --split-ratios RATIO [RATIO ...]
                        the ratios to use for the splits
</code></pre>
<h5 id="to-opex-od">TO-OPEX-OD</h5>
<p>Writes image object-detection annotations in the OPEX format</p>
<h6 id="domains_68">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_68">Options:</h6>
<pre><code>usage: to-opex-od [-c PATH] [-l PATH] [--annotations-only] -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]]

optional arguments:
  -c PATH, --labels-csv PATH
                        Path to the labels CSV file to write
  -l PATH, --labels PATH
                        Path to the labels file to write
  --annotations-only    skip the writing of data files, outputting only the annotation files
  -o PATH, --output PATH
                        output directory to write images and annotations to
  --split-names SPLIT NAME [SPLIT NAME ...]
                        the names to use for the splits
  --split-ratios RATIO [RATIO ...]
                        the ratios to use for the splits
</code></pre>
<h5 id="to-roi-od">TO-ROI-OD</h5>
<p>Writes image object-detection annotations in the ROI CSV-format</p>
<h6 id="domains_69">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_69">Options:</h6>
<pre><code>usage: to-roi-od [-d WIDTH HEIGHT] [--annotations-only] [--comments COMMENTS [COMMENTS ...]] -o PATH [--size-mode] [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]] [--prefix WRITER_PREFIX] [--suffix WRITER_SUFFIX]

optional arguments:
  -d WIDTH HEIGHT, --image-dimensions WIDTH HEIGHT
                        image dimensions to use if none can be inferred
  --annotations-only    skip the writing of data files, outputting only the annotation files
  --comments COMMENTS [COMMENTS ...]
                        comments to write to the beginning of the ROI file
  -o PATH, --output PATH
                        output directory to write files to
  --size-mode           writes the ROI files with x,y,w,h headers instead of x0,y0,x1,y1
  --split-names SPLIT NAME [SPLIT NAME ...]
                        the names to use for the splits
  --split-ratios RATIO [RATIO ...]
                        the ratios to use for the splits
  --prefix WRITER_PREFIX
                        the prefix for output filenames (default = '')
  --suffix WRITER_SUFFIX
                        the suffix for output filenames (default = '-rois.csv')
</code></pre>
<h5 id="to-subdir-ic">TO-SUBDIR-IC</h5>
<p>Writes images to sub-directories named after their class labels.</p>
<h6 id="domains_70">Domain(s):</h6>
<ul>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_70">Options:</h6>
<pre><code>usage: to-subdir-ic -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]]

optional arguments:
  -o PATH, --output PATH
                        the directory to store the class directories in
  --split-names SPLIT NAME [SPLIT NAME ...]
                        the names to use for the splits
  --split-ratios RATIO [RATIO ...]
                        the ratios to use for the splits
</code></pre>
<h5 id="to-tf-od">TO-TF-OD</h5>
<p>Writes image object-detection annotations in the TFRecords binary format</p>
<h6 id="domains_71">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_71">Options:</h6>
<pre><code>usage: to-tf-od [--dense] [--source-id-type {filename,numeric-dummy}] -o PATH [-p FILENAME] [-s FILENAME [FILENAME ...]] [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]]

optional arguments:
  --dense               outputs masks in the dense numerical format instead of PNG-encoded
  --source-id-type {filename,numeric-dummy}
                        by default, the filename gets stored in the 'source_id' field, but some algorithms try to convert it into a number and fail with 'StringToNumberOp could not correctly convert string'; in which case you can use 'numeric-dummy' (see https://github.com/google/automl/issues/307)
  -o PATH, --output PATH
                        name of output file for TFRecords
  -p FILENAME, --protobuf FILENAME
                        for storing the label strings and IDs
  -s FILENAME [FILENAME ...], --shards FILENAME [FILENAME ...]
                        additional shards to write to
  --split-names SPLIT NAME [SPLIT NAME ...]
                        the names to use for the splits
  --split-ratios RATIO [RATIO ...]
                        the ratios to use for the splits
</code></pre>
<h5 id="to-vgg-od">TO-VGG-OD</h5>
<p>Writes image object-detection annotations in the VGG JSON-format</p>
<h6 id="domains_72">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_72">Options:</h6>
<pre><code>usage: to-vgg-od [--annotations-only] -o PATH [--pretty] [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]]

optional arguments:
  --annotations-only    skip the writing of data files, outputting only the annotation files
  -o PATH, --output PATH
                        output file to write annotations to (images are placed in same directory)
  --pretty              whether to format the JSON annotations file with indentation
  --split-names SPLIT NAME [SPLIT NAME ...]
                        the names to use for the splits
  --split-ratios RATIO [RATIO ...]
                        the ratios to use for the splits
</code></pre>
<h5 id="to-video-file-od">TO-VIDEO-FILE-OD</h5>
<p>Writes frames to a MJPG video file.</p>
<h6 id="domains_73">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_73">Options:</h6>
<pre><code>usage: to-video-file-od [-f FPS] [-o OUTPUT_FILE]

optional arguments:
  -f FPS, --fps FPS     the frames per second to use
  -o OUTPUT_FILE, --output OUTPUT_FILE
                        the MJPG video file to write to
</code></pre>
<h5 id="to-voc-od">TO-VOC-OD</h5>
<p>Writes image object-detection annotations in the Pascal VOC XML-format</p>
<h6 id="domains_74">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_74">Options:</h6>
<pre><code>usage: to-voc-od [--annotations-only] -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]]

optional arguments:
  --annotations-only    skip the writing of data files, outputting only the annotation files
  -o PATH, --output PATH
                        output directory to write annotations to (images are placed in same directory)
  --split-names SPLIT NAME [SPLIT NAME ...]
                        the names to use for the splits
  --split-ratios RATIO [RATIO ...]
                        the ratios to use for the splits
</code></pre>
<h5 id="to-void-ic">TO-VOID-IC</h5>
<p>Consumes instances without writing them.</p>
<h6 id="domains_75">Domain(s):</h6>
<ul>
<li><strong>Image Classification Domain</strong></li>
</ul>
<h6 id="options_75">Options:</h6>
<pre><code>usage: to-void-ic
</code></pre>
<h5 id="to-void-is">TO-VOID-IS</h5>
<p>Consumes instances without writing them.</p>
<h6 id="domains_76">Domain(s):</h6>
<ul>
<li><strong>Image Segmentation Domain</strong></li>
</ul>
<h6 id="options_76">Options:</h6>
<pre><code>usage: to-void-is
</code></pre>
<h5 id="to-void-od">TO-VOID-OD</h5>
<p>Consumes instances without writing them.</p>
<h6 id="domains_77">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_77">Options:</h6>
<pre><code>usage: to-void-od
</code></pre>
<h5 id="to-void-sp">TO-VOID-SP</h5>
<p>Consumes instances without writing them.</p>
<h6 id="domains_78">Domain(s):</h6>
<ul>
<li><strong>Speech Domain</strong></li>
</ul>
<h6 id="options_78">Options:</h6>
<pre><code>usage: to-void-sp
</code></pre>
<h5 id="to-yolo-od">TO-YOLO-OD</h5>
<p>Writes image object-detection annotations in the YOLO format</p>
<h6 id="domains_79">Domain(s):</h6>
<ul>
<li><strong>Image Object-Detection Domain</strong></li>
</ul>
<h6 id="options_79">Options:</h6>
<pre><code>usage: to-yolo-od [-c PATH] [-l PATH] [--annotations-only] -o PATH [--split-names SPLIT NAME [SPLIT NAME ...]] [--split-ratios RATIO [RATIO ...]]

optional arguments:
  -c PATH, --labels-csv PATH
                        Path to the labels CSV file to write
  -l PATH, --labels PATH
                        Path to the labels file to write
  --annotations-only    skip the writing of data files, outputting only the annotation files
  -o PATH, --output PATH
                        output directory to write images and annotations to
  --split-names SPLIT NAME [SPLIT NAME ...]
                        the names to use for the splits
  --split-ratios RATIO [RATIO ...]
                        the ratios to use for the splits
</code></pre>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../glossary/" class="btn btn-neutral float-right" title="Glossary">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../domains/" class="btn btn-neutral" title="Domains"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href="../domains/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../glossary/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme.js" defer></script>
      <script src="../search/main.js" defer></script>

</body>
</html>
